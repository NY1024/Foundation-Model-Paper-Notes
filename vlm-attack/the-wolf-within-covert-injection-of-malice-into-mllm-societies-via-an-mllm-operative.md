# THE WOLF WITHIN: COVERT INJECTION OF MALICE  INTO MLLM SOCIETIES VIA AN MLLM OPERATIVE

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

1. 研究背景： 多模态大型语言模型（MLLMs）在处理和响应各种类型数据方面的能力前所未有，它们不断定义着人工通用智能（AGI）的新边界。随着这些先进的生成模型越来越多地形成复杂任务的协作网络，确保这些系统的完整性和安全性变得至关重要。本文探讨了MLLM社会中的一个新型漏洞——通过MLLM代理间接传播恶意内容。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

1. 过去方案和缺点： 以往的研究主要集中在直接操纵MLLMs以产生有害输出，例如通过对抗性攻击和数据投毒。这些方法通常需要对模型有深入的了解，并且可能需要直接访问模型的参数。然而，这些方法没有考虑到通过MLLM网络中的单个代理间接传播恶意内容的可能性。

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

1. 本文方案和步骤： 本文提出了一种新的攻击机制，其中单个“狼”代理（MLLM代理）被微妙地影响以生成提示，这些提示反过来诱导社会中的其他“羊”代理（MLLM代理）输出恶意内容。研究者们通过注入可学习的噪声到图像输入中，然后优化这些噪声以生成恶意提示，从而实现对其他代理的“感染”。
2. 本文创新点与贡献：

* 提出了一种新的MLLM社会中的恶意内容传播方式，即通过间接影响实现。
* 展示了即使在没有或仅有有限访问MLLMs参数的情况下，也能通过特定提示“感染”其他代理。
* 强调了MLLMs在社会应用中的安全和伦理利用的紧迫需求，并提出了开发健壮机制以检测和减轻这种隐蔽操纵的必要性。

5. 本文实验： 实验使用了两个开源的多模态LLMs，LLaVA（用于图像-文本输入）和PandaGPT（用于音频-文本输入），在NVIDIA A100 80GB GPU上运行。实验结果显示，通过提出的方法，狼代理能够有效地生成恶意内容，从而“越狱”羊代理。
6. 结论： 研究发现，MLLMs社会中存在一种微妙但深远的漏洞，即单个被破坏的代理可以秘密地触发恶意内容在网络中的传播。这种间接影响的方法绕过了直接参数访问的需要，代表了一种系统性风险，将威胁从个体模型扩展到MLLM社会的协作结构。研究结果强调了先进安全措施的紧迫需求，并突出了重新评估现有框架以预防此类隐蔽威胁的重要性。

注：

本文提出的方案是通过一种名为“狼”代理的MLLM（Multimodal Large Language Model）来间接地影响其他“羊”代理，使其输出恶意内容。以下是实施这一方案的详细步骤：

1. **注入可学习的噪声**：
   * 首先，给定一对良性的文本提示（xT）和图像（xI）。
   * 然后，向图像注入可学习的噪声（n），得到一个扰动后的图像（˜xI）。
   * 选择一个包含恶意内容的目标响应（y）。
2. **选择狼代理并生成恶意提示**：
   * 在MLLM社会中选择一个代理作为狼代理。
   * 将扰动后的图像和文本提示对输入给狼代理，得到其输出作为羊代理的恶意提示（˜xT）。
3. **选择羊代理并获取输出**：
   * 在MLLM社会中选择另一个代理作为羊代理。
   * 将扰动后的图像和恶意提示输入给羊代理，得到其输出（ˆy）。
4. **计算差异并优化噪声**：
   * 使用交叉熵损失（LCE）计算ˆy和y之间的差异。
   * 使用损失来优化噪声n，通过优化器进行迭代优化。
5. **评估“感染性”**：
   * 使用优化后的噪声，得到相应的扰动图像（˜xI）和恶意提示（˜xT）。
   * 评估这些提示的“感染性”，即它们能否通过直接转移来“越狱”其他MLLM代理。

在优化过程中，作者考虑了两种优化方法：投影梯度下降（PGD）和近端策略优化（PPO）。

* **PGD**：假设攻击者可以访问狼代理解码器中的采样操作。通过迭代优化输入图像的扰动，以生成恶意提示。
* **PPO**：通过强化学习（RL）直接优化噪声。定义RL模块的状态为注入的噪声n和羊代理ϕ。奖励是交叉熵损失的负值，目标是最小化羊代理生成的响应与目标响应之间的差异。

实验设置中，作者使用了两个开源的多模态LLMs，LLaVA和PandaGPT，分别用于图像-文本输入和音频-文本输入。通过这些步骤，作者能够展示如何通过一个MLLM代理来间接地影响其他代理，从而在MLLM社会中传播恶意内容。



注2：

在本文的研究中，设置两种代理角色——“狼”代理和“羊”代理——是为了模拟和研究MLLM社会中恶意内容传播的动态。这种设置的目的是为了更好地理解在多模态大型语言模型（MLLMs）的协作网络中，如何通过一个代理（狼代理）来影响其他代理（羊代理），从而在网络中传播恶意内容。以下是设置这两种角色的原因：

1. **模拟现实世界的攻击场景**： 在现实世界中，攻击者可能会尝试通过各种手段来操纵或破坏系统。在MLLMs的背景下，攻击者可能会尝试通过特定的输入（提示）来影响模型的行为。通过设置狼代理，研究者可以模拟这种攻击者的行为，而羊代理则代表了那些可能被影响的模型。
2. **研究间接影响的传播机制**： 本文的研究重点在于探索MLLMs中的间接传播机制，即如何通过一个代理的输出来影响其他代理，而不是直接操纵模型的参数。这种设置允许研究者观察和分析在MLLM社会中，恶意内容是如何从一个代理传播到另一个代理的。
3. **评估系统的安全性和鲁棒性**： 通过这种角色设置，研究者可以评估MLLMs在面对潜在攻击时的安全性和鲁棒性。这有助于识别系统可能存在的漏洞，并为开发更强大的安全措施提供依据。
4. **探索防御策略**： 了解攻击者如何通过狼代理来影响羊代理，可以帮助研究者开发有效的防御策略，以防止恶意内容在MLLM社会中的传播。这种策略可能包括改进模型的输入处理机制、增强模型的鲁棒性，或者开发新的检测和响应机制。
5. **实验验证和分析**： 通过实验，研究者可以验证提出的攻击方法的有效性，并分析不同情况下的传播效果。这有助于理解在实际应用中，MLLMs可能面临的风险，并为未来的研究提供实验数据和分析基础。

总之，设置两种代理角色是为了更全面地研究MLLMs在面对潜在攻击时的行为和响应，以及如何设计更安全的MLLM社会。这种研究对于确保MLLMs在各种应用中的安全和伦理使用至关重要。



注3：

在本文中，"Malicious tokens"（恶意标记）是狼代理的输出。这些恶意标记是由狼代理生成的，它们是经过精心设计的文本提示，旨在诱导羊代理输出恶意内容。狼代理接收扰动后的图像和良性文本提示作为输入，然后生成包含恶意标记的输出。这些输出随后被用作羊代理的输入，以诱导羊代理产生恶意响应。

具体来说，狼代理的角色是：

1. 接收扰动后的图像（˜xI）和良性文本提示（xT）作为输入。
2. 生成包含恶意标记的文本提示（˜xT），这些提示是狼代理的输出，旨在诱导羊代理。
3. 将这些恶意标记传递给羊代理，以测试羊代理是否会被“感染”并输出恶意内容。

这个过程模拟了攻击者如何利用MLLMs的协作网络来传播恶意内容，而不需要直接访问模型的内部参数。通过这种方式，研究者可以评估MLLMs在面对这种间接攻击时的脆弱性，并探索可能的防御策略。



注4：

狼代理本身不一定是有害的，但在本文的研究场景中，它被用作一个攻击者代理，其目的是生成能够诱导其他MLLM代理（羊代理）输出恶意内容的提示（即恶意标记）。狼代理能够输出恶意标记的原因在于研究者对其进行了特定的操纵或“感染”，使其在不知情的情况下产生这些有害的输出。

这个过程通常涉及以下几个步骤：

1. **注入噪声**：研究者向狼代理的输入中注入可学习的噪声，这些噪声经过精心设计，以改变模型的输出。
2. **优化过程**：通过迭代优化过程，研究者调整噪声，使得狼代理的输出逐渐接近目标恶意内容。
3. **生成恶意提示**：经过优化的噪声导致狼代理生成包含恶意标记的文本提示，这些提示被设计为能够诱导羊代理产生恶意响应。
4. **传播恶意内容**：狼代理的恶意提示被传递给羊代理，如果羊代理对这些提示敏感，它可能会输出恶意内容，从而被“感染”。

在这个过程中，狼代理的角色是作为一个攻击者的工具，而不是因为它本身具有恶意。这种设置允许研究者模拟和分析在MLLM社会中可能发生的攻击场景，以及这些攻击如何影响模型的行为和输出。通过这种方式，研究者可以更好地理解MLLMs的安全性，并开发出更有效的防御措施来保护这些模型免受实际攻击。







5. 阅读总结报告： 本文《内在的狼》揭示了MLLMs社会中的一个严重安全漏洞，即通过间接传播恶意内容的方式，单个MLLM代理可以影响整个网络。这种攻击方法不需要深入了解模型参数，使得检测和防御变得更加困难。研究强调了开发新的安全机制的重要性，以确保MLLMs在社会应用中的安全和伦理使用。实验结果表明，通过优化注入的噪声，可以有效地“感染”其他MLLM代理，产生有害输出。这一发现对于理解和保护MLLMs免受潜在攻击具有重要意义。
