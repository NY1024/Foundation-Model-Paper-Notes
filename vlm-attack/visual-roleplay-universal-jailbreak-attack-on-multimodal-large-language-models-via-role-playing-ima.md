# Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Ima

<figure><img src="../.gitbook/assets/image (280).png" alt=""><figcaption></figcaption></figure>

#### 研究背景

随着多模态大型语言模型（MLLMs）的出现和广泛部署，确保它们的安全性变得越来越重要。MLLMs在处理视觉和语言任务方面表现出色，但同时也可能被恶意利用来生成有害内容，如暴力、歧视、虚假信息或不道德内容。因此，研究者们提出了“越狱攻击”（jailbreak attacks），目的是通过精心设计的输入误导MLLMs响应恶意请求。

#### 过去方案和缺点

现有的越狱攻击方法主要分为三类：基于扰动的攻击、基于文本的攻击和基于结构的攻击。基于扰动的攻击通过对抗性扰动破坏MLLMs的对齐，而基于文本的攻击则利用针对大型语言模型（LLMs）的越狱技术生成文本提示来破坏MLLMs。然而，这些方法存在局限性，如缺乏足够的越狱效果和泛化能力。特别是基于结构的越狱攻击，它们通常需要针对每个查询进行计算，处理大数据集时不切实际。

<figure><img src="../.gitbook/assets/image (281).png" alt=""><figcaption></figcaption></figure>

#### 本文方案和步骤

为了克服现有方法的局限性，本文提出了一种新颖有效的方法，称为视觉角色扮演（Visual Role-play, VRP）。VRP利用大型语言模型生成高风险角色的详细描述，并基于这些描述创建相应的图像。具体步骤包括：

1. **生成角色描述**：使用LLM生成高风险角色的关键特征描述。
2. **生成角色图像**：利用文本到图像模型根据描述生成角色图像。
3. **生成问题文本**：将恶意查询直接嵌入图像中。
4. **图像拼接**：将角色描述文本、角色图像和恶意查询文本从上到下拼接形成完整的输入图像。
5. **攻击MLLMs**：将完整的恶意图像与良性角色扮演指令文本配对，查询并攻击MLLMs。

#### 本文创新点与贡献

* 提出了首个利用“角色扮演”概念来增强MLLMs越狱攻击性能的方法。
* VRP通过生成详细的角色描述和图像，有效地误导MLLMs生成恶意响应。
* VRP展示了强大的泛化能力，能够处理广泛的恶意查询，不仅限于特定用户请求。
* 在流行的基准测试中，VRP实现了优越的越狱性能和强泛化能力。

#### 本文实验

实验使用了两个广泛使用的越狱攻击数据集RedTeam-2K和HarmBench来评估VRP。通过与现有的最强基线Query relevant和FigStep进行比较，VRP在所有模型上平均提高了14.3%的攻击成功率（ASR）。

#### 实验结论

VRP方法在越狱攻击MLLMs方面表现出色，不仅成功地破坏了这些模型，而且与所有评估的基线攻击相比，具有更高的ASR。此外，VRP在更具有挑战性的通用攻击设置中仍然表现出最佳性能，证明了其泛化能力。

#### 全文结论

本文提出的VRP方法有效地克服了现有越狱攻击方法在效果和泛化能力上的局限性。通过联合框架生成角色肖像并指导MLLMs进行角色扮演，VRP破坏了模型的对齐鲁棒性。广泛的实验表明，与现有方法相比，VRP在各种模型上展现出卓越的攻击效果，甚至能够抵御先进的防御措施。

####
