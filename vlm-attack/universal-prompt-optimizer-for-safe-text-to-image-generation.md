# Universal Prompt Optimizer for Safe Text-to-Image Generation

<figure><img src="../.gitbook/assets/image (218).png" alt=""><figcaption></figcaption></figure>

## 研究背景

文本到图像（Text-to-Image, T2I）模型在根据文本提示生成图像方面表现出色，但这些模型容易受到不安全输入的影响，从而生成不安全的内容，如色情、骚扰和非法活动图像。现有的基于图像检查器、模型微调和嵌入屏蔽的方法在现实世界应用中不切实际。

<figure><img src="../.gitbook/assets/image (219).png" alt=""><figcaption></figcaption></figure>

## 过去方案和缺点

以往的解决方案包括使用安全检查器检测生成的图像、通过嵌入屏蔽引导模型生成安全内容，或通过微调模型来抑制某些概念的生成。然而，直接拒绝图像可能会影响用户体验，优化模型则需要获取T2I模型的内部结构，这不仅耗时，也缺乏普遍性。

<figure><img src="../.gitbook/assets/image (220).png" alt=""><figcaption></figcaption></figure>

## 本文方案和步骤

本文提出了一种通用的提示优化器，用于在黑盒场景下安全地生成T2I内容。首先，使用GPT-3.5 Turbo构建了一个由有毒和清洁提示对组成的数据集。为了引导优化器在保留语义信息的同时将有毒提示转换为清洁提示，设计了一种新颖的奖励函数来衡量生成图像的毒性和文本对齐，并使用近端策略优化（Proximal Policy Optimization, PPO）来训练优化器。

## 本文创新点与贡献

* 研究了使用提示工程生成安全T2I内容的新问题。
* 提出了第一个黑盒提示优化器，可以在不获取T2I模型结构的情况下，修改有毒提示以生成安全且保留语义的图像，并可应用于各种T2I模型。
* 广泛的实验表明，该方法能够有效降低生成不适当图像的可能性，同时不会显著影响文本对齐。

## 本文实验

实验部分评估了所提出框架的有效性，回答了以下研究问题：（i）所提出框架在修改有毒提示以生成安全和保留语义的图像方面的有效性如何？（ii）所提出的方法是否有助于各种T2I模型？（iii）我们框架中每个组件的贡献是什么？

## 实验结论

实验结果表明，与现有方法相比，所提出的方法在生成安全图像方面更为有效，且可以与其他方法结合使用，进一步提高效果。此外，该方法在不同版本的Stable Diffusion模型上具有良好的迁移性，并且可以应用于其他黑盒T2I模型。

## 全文结论

本文提出了一个新颖的框架，通过自动提示优化来生成安全的图像。实验结果证明了所提出框架的有效性。此外，该方法具有良好的迁移性，并且可以灵活地应用于各种T2I模型。

## 阅读总结报告

本研究针对T2I模型在生成不安全图像方面的风险，提出了一种新颖的通用提示优化器。通过构建有毒和清洁提示对的数据集，并设计奖励函数和使用PPO算法，该优化器能够有效地将有毒提示转换为清洁提示，从而生成既安全又保留语义的图像。实验表明，该方法不仅有效，而且具有很好的迁移性和灵活性，可以广泛应用于不同的T2I模型。这项工作为提高T2I模型生成内容的安全性提供了一种有效的解决方案。
