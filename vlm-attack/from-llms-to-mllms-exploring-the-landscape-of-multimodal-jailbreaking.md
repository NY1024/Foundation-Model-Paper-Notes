# From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking

<figure><img src="../.gitbook/assets/image (287).png" alt=""><figcaption></figcaption></figure>

### 研究背景

大型语言模型（LLMs）和多模态大型语言模型（MLLMs）的快速发展，展示了在多种任务上卓越的性能，但同时也暴露了对各种对抗性攻击的脆弱性。这些模型在遵循指令以满足不同用户需求的同时，其完整性和可靠性面临显著挑战。特别是所谓的“越狱攻击”（jailbreak attack），通过恶意指令或干预训练和解码过程，绕过LLMs内置的安全措施，导致模型表现出不良行为。因此，研究攻击策略和强大的防御措施，以更好地保护道德限制并提高LLMs的安全性，变得尤为重要。

### 过去方案和缺点

过去的研究主要集中在单模态越狱攻击和防御上，而多模态领域的研究相对较少。现有的多模态越狱数据集面临多种限制，例如图像来源有限、任务范围狭窄、毒性表现明显等。此外，对于多模态越狱攻击的研究还处于探索阶段，缺乏复杂多模态任务的探索、图像域转换的忽视以及缺乏多模态训练干预。

<figure><img src="../.gitbook/assets/image (288).png" alt=""><figcaption></figcaption></figure>

### 本文方案和步骤

本文提供了对针对LLMs和MLLMs的越狱研究的全面概述，并探讨了MLLMs越狱的潜在方向。研究从详细的介绍开始，接着描述了LLMs和MLLMs越狱的评估数据集，详细阐述了越狱攻击的各种方法和防御策略，并讨论了多模态越狱的局限性和未来研究方向。

<figure><img src="../.gitbook/assets/image (289).png" alt=""><figcaption></figcaption></figure>

### 本文创新点与贡献

1. 对比单模态和多模态越狱的研究现状，指出了多模态领域的研究空白。
2. 总结了多模态越狱的局限性，并提出了未来研究方向，如探索多样化的多模态任务、图像域转换、多模态训练干预等。
3. 提出了一系列新的多模态越狱攻击和防御策略，包括非参数攻击和参数攻击，以及对应的内在和外在防御方法。

### 本文实验

本文没有明确提到具体的实验设置或结果。它更多地集中在对现有越狱攻击和防御策略的分析，以及对未来研究方向的展望。

### 实验结论

由于缺乏具体的实验部分，本文没有直接的实验结论。但通过对现有研究的分析，作者指出了多模态越狱领域的研究不足，并呼吁更多的研究者关注这一领域，以促进更安全、更可靠的大型模型的发展。

### 全文结论

本文提供了对LLMs和MLLMs越狱研究的全面概述，讨论了评估基准、攻击技术和防御策略的最新进展。同时，总结了MLLMs越狱的局限性和潜在研究方向，旨在激发未来的工作。

###
