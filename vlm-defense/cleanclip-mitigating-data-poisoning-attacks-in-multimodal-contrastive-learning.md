# CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning

<figure><img src="../.gitbook/assets/image (176).png" alt=""><figcaption></figcaption></figure>

**研究背景：** 在人工智能的发展中，学习从多种模态中获取通用表示是一个长期目标。多模态对比学习方法，如CLIP（Contrastive Language-Image Pretraining），通过在大规模、嘈杂且未经筛选的图像-文本对上进行训练，已经能够实现图像和文本的联合表示。这些模型在ImageNet等数据集上展示了出色的零样本分类性能，并且在面对自然分布变化的数据集时表现出鲁棒性。然而，最近的研究表明，这些模型容易受到后门攻击的影响。通过在预训练数据中注入少量的带有特定触发器的恶意样本，可以显著操纵模型的行为，使得模型在检测或消除这些相关性时遇到困难。

**过去方案和缺点：** 以往的多模态对比学习方法在面对后门攻击时表现出脆弱性。例如，通过在图像中嵌入后门触发器，并将其与目标标签的代理标题配对，可以在模型中植入后门。这种后门攻击会导致模型在预训练过程中学习到图像中后门触发器与目标标签之间的虚假相关性。这使得模型在下游应用中，如图像分类，会错误地将含有后门触发器的图像分类为目标类别。此外，由于后门触发器通常是未知的，因此很难检测和消除这种攻击。

<figure><img src="../.gitbook/assets/image (177).png" alt=""><figcaption></figcaption></figure>

**本文方案和步骤：** 为了解决这个问题，本文提出了CleanCLIP，一个微调框架，通过独立地重新对齐各个模态（图像和文本）的表示来削弱后门攻击引入的虚假关联。CleanCLIP通过结合多模态对比和单模态自监督目标来实现。在实验中，作者展示了使用CleanCLIP可以在保持对良性样本性能的同时，消除多种后门攻击对多模态对比学习的影响。此外，作者还展示了在特定任务的标记图像数据上进行有监督微调可以移除CLIP视觉编码器中的后门触发器。



在多模态对比学习中，模型通过训练来学习图像和文本之间的联合表示，使得匹配的图像-文本对在表示空间中更接近，而不匹配的对则更远离。这种学习过程旨在捕捉图像和文本的语义含义，并在共享的嵌入空间中形成关联。

然而，后门攻击通过在训练数据中注入带有特定触发器的恶意样本，使得模型学习到图像中的后门触发器与特定目标标签之间的虚假关联。这意味着，即使图像本身并不属于攻击者指定的目标类别，只要图像中存在后门触发器，模型就会错误地将其分类为该目标类别。

为了削弱这种虚假关联，CleanCLIP框架提出了一种方法，即独立地重新对齐各个模态（图像和文本）的表示。具体来说，这意味着在微调过程中，模型不仅继续学习图像和文本之间的关联（多模态对比学习），而且还学习图像和文本各自内部的表示（自监督学习）。这样，模型被鼓励去学习图像和文本的独立特征，而不是仅仅依赖于它们之间的关联。通过这种方式，模型可以减少对后门触发器的依赖，从而降低后门攻击的影响。

在CleanCLIP中，这种独立学习是通过在微调过程中同时使用多模态对比损失（用于图像和文本对的对齐）和自监督学习目标（用于图像和文本各自的对齐）来实现的。这种方法有助于打破模型在预训练阶段可能学到的后门触发器与目标标签之间的不当关联，从而提高模型对后门攻击的鲁棒性。





**本文创新点与贡献：**

* 提出了CleanCLIP框架，用于通过微调预训练的CLIP模型来移除后门。
* 引入了自监督学习目标，鼓励模型独立地学习每个模态的表示，从而打破后门触发器和目标标签之间的虚假映射。
* 实验结果表明，CleanCLIP能够有效地减少后门攻击的成功率，同时保持对良性图像的分类性能。
* 提供了代码和预训练的检查点，以便研究社区可以复现和利用CleanCLIP。

**本文实验：** 作者在多个实验中评估了CleanCLIP的有效性。实验包括在ImageNet-1K验证集上评估模型的清洁准确性和攻击成功率。实验结果表明，CleanCLIP在不降低清洁准确性的情况下显著降低了攻击成功率。此外，作者还研究了自监督信号强度、后门样本数量、预训练数据集大小等因素对CleanCLIP效果的影响。

**实验结论：** 实验结果证实了CleanCLIP在减少后门攻击影响方面的有效性。通过调整自监督信号的强度，可以在不牺牲清洁准确性的情况下显著降低攻击成功率。此外，使用有监督微调可以进一步减少后门攻击的成功率。

**全文结论：** 本文提出了CleanCLIP，一个有效的框架，用于保护多模态对比预训练（如CLIP）免受后门攻击。CleanCLIP通过鼓励模型独立地学习每个模态的表示，打破了后门触发器和目标标签之间的虚假关联。实验结果表明，CleanCLIP能够在不牺牲模型性能的情况下，有效地减少后门攻击的成功率。

**阅读总结报告：** 本研究针对多模态对比学习模型（如CLIP）在面对后门攻击时的脆弱性提出了解决方案。通过CleanCLIP框架，作者展示了如何通过微调策略来削弱后门攻击的影响，同时保持模型对良性样本的分类性能。这一工作不仅提供了一种新的防御机制，还通过实验验证了其有效性，并为未来在这一领域的研究提供了新的方向。
