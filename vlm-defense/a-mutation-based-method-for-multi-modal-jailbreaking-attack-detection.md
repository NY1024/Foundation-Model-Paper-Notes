# A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection

<figure><img src="../.gitbook/assets/image (7) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在各种应用中的广泛使用，它们在从简单的聊天机器人到复杂的决策系统等方面发挥着关键作用。然而，这些模型的安全问题也日益凸显，特别是它们容易受到越狱攻击（jailbreaking attacks），这种攻击允许恶意用户利用模型，从而破坏了基于LLM应用的完整性和可信度。

### 2. 过去方案和缺点

现有的越狱攻击检测方法主要分为两类：基于查询后的防御和基于查询前的防御。基于查询后的防御通常是反应性的，需要特定目标领域的知识，并且只在安全漏洞发生后才进行识别。而基于查询前的防御主要关注文本级别的攻击，无法满足现代LLMs日益复杂的多模态安全需求。这些方法的局限性强调了需要更全面的策略来保护这些有影响力的系统。

### 3. 本文方案和步骤

本文提出了JailGuard，这是一个基于变异的越狱检测框架，支持图像和文本模态。JailGuard的关键观察是攻击查询本质上比良性查询具有更低的鲁棒性。为了混淆模型，攻击查询通常是根据精心设计的模板或复杂的扰动生成的，这导致输入的轻微干扰可能导致响应的剧烈变化。JailGuard利用这种缺乏鲁棒性来进行攻击检测，首先将传入的输入变异为变体查询，然后检查变体响应的分歧。基于这种直觉，作者设计并实现了一个包含19种不同变异器和基于分歧的检测公式的检测框架。

### 4. 本文创新点与贡献

* 提出了JailGuard，这是第一个基于变异的多模态越狱检测框架，支持图像和文本模态的检测。
* 构建了第一个覆盖图像和文本输入的越狱攻击数据集。
* 在构建的数据集上进行了实验，JailGuard在图像和文本输入上的检测准确率分别达到了89.38%和85.42%，比最先进的防御方法提高了15.28%。

### 5. 本文实验

作者构建了一个包含304个数据项的多模态LLM越狱攻击数据集，涵盖了十种已知的针对图像和文本模态的越狱攻击。实验结果表明，JailGuard能够有效地检测图像和文本模态上的越狱攻击，并且在所有收集到的攻击类型上，JailGuard的最佳检测准确率总是高于70%。

### 6. 实验结论

JailGuard在检测图像和文本输入上的越狱攻击方面表现出色，其检测准确率显著高于现有的防御方法。此外，JailGuard能够有效地检测和防御不同类型的越狱攻击。

### 7. 全文结论

本文提出的JailGuard框架为多模态LLMs提供了一种有效的越狱攻击检测和防御机制。通过变异输入并分析响应的分歧，JailGuard能够以较高的准确率识别攻击查询。实验结果证明了其在图像和文本模态上的有效性，并为未来的LLM安全研究提供了新的视角和工具。

### 阅读总结

本文针对大型语言模型（LLMs）面临的越狱攻击问题，提出了一个新的检测框架JailGuard。JailGuard通过变异输入并分析模型响应的分歧来检测攻击，这在多模态LLMs的安全领域是一个创新。实验结果表明，JailGuard在图像和文本输入上的检测准确率显著优于现有方法，为LLMs的安全性提供了更全面的保护。此外，作者还构建了第一个多模态越狱攻击数据集，为未来的研究和评估提供了宝贵的资源。为未来的研究和评估提供了宝贵的资源。
