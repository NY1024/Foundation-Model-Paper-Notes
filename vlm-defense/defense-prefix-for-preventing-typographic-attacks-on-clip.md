# Defense-Prefix for Preventing Typographic Attacks on CLIP

<figure><img src="../.gitbook/assets/image (36).png" alt=""><figcaption></figcaption></figure>

1. 研究背景： 视觉-语言预训练模型（VLPs），如CLIP和ALIGN，已经在各种视觉-语言任务中取得了革命性的进展。然而，这些模型容易受到对抗性攻击的影响，尤其是排版攻击（Typographic Attacks），在这种攻击中，图像中的文本会导致模型误分类。先前的研究主要通过微调模型或改变其架构来应对这些攻击，但这些方法可能会损失原始模型的性能，并且难以应用于下游任务。

<figure><img src="../.gitbook/assets/image (37).png" alt=""><figcaption></figcaption></figure>

1. 过去方案和缺点： 以往的研究主要集中在对分类任务的排版攻击上，忽略了其在其他任务中的适用性。此外，先前的方法通过改变模型参数或在CLIP输出上应用学习到的线性变换来解决排版攻击问题，这可能导致原始模型性能的损失，并且难以应用于下游任务。这些方法还需要更新图像特征，增加了复杂性。

<figure><img src="../.gitbook/assets/image (38).png" alt=""><figcaption></figcaption></figure>

1. 本文方案和步骤： 本文提出了一种名为Defense-Prefix（DP）的简单而有效的方法，通过在类别名称前插入DP标记来增强模型对排版攻击的鲁棒性。DP方法不改变模型参数，可以轻松应用于下游任务，如对象检测。研究者首先训练DP向量，然后在分类和对象检测任务中应用该向量。
2. 本文创新点与贡献：
   * 提出了DP方法，一种新颖的防止CLIP遭受排版攻击的方法，无需改变模型参数。
   * 证明了基于CLIP的下游分类器也容易受到排版攻击，并展示了DP方法的有效性。
   * 通过实验验证了DP方法在保持原始模型性能的同时，有效防止排版攻击。
   * 创建了最大的现实世界排版攻击数据集RTA-100，并将公开提供。
3. 本文实验和性能： 实验在十个合成和三个现实世界的排版攻击数据集上进行，结果表明DP方法在防止排版攻击的同时，仅在原始数据集上损失了0.64%的准确率。在对象检测任务中，DP方法在保持原始准确性的同时，减少了排版攻击的影响。此外，通过消融研究，研究者展示了身份损失（Identity Loss）在保持单词原始含义方面的重要性。
4. 结论： 本研究通过提出DP方法，有效地减少了排版攻击对CLIP的影响，同时保持了模型的原始性能。DP方法的简单性和有效性使其成为现有研究的显著优势，因为它不需要修改模型或现有特征。未来的工作将探索将DP方法应用于其他对抗性攻击的可能性。

阅读总结报告： 本文针对视觉-语言预训练模型（VLPs）在面对排版攻击时的脆弱性提出了一种新的防御方法。通过引入Defense-Prefix（DP）概念，研究者成功地在不改变模型参数的情况下提高了模型对排版攻击的鲁棒性。DP方法的创新之处在于其简单性和通用性，可以轻松应用于各种下游任务。实验结果证明了DP方法在提高分类任务准确性和对象检测任务鲁棒性方面的有效性。此外，通过创建RTA-100数据集，本文为未来在这一领域的研究提供了宝贵的资源。尽管DP方法在某些合成排版攻击数据集上的表现略逊于先前研究，但其在现实世界数据集上的表现以及对模型参数的无影响性，使其成为一个有吸引力的解决方案。未来的研究可能会探索将DP方法扩展到其他类型的对抗性攻击。
