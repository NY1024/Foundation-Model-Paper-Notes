# PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification

<figure><img src="../.gitbook/assets/image (22) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着大型语言模型（LLMs）在各种下游任务中的广泛应用，提示（prompt）技术在提高预训练LLMs性能方面发挥了关键作用。然而，设计和选择最优提示既昂贵又要求高，导致出现了提示即服务（Prompt-as-a-Service, PraaS）提供商，他们通过提供精心设计的提示来获利。随着提示在LLM基础服务中变得越来越重要，保护提示版权免受未经授权使用的需求日益迫切。

### 2. 过去方案和缺点

现有的版权保护研究主要集中在模型和数据集上，而针对提示的版权保护尚未得到充分研究。现有的水印技术，如指纹技术、数据集推断和水印技术，虽然在模型和数据集版权保护方面取得了一定成效，但并不适用于提示版权保护。提示水印的注入和验证面临独特挑战，如低熵提示的注入困难，以及在序列分类任务中使用低熵文本验证水印的挑战。

<figure><img src="../.gitbook/assets/image (23) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了PromptCARE框架，用于通过水印注入和验证来保护提示版权。在水印注入阶段，PromptCARE将水印注入视为双层优化任务，同时训练水印注入和提示调整任务。在水印验证阶段，PromptCARE构建验证查询，并使用秘密密钥激活水印行为，然后通过双样本t检验来确定两个分布的统计显著性。

### 4. 本文创新点与贡献

* 提出了PromptCARE，这是第一个用于提示版权保护的水印注入和验证框架。
* 设计了针对提示特性和自然语言领域的水印注入和验证方案。
* 在六个知名基准数据集上进行了广泛的实验，使用了三种流行的预训练LLMs（BERT、RoBERTa和Facebook OPT-1.3b），证明了PromptCARE的有效性、无害性、鲁棒性和隐蔽性。
* 对大型商业语言模型LLaMA进行了案例研究，评估了PromptCARE在大型商业模型上的性能。

### 5. 本文实验

实验在六个下游任务数据集上进行，涵盖了BERT、RoBERTa和Facebook OPT-1.3b三种预训练LLMs。实验结果表明，PromptCARE在保持提示正常功能的同时，能够有效地检测到未经授权的提示使用。

### 6. 实验结论

PromptCARE在各种设置下都表现出了良好的性能，包括在不同大小的提示、不同预训练模型以及在大型商业模型LLaMA上。实验结果证明了PromptCARE在保护提示版权方面的有效性和实用性。

### 7. 全文结论

本文针对提示版权保护的需求，提出了PromptCARE框架，这是一个创新的解决方案，能够有效地保护提示免受未经授权的使用。通过在多个数据集和模型上的实验，PromptCARE展示了其在实际应用中的潜力，为未来在这一领域的研究提供了新的方向。



注1：

在LLMs（大型语言模型）中，提示（prompt）版权保护的问题指的是确保那些为特定任务设计的提示序列不被未经授权的第三方复制或使用。提示是一种有效的技术，它通过在用户查询前添加一系列特定的文本（即提示），来引导预训练的LLMs产生更准确的输出。这些提示通常需要专业知识和资源来设计，因此具有商业价值。

本文要解决的问题是如何保护这些提示不被未经授权的服务提供商复制和使用。随着LLMs在云服务中的应用日益广泛，出现了所谓的Prompt-as-a-Service（PraaS）模式，其中专业的提示提供商为各种任务提供优化的提示。然而，如果没有适当的版权保护措施，这些提示可能会被竞争对手非法复制和使用，从而损害原始提示开发者的经济利益和知识产权。

PromptCARE框架通过在提示中注入水印来解决这个问题。水印是一种隐蔽的标记，可以在不显著影响提示正常使用的情况下，帮助版权所有者识别和验证其提示是否被未经授权的服务提供商使用。这样，即使提示被非法复制，版权所有者也能够检测到这种侵权行为，并采取相应的法律行动。



注2：

PromptCARE框架旨在通过在提示（prompts）中注入水印来解决LLMs中提示版权保护的问题。这个框架的核心思想是在提示中嵌入一种独特的、可检测的标记（水印），以便在后续的使用中能够验证提示的版权。以下是PromptCARE框架的主要步骤和特点：

1. **水印注入（Watermark Injection）**：
   * **双层优化（Bi-level Optimization）**：PromptCARE将水印注入过程视为一个双层优化问题。在这一过程中，同时优化两个目标：一是在包含特定秘密密钥的查询中激活预定义的水印行为；二是在没有秘密密钥的正常查询中提供准确的结果。
   * **信号标记（Signal Tokens）**：为了在低熵提示中注入水印，PromptCARE选择与下游任务相关的标记作为信号标记。这些信号标记在预训练LLMs的输出中具有较高的概率，从而更容易被模型生成。
   * **触发器（Triggers）**：在验证阶段，通过在查询中嵌入特定的触发器（秘密密钥），可以激活水印行为。这些触发器在注入水印时被优化，以便在验证时能够被识别。
2. **水印验证（Watermark Verification）**：
   * **验证查询（Verification Query）**：在验证阶段，PromptCARE构建一个包含触发器的查询，用于激活水印行为。然后，将这个查询发送给疑似侵权的LLM服务提供商，并收集其返回的预测标记。
   * **统计测试（Statistical Testing）**：通过双样本t检验来比较从合法和疑似侵权服务中获得的预测标记序列的分布。如果两个分布显著不同，那么可以认为疑似服务使用了带有水印的提示。
3. **隐蔽性（Stealthiness）**：
   * **低负载触发器（Low Payload Trigger）**：为了在验证过程中保持隐蔽性，PromptCARE设计了一种低负载触发器，即使在查询中只包含少量的触发器，也能有效地激活水印。
   * **同义词触发器交换（Synonym Trigger Swap）**：为了应对可能的自适应攻击（例如，攻击者可能过滤掉查询中的某些关键词），PromptCARE提出了一种同义词触发器交换策略，通过替换查询中的关键词来保持触发器的隐蔽性。

PromptCARE框架通过这些步骤和特点，为提示版权保护提供了一种有效的方法。它不仅能够在不显著影响模型性能的情况下注入水印，而且能够在后续的使用中准确地检测到未经授权的提示使用。这种方法为LLMs的版权保护提供了新的解决方案，有助于保护提示开发者的知识产权。



注3：

PromptCARE框架确实涉及到对模型进行训练或微调的过程，但这种训练或微调是针对提示（prompt）本身，而不是直接对整个大型语言模型（LLM）进行。具体来说，PromptCARE框架中的水印注入和验证过程包括以下几个方面：

1. **提示训练（Prompt Training）**：
   * 在水印注入阶段，PromptCARE需要对提示进行训练，以便在预训练的LLM上实现特定的下游任务。这个过程涉及到优化提示序列，使其能够引导模型产生期望的输出。
   * 对于连续提示（continuous prompts），这可能涉及到在模型的嵌入层注入可训练的张量（tensors）。
   * 对于离散提示（discrete prompts），这可能涉及到选择和优化一系列离散的标记（tokens）。
2. **水印注入（Watermark Injection）**：
   * PromptCARE将水印注入过程视为双层优化问题。在这一过程中，需要训练一个触发器（trigger），它能够在包含秘密密钥的查询中激活水印行为。
   * 这个过程可能涉及到对模型进行额外的训练步骤，以确保在特定条件下模型能够产生包含水印的输出。
3. **水印验证（Watermark Verification）**：
   * 在验证阶段，PromptCARE不需要对模型进行额外的训练。相反，它使用已经训练好的模型和提示来检测水印。这涉及到构建特定的查询，这些查询包含用于激活水印的触发器，并收集模型的预测输出。

总的来说，PromptCARE框架中的训练或微调主要是为了优化提示和水印的注入，而不是为了改变LLM的基本结构或参数。这种训练通常是在模型的预训练基础上进行的，目的是在不损害模型原有性能的前提下，增强模型输出的版权保护能力。





### 阅读总结

本文针对LLMs中提示版权保护的问题，提出了PromptCARE框架，这是一个创新的水印注入和验证方法。通过在多个数据集和模型上的实验，PromptCARE证明了其在保护提示版权方面的有效性。这一研究不仅填补了现有研究的空白，也为LLMs的版权保护提供了新的视角和工具。
