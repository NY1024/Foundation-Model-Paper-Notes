# SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Mode

<figure><img src="../.gitbook/assets/image (255).png" alt=""><figcaption></figcaption></figure>

1. **研究背景：** 近年来，大型语言模型（LLMs）的安全性问题引起了广泛关注。研究人员和实践者为了评估和提高LLMs的安全性，创建了大量的新数据集。然而，这些工作往往目标各异，从减轻短期偏见和有害内容生成的风险，到评估长期潜在的灾难性风险。这使得研究人员和实践者难以找到针对特定用例的最相关数据集，并识别数据集覆盖范围的空白，以便未来的工作能够填补。
2. **过去方案和缺点：** 过去的研究在创建安全数据集方面采取了多种方法，但这些方法往往缺乏统一的定义和标准化。此外，数据集的创建和使用分散在不同的研究领域和目标之间，导致难以追踪和比较不同数据集的质量和适用性。此外，现有的数据集大多集中在英语内容上，对非英语语言的支持不足。
3. **本文方案和步骤：** 本文通过进行首次系统性回顾来解决上述问题，回顾了用于评估和提高LLMs安全性的开放数据集。作者通过迭代和社区驱动的过程，在几个月的时间里识别了102个数据集。本文从多个关键维度（如目的、创建、格式和大小、访问和许可、发布等）对这些数据集进行了审查。
4. **本文创新点与贡献：** 本文的主要创新点在于提供了一个全面的、系统性的数据集回顾，这在LLMs安全性领域是首次。此外，作者创建了SafetyPrompts.com，这是一个活跃的开放数据集目录，承诺随着LLMs安全性领域的发展不断更新。这为研究人员和实践者提供了一个宝贵的资源，帮助他们更好地理解和利用现有的安全数据集。
5. **本文实验：** 本文没有进行传统意义上的实验，而是通过文献回顾和社区反馈来识别和分析数据集。作者使用了迭代和社区驱动的方法来收集数据集，并记录了每个数据集的23个结构化信息点。
6. **实验结论：** 实验发现，数据集创建的速度前所未有，主要由学术和非营利组织推动。数据集趋向于更专业的安全评估和使用合成数据。此外，英语在数据集中占据主导地位，而非英语数据集明显缺乏。
7. **全文结论：** 本文的结论是，对LLMs安全性的日益关注推动了更多和更多样化的开放安全数据集的创建。当前的评估实践高度特异化，只利用了可用数据集的一小部分。作者认为，通过更好地利用最近在安全数据集创建方面的进步，可以改进评估实践，并为未来的数据集开发提供坚实的基础。

注1：

本文提出并回顾的数据集具有以下特点：

1. **多样性**: 数据集覆盖了多种不同的安全性方面，包括偏见、有害内容生成、权力追求、阿谀行为等。这种多样性反映了LLMs安全性概念的多面性和上下文依赖性。
2. **增长迅速**: 数据集的创建速度前所未有，特别是在2023年，有大量的数据集被发布。这表明了LLMs安全性领域的研究和实践正在迅速发展。
3. **专业化评估**: 近年来，数据集趋向于更专业的安全评估，例如针对特定安全问题的评估，如遵循规则的能力或隐私推理能力。
4. **合成数据的使用**: 有越来越多的数据集完全由机器生成，这些数据集通常使用LLMs（如GPT-3.5）来生成提示、句子或多项选择题。
5. **英语主导**: 在回顾的数据集中，英语占据了主导地位，有88个数据集（占86.3%）只包含英语条目。这反映了当前安全数据集在语言多样性方面的不足。
6. **访问和许可**: 大多数数据集都通过GitHub和/或Hugging Face平台共享，且使用许可证大多是宽松的，如MIT许可证。这有助于促进数据集的广泛使用和进一步的研究。
7. **学术和非营利组织的驱动**: 绝大多数开放LLMs安全数据集的创建和发布是由学术和非营利组织推动的，这表明了这些组织在推动LLMs安全性研究方面的重要性。
8. **社区驱动的方法**: 本文使用的方法是迭代和社区驱动的，这意味着它依赖于社区的反馈和建议来识别和审查数据集，从而确保了回顾的全面性和时效性。

这些特点不仅揭示了当前LLMs安全数据集的现状，也为未来的研究提供了方向，特别是在非英语语言数据集的创建和标准化评估实践方面。



注2：

本文提出了一系列有价值的结论，主要包括：

1. **数据集增长迅速**：LLMs安全性领域的数据集创建正在以前所未有的速度增长，特别是在2023年，有大量的数据集被发布。这表明了该领域研究的活跃度和对LLMs安全性问题的关注正在增加。
2. **专业化评估的趋势**：数据集趋向于更专业的安全评估，这包括对LLMs在特定方面（如遵循规则、隐私推理等）的安全性进行评估。这种专业化有助于更精确地识别和解决问题。
3. **合成数据的兴起**：近年来发布的数据集中，有相当一部分完全由LLMs生成，这种合成数据的使用可能会提高评估的效率和相关性。
4. **英语数据集的主导地位**：大多数数据集都使用英语，这可能限制了对非英语环境下LLMs安全性的评估和理解。这表明需要更多非英语数据集来提高全球范围内的适用性和多样性。
5. **宽松的许可政策**：大多数数据集采用宽松的许可协议，如MIT许可证，这有助于促进数据集的共享和再利用，从而推动社区的协作和创新。
6. **学术和非营利组织的重要作用**：这些组织是推动LLMs安全数据集创建和发布的主要力量。这强调了学术界和非营利部门在解决LLMs安全性问题中的关键角色。
7. **评估实践的个性化**：当前的LLMs安全性评估实践高度个性化，且只利用了可用数据集的一小部分。这表明存在标准化评估实践和更全面利用现有数据集的潜力。
8. **SafetyPrompts.com的贡献**：作者创建的SafetyPrompts.com是一个活跃的开放数据集目录，它为研究人员和实践者提供了一个宝贵的资源，帮助他们跟踪最新的数据集，并促进了LLMs安全性领域的协作和发展。

这些结论不仅为LLMs安全性领域的当前状态提供了全面的视角，也为未来的研究方向和实践提供了指导。特别是，它们强调了需要更多的非英语数据集、更专业的评估方法和标准化的评估实践，以进一步提高LLMs的安全性。





**阅读总结报告：** 本篇论文《SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety》由Paul Röttger等人撰写，旨在通过系统性回顾来解决大型语言模型安全性评估和改进的数据集问题。研究背景强调了LLMs安全性问题的重要性和当前研究的分散性。过去的方案存在缺乏统一定义和标准化的问题，本文通过提供一个全面的回顾和社区驱动的方法来解决这些问题。本文的创新之处在于创建了SafetyPrompts.com，这是一个活跃的数据集目录，有助于标准化和改进LLMs安全性评估。通过分析102个数据集，本文揭示了数据集创建的快速增长、专业安全评估的趋势以及英语数据集的主导地位。实验结论指出了当前评估实践的特异化和对新数据集的利用不足。全文结论强调了对LLMs安全性的持续关注和对现有安全数据集的更好利用的必要性。这篇论文为LLMs安全性领域的研究人员和实践者提供了宝贵的见解和资源。
