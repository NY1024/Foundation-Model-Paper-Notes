# TRUSTWORTHY LARGE MODELS IN VISION: A SURVEY

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着大型模型（LMs）在自然语言处理（NLP）和计算机视觉（CV）等领域的显著进展，它们在性能上的提升引起了广泛关注。然而，LMs在可信度方面面临挑战，因为它们的不可靠行为可能导致严重问题。尽管在NLP领域对可信LMs的研究已经相当丰富，但在CV领域，特别是针对LMs的可信度问题，尚缺乏系统的调查。

### 2. 过去方案和缺点

以往的研究主要集中在提高LMs在评估指标上的性能，如准确性，而忽视了模型的可信度问题。这导致了LMs在实际应用中可能产生误导性内容、侵犯隐私、存在偏见等问题，这些问题不仅对人类社会构成风险，也降低了人们对LMs的信任。

<figure><img src="../.gitbook/assets/image (3) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一个系统性的调查，总结了阻碍LMs在视觉领域可信使用的四个相关问题：人类滥用、脆弱性、固有问题和可解释性。通过强调每个主题的挑战、对策和讨论，本文旨在促进读者对这一领域的理解，并推动LMs与人类期望的一致性，使可信的LMs能够为人类社会带来福祉而非灾难。

### 4. 本文创新点与贡献

* 本文是首次系统性地回顾了视觉领域中LMs的可信度问题，包括深度伪造、不适宜内容、数据投毒攻击、后门攻击、对抗性攻击、版权、隐私、偏见、幻觉和可解释性等方面。
* 提供了关于视觉领域可信LMs的最新发展的全面介绍，以帮助读者掌握前沿信息和最新方法。

### 5. 本文实验

本文没有进行实验，而是通过文献综述的方式，对现有的研究进行了系统的总结和分析。

### 6. 实验结论

由于本文是一篇综述性论文，没有实验部分，因此没有实验结论。

### 7. 全文结论

本文强调了在视觉领域建立可信LMs的重要性，并提出了一系列挑战和对策。作者希望这篇综述能够激发未来在视觉领域可信LMs研究方面的更多工作，以促进LMs的健康发展，使其更好地服务于人类社会。

### 阅读总结

本文是对视觉领域中大型模型可信度问题的全面综述。作者指出了LMs在性能提升的同时，也带来了一系列可信度挑战，如人类滥用、模型脆弱性、固有问题和可解释性等。文章通过总结现有研究，提出了相应的挑战、对策和讨论，旨在推动LMs的可信度研究，使其更好地服务于人类社会。这篇综述为研究人员提供了宝贵的资源，有助于理解当前在视觉领域中LMs可信度研究的现状和未来方向。
