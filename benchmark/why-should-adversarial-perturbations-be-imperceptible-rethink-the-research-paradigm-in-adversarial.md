# Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

文本对抗样本在自然语言处理（NLP）的多个子领域中扮演着重要角色，包括安全性、评估、可解释性和数据增强。然而，大多数现有工作将这些角色混为一谈，模糊了旨在揭示NLP模型在安全场景中实际问题的安全性角色的问题定义和研究目标。本文重新思考了文本对抗样本在安全场景中的研究范式。

### 2. 过去方案和缺点

以往的对抗性NLP研究通常没有考虑安全性任务和数据集，而是涉及与安全性无关的任务，如情感分析和自然语言推理。此外，这些研究没有考虑现实世界攻击者的目标，而是做出了不切实际的假设或添加了不必要的限制，例如要求对抗性扰动不可感知。大多数方法效率低下，需要多次查询受害者模型才能生成对抗样本，这在现实世界中不太可能发生。

### 3. 本文方案和步骤

本文首先收集、处理并发布了一个名为Advbench的安全数据集集合，以促进未来的研究。然后，重新定义了文本对抗攻击任务，并调整了不同对抗目标的重点。接着，提出了一种基于启发式规则的简单方法，可以轻松实现实际攻击者的目标，以模拟现实世界的攻击方法。最后，在Advbench上对攻击和防御两方面进行了实验。

### 4. 本文创新点与贡献

* 提供了一个新的安全数据集集合Advbench。
* 重新考虑了攻击者的目标，并重新定义了文本对抗攻击任务。
* 提出了一种简单的攻击方法，能够满足实际攻击者的目标，以模拟现实世界的攻击。
* 在Advbench上进行了全面的实验，证明了所提方法在攻击性能、攻击效率和对抗性意义保持方面的优越性。

### 5. 本文实验

实验在Advbench上进行，评估了NLP社区提出的方法和本文提出的简单方法。实验结果表明，本文的方法在考虑攻击性能和攻击效率时表现出优越性。此外，还考虑了防御方面，并展示了最先进的防御方法无法处理本文提出的简单启发式攻击算法。

### 6. 实验结论

实验结果表明，本文提出的ROCKET方法在攻击性能和攻击效率方面优于现有方法，并且在对抗性意义的保持上也表现良好。这表明在SoadNLP领域的研究范式可能需要从本文的新基准开始。

### 7. 全文结论

本文重新思考了对抗性NLP领域的研究范式，特别是针对安全角色的文本对抗样本。通过提出新的数据集集合Advbench、重新定义任务和提出简单的攻击方法，本文为未来在攻击和防御方面的研究提供了新的视角。实验结果表明，本文的方法在模拟现实世界攻击方面具有更高的实际价值。



注：

ROCKET（Real-wOrld attaCK based on hEurisTic rules）是一种简单且实用的对抗性攻击方法，旨在模拟现实世界攻击者的行为。该方法基于启发式规则，易于实现，且不需要外部知识库或复杂的NLP模型。ROCKET方法的核心思想是通过对原始文本应用一系列简单的文本扰动规则，生成能够欺骗NLP模型的对抗样本。以下是ROCKET方法的详细说明：

#### 启发式扰动规则

ROCKET方法包含以下六种启发式扰动规则：

1. **插入空格（Insert Space）**：在文本中随机插入空格，例如将 "foolish" 变为 "foo lish"。
2. **插入无关字符（Insert Irrelevant）**：在文本中随机插入无关字符，例如将 "foolish" 变为 "foo^lish"。
3. **删除字符（Delete）**：随机删除文本中的字符，例如将 "foolish" 变为 "fooih"。
4. **交换字符（Swap）**：随机交换文本中相邻字符的位置，例如将 "foolish" 变为 "fooilsh"。
5. **替换字符（Substitute）**：随机替换文本中的字符，例如将 "foolish" 变为 "foo1ish"。
6. **添加干扰词（Add Distractor）**：在句子的开头或结尾添加干扰性的词汇，例如在 "fuck peace!" 后添加 "!" 变为 "fuck peace!!"。

#### 搜索算法

ROCKET方法在黑盒设置中应用这些扰动规则，因为只有受害者模型的决策结果可用。搜索算法的步骤如下：

1. **预处理**：首先对原始句子应用规则6（添加干扰词），并过滤掉停用词，得到修改后句子的语义词汇列表L。
2. **迭代扰动**：重复以下过程，直到达到预设的迭代次数或攻击成功：
   * 从L中随机选择一批词汇w。
   * 对w中的每个词重复执行规则1到规则5的随机扰动动作。
   * 查询受害者模型，直到达到预设的查询次数阈值或攻击成功。
   * 将成功扰动的词汇从L中移除。

#### 实施过程

ROCKET方法的实施过程考虑了攻击者可能采取的简单策略，这些策略不需要复杂的技术知识，而是依赖于直观的文本操作。这种方法的设计使得即使是没有NLP背景的攻击者也能够有效地生成对抗样本。

#### 应用场景

ROCKET方法适用于多种安全相关的NLP任务，如虚假信息检测、有害内容识别、垃圾邮件过滤等。它通过模拟现实世界的攻击行为，帮助研究人员评估和提高NLP模型在面对实际威胁时的鲁棒性。

#### 实验结果

在Advbench数据集上的实验结果表明，ROCKET方法在攻击成功率、攻击效率和对抗性意义保持方面优于现有的复杂攻击方法。这证明了ROCKET方法在模拟现实世界攻击方面的有效性和实用性。





### 阅读总结

本文针对现有对抗性NLP研究中存在的问题，提出了新的研究范式和方法。通过构建新的安全数据集Advbench，重新定义了文本对抗攻击任务，并提出了一种简单有效的攻击方法ROCKET。实验结果证明了该方法在实际攻击场景中的有效性和优越性，为对抗性NLP领域的研究提供了新的基准和方向。
