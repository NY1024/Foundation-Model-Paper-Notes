# JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against

<figure><img src="../.gitbook/assets/image (4) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

#### 阅读总结报告

**1. 研究背景**

随着多模态大型语言模型（MLLMs）的快速发展，确保这些模型免受恶意输入的攻击，并与人类价值观保持一致，成为了一个关键挑战。本文探讨了一个重要且尚未被充分研究的问题：成功破解大型语言模型（LLMs）的技术是否同样适用于破解MLLMs。

**2. 过去方案和缺点**

以往的研究主要集中在基于图像的MLLMs破解方法上，这些方法通常关注设计特定图像内容以打破模型的一致性。然而，由于所有MLLMs都包含一个LLM作为其文本编码器，现有研究尚未探索LLMs的文本破解技术是否可转移到MLLMs上。

<figure><img src="../.gitbook/assets/image (5) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

**3. 本文方案和步骤**

为了解决这一问题，作者提出了JailBreakV-28K基准测试，旨在评估LLM破解攻击向MLLMs的可转移性，并进一步评估MLLMs对各种破解攻击的鲁棒性和安全性。具体步骤包括：

* 创建RedTeam-2K数据集，包含2,000个恶意查询。
* 基于RedTeam-2K生成20,000个基于文本的LLM转移破解提示。
* 结合不同类型图像，生成8,000个基于图像的MLLM破解输入。
* 对10个开源MLLMs进行全面评估。

**4. 本文创新点与贡献**

* 提出了JailBreakV-28K基准测试，这是一个全面的测试集，包含28,000个测试案例，覆盖多种对抗性场景。
* 发现文本破解提示能够有效地应用于MLLMs，且与图像输入无关。
* 强调了未来研究需要解决MLLMs对文本和视觉输入的一致性漏洞。

**5. 本文实验**

* 使用JailBreakV-28K数据集对10个开源MLLMs进行了评估。
* 展示了从LLMs转移的破解攻击对MLLMs的高攻击成功率（ASR）。

**6. 实验结论**

* JailBreakV-28K是一个具有挑战性的基准测试，能够显著考验MLLMs的安全性。
* MLLMs在“经济伤害”和“恶意软件”安全策略下的脆弱性最高。
* 文本基破解攻击比基于图像的攻击更有效，且与图像输入类型无关。

**7. 全文结论**

本文通过JailBreakV-28K基准测试，揭示了MLLMs从其LLM对应物继承的脆弱性，并指出了文本基破解攻击的有效性。基于这些发现，作者鼓励社区关注MLLMs的安全性对齐，包括文本和视觉输入。



注：

本文的主要发现和结论包括：

1. **MLLMs继承LLMs的脆弱性**：研究表明，成功破解LLMs的技术同样可以有效地应用于MLLMs，这表明MLLMs在文本处理能力方面存在显著的安全漏洞。
2. **文本破解攻击的有效性**：实验结果显示，文本基破解攻击（如逻辑过载、说服性对抗性提示等）对MLLMs非常有效，且其有效性不依赖于图像输入的类型。这表明MLLMs对文本输入的依赖性比对图像输入的依赖性更强。
3. **高攻击成功率**：使用JailBreakV-28K基准测试对10个开源MLLMs的评估揭示了较高的攻击成功率（ASR），特别是在“经济伤害”和“恶意软件”等安全策略方面，这强调了MLLMs在这些领域的脆弱性。
4. **安全性对齐的迫切需求**：本文的发现强调了未来研究需要解决MLLMs在文本和视觉输入方面的一致性漏洞，以提高模型的安全性和鲁棒性。
5. **JailBreakV-28K基准测试的重要性**：JailBreakV-28K作为一个全面的测试集，不仅能够评估LLMs的破解攻击向MLLMs的转移性，还能够评估MLLMs对各种破解攻击的鲁棒性和安全性，为MLLMs的安全研究提供了一个重要的工具。

综上所述，本文的发现和结论对于理解和改进MLLMs的安全性具有重要意义，并为未来的研究方向提供了明确的指导。



**阅读总结**

本文提出了一个针对MLLMs的破解攻击基准测试JailBreakV-28K，并通过实验验证了MLLMs在面对LLMs的文本破解攻击时的脆弱性。研究表明，即使在不同类型的图像输入下，文本破解攻击依然有效，这强调了对MLLMs进行安全性对齐的重要性。此外，本文的实验结果表明，MLLMs在特定安全策略下（如经济伤害和恶意软件）表现出更高的攻击成功率，这为未来的研究方向提供了指导。作者建议社区应重视MLLMs的文本和视觉输入的安全性，并开发出更强大的防御机制来应对这些挑战。
