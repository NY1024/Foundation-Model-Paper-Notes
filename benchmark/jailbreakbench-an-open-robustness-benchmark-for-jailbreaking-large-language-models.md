# JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

##

### 1. 研究背景

大型语言模型（LLMs）通常被训练以符合人类价值观，从而拒绝生成有害或有毒内容。然而，越来越多的研究表明，即使是性能最好的LLMs也并非对敌意攻击免疫，可以通过所谓的“越狱攻击”（jailbreaking attacks）引出不受欢迎的内容。越狱攻击的评估面临许多挑战，现有的基准测试和评估技术未能充分解决这些问题。主要挑战包括缺乏明确的越狱评估标准、现有工作计算成本和成功率的方式不可比、以及许多工作不可复制，因为它们隐瞒了对抗性提示、涉及闭源代码或依赖不断变化的专有API。

### 2. 过去方案和缺点

过去的越狱攻击主要依赖手工制作的越狱提示，或者通过Reddit和Discord等平台搜集潜在的越狱案例。这些方法耗时且难以复制，因此研究逐渐转向自动化红队流程。然而，现有的评估技术包括人工标记、基于规则的分类器、基于神经网络的分类器和LLM作为评判框架，这些方法之间的差异和不一致导致了多变的结果。

### 3. 本文方案和步骤

本文介绍了JailbreakBench，一个开源的基准测试，旨在跟踪越狱攻击和防御的进展。JailbreakBench包括以下几个组成部分：

* 一个新的越狱数据集JBB-Behaviors，包含100种独特的不当行为。
* 一个不断发展的越狱工件存储库。
* 一个标准化的评估框架，包括清晰的威胁模型、系统提示、聊天模板和评分函数。
* 一个跟踪各种LLMs的攻击和防御性能的排行榜。

### 4. 本文创新点与贡献

JailbreakBench的贡献包括：

* 提供了一个包含100种独特行为的数据集，这些行为被分为与OpenAI使用政策相对应的十个广泛类别。
* 创建了一个包含最新越狱攻击和防御工件的存储库。
* 提供了一个标准化的红队流程，用于评估潜在的越狱，标准化解码参数，并支持本地和基于云的查询。
* 通过严格的人类评估比较了六种常用的越狱分类器，并发现Llama Guard是一个有效的分类器。
* 提供了一个可复制的评估框架，用于评估越狱算法的攻击成功率，并可以用于提交算法的越狱字符串到我们的工件存储库。
* 发起了一个网站，跟踪越狱攻击和防御在各种最新LLMs上的性能。

### 5. 本文实验

本文通过一系列实验来评估JailbreakBench的性能。实验包括使用JBB-Behaviors数据集、越狱工件存储库、红队流程和防御流程来测试不同的越狱攻击和防御策略。实验结果表明，Llama Guard作为越狱评估器是首选，并且无论是开源还是闭源的LLMs仍然容易受到越狱攻击，这些威胁可以通过现有防御得到一定程度的缓解，尽管不能完全消除。

### 6. 实验结论

实验结果表明，JailbreakBench能够有效地跟踪和评估越狱攻击和防御的进展。通过提供标准化的评估框架和公开的越狱工件，JailbreakBench有助于推动LLM越狱领域的研究，并促进更强大防御策略的发展。

### 7. 全文结论

JailbreakBench作为一个开放的基准测试，为评估和比较LLMs对抗越狱攻击的能力提供了一个统一的平台。它通过提供数据集、工件存储库、评估框架和排行榜，促进了越狱攻击和防御策略的研究。随着技术的进步和方法论的发展，JailbreakBench将不断扩展和适应，以反映研究社区的技术进步。

### 阅读总结

本文提出了JailbreakBench，一个针对大型语言模型越狱攻击和防御的开源基准测试。通过引入新的数据集、存储库、评估框架和排行榜，JailbreakBench旨在提供一个标准化和可复制的环境，以促进LLM越狱领域的研究和进步。实验结果表明，JailbreakBench能够有效地跟踪越狱攻击和防御的进展，并有助于发现和评估新的防御策略。这项工作不仅为研究人员提供了一个强大的工具，而且通过公开越狱工件，有助于提高LLMs的整体安全性。
