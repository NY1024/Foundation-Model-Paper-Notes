# Table of contents

* [MM-LLM](README.md)
  * [MM-LLMs: Recent Advances in MultiModal Large Language Models](mm-llm/mm-llms-recent-advances-in-multimodal-large-language-models.md)
  * [Multimodal datasets: misogyny, pornography, and  malignant stereotypes](mm-llm/multimodal-datasets-misogyny-pornography-and-malignant-stereotypes.md)
* [LLM-Attack](llm-attack/README.md)
  * [SHADOW ALIGNMENT: THE EASE OF SUBVERTING  SAFELY-ALIGNED LANGUAGE MODELS](llm-attack/shadow-alignment-the-ease-of-subverting-safely-aligned-language-models.md)
  * [Defending LLMs against Jailbreaking Attacks via Backtranslation](llm-attack/defending-llms-against-jailbreaking-attacks-via-backtranslation.md)
  * [EMULATED DISALIGNMENT: SAFETY ALIGNMENT  FOR LARGE LANGUAGE MODELS MAY BACKFIRE!](llm-attack/emulated-disalignment-safety-alignment-for-large-language-models-may-backfire.md)
  * [ON THE SAFETY OF OPEN-SOURCED LARGE LAN GUAGE MODELS: DOES ALIGNMENT REALLY PREVENT  THEM FROM BEING](llm-attack/on-the-safety-of-open-sourced-large-lan-guage-models-does-alignment-really-prevent-them-from-being.md)
  * [Unveiling the Implicit Toxicity in Large Language Models](llm-attack/unveiling-the-implicit-toxicity-in-large-language-models.md)
* [VLM-Defense](vlm-defense/README.md)
  * [Removing NSFW Concepts from Vision-and-Language Models  for Text-to-Image Retrieval and Generation](vlm-defense/removing-nsfw-concepts-from-vision-and-language-models-for-text-to-image-retrieval-and-generation.md)
  * [Image Safeguarding: Reasoning with Conditional Vision Language Model  and Obfuscating Unsafe Content](vlm-defense/image-safeguarding-reasoning-with-conditional-vision-language-model-and-obfuscating-unsafe-content.md)
  * [Towards Safe Self-Distillation of  Internet-Scale Text-to-Image Diffusion Models](vlm-defense/towards-safe-self-distillation-of-internet-scale-text-to-image-diffusion-models.md)
* [VLM](vlm/README.md)
  * [Scalable Performance Analysis for Vision-Language Models](vlm/scalable-performance-analysis-for-vision-language-models.md)
* [VLM-Attack](vlm-attack/README.md)
  * [Circumventing Concept Erasure Methods For  Text-to-Image Generative Models](vlm-attack/circumventing-concept-erasure-methods-for-text-to-image-generative-models.md)
* [Survey](survey/README.md)
  * [Generative AI Security: Challenges and Countermeasures](survey/generative-ai-security-challenges-and-countermeasures.md)
* [LLM-Defense](llm-defense/README.md)
  * [LANGUAGE MODELS ARE HOMER SIMPSON!](llm-defense/language-models-are-homer-simpson.md)
  * [THE POISON OF ALIGNMENT](llm-defense/the-poison-of-alignment.md)
  * [GAINING WISDOM FROM SETBACKS : ALIGNING  LARGE LANGUAGE MODELS VIA MISTAKE ANALYSIS](llm-defense/gaining-wisdom-from-setbacks-aligning-large-language-models-via-mistake-analysis.md)
* [Forcing Generative Models to Degenerate Ones:  The Power of Data Poisoning Attacks](forcing-generative-models-to-degenerate-ones-the-power-of-data-poisoning-attacks.md)
