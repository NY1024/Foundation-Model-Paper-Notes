# 前言

这本电子书主要是囊括了在调研大模型(Foundation model)安全期间所看的一些论文的阅读笔记与思考，会实时更新，并不是最终版本。

公开出来，也可以方便同仁一起学习、交流、探讨。

受限于一开始对整个领域的认识不够，所以章节划分得有些问题，比如VLM中可以进一步分为text-to-image,以及image-to-text，attack可以进一步分为backdoor/poisoning attack以及adversail attack、jailbreak, prompt injection attack等，还望大家见谅。



注0：我们团队长期招募科研实习生，欢迎联系。募主要面向有志于深造并希望在顶会顶刊上发表研究成果的优秀本科生。对于硕士生和博士生，若有兴趣，请在联系前获得导师的许可。研究方向包括但不限于:

&#x20;    面向（多模态）大模型的攻防算法研究

&#x20;    面向（多模态）大模型的公平性研究

&#x20;    大模型驱动的Agent的安全和隐私研究

&#x20;    大模型驱动的的自动驾驶安全风险研究

注1：本书github网址为[https://github.com/NY1024/Foundation-Model-Paper-Notes](https://github.com/NY1024/Foundation-Model-Paper-Notes)

注2：欢迎关注公众号（![](<.gitbook/assets/image (286).png>)）

注3：本电子书已经不再更新维护，最新阅读笔记在公众号上发布.



应宗浩(yingzonghao\[AT]buaa.edu.cn)

20240401
