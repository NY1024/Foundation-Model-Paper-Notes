# Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision

<figure><img src="../.gitbook/assets/image (3) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

####

**1. 研究背景**

在线用户生成内容游戏（UGCGs）在儿童和青少年中越来越受欢迎，它们提供了社交互动和更具创造性的在线娱乐。然而，这些平台也增加了接触不适宜内容的风险，引发了对儿童和青少年在线安全日益增长的担忧。尽管存在这些担忧，但很少有研究关注社交媒体上不安全UGCGs的非法图像推广问题，这可能会无意中吸引年轻用户。这个问题的挑战在于获取UGCG图像的综合训练数据的难度，以及这些图像的独特性，它们与传统的不安全内容不同。

**2. 过去方案和缺点**

现有的工具，如Google Cloud Vision API、Clarifai和Amazon Rekognition，使用人工智能和机器学习（AI/ML）模型来缓和有害内容。但是，这些工具在防止不安全UGCG图像的非法推广方面的有效性存在疑问。基于AI/ML的系统在识别传统不安全图像方面表现出相当的效力，但在检测用于在线推广UGCGs的不安全图像时，这些系统的效率降低。

**3. 本文方案和步骤**

本文提出了一个名为UGCG-GUARD的系统，旨在帮助社交媒体平台有效识别用于非法推广UGCG的图像。该系统利用最近引入的大规模视觉-语言模型（VLMs），采用零样本领域适应的新颖条件提示策略，以及用于上下文识别的链式思考（CoT）推理。系统的工作流程如下：

* 数据收集与注释：收集和注释用于UGCG推广的图像。
* UGCG-CoT提示：开发基于CoT推理的提示策略，以适应零样本领域。
* VLM基于检测：利用大型VLM运行提示，并解析模型的输出。
* 内容缓和：根据VLM的输出决定帖子是否包含非法推广图像，并进行相应的标记。

**4. 本文创新点与贡献**

* 提供了一个包含2,924张由真实游戏创作者在社交媒体平台上用于不安全UGCG推广的图像的新数据集。
* 对不安全UGCG及其非法推广的新理解，发现大多数推广图像是直接从UGCG中截取的屏幕截图。
* 提出了一个新的框架UGCG-GUARD，用于缓和基于图像的UGCG非法在线推广。
* 对UGCG-GUARD进行了广泛的评估，展示了其在检测此类内容方面的最新平均准确率达到94%。

**5. 本文实验**

作者进行了多项实验来评估UGCG-GUARD的有效性：

* 与现有基线检测器的比较。
* 评估UGCG-GUARD在传统不安全图像到UGCG输入领域的转变中的性能。
* 检查UGCG-GUARD的条件提示的有效性。
* 评估UGCG-GUARD的上下文识别过程的有效性。
* 在来自不同社交媒体平台的未标记样本上运行UGCG-GUARD。
* 研究传统视觉模型在检测不安全UGCG图像方面的局限性。

**6. 实验结论**

实验结果表明，UGCG-GUARD在识别用于非法推广不安全UGCG的图像方面具有出色的性能，平均准确率达到94%，超过了现有的基线检测器。此外，UGCG-GUARD在“现实世界”样本上的表现也证明了其在实际部署中的潜力。

**7. 全文结论**

本文提出了UGCG-GUARD，一个用于检测和缓和不安全UGCG的非法在线推广的框架。通过一系列实验，证明了UGCG-GUARD在识别和缓和这些图像方面的有效性。未来的工作将扩展该框架，以适应缓和游戏中的不安全内容，并探索将工作扩展到虚拟现实（VR）领域的可能性。

**阅读总结**

本文针对在线用户生成内容游戏（UGCGs）的非法推广问题，提出了一个创新的系统UGCG-GUARD。通过收集和分析数据集，作者发现现有的不安全图像检测系统在处理UGCG图像时存在局限性。为此，他们设计了一个新的基于大规模视觉-语言模型的系统，该系统采用条件提示和链式思考推理策略，以零样本领域适应的方式有效地识别和缓和不安全UGCG图像。通过广泛的实验评估，UGCG-GUARD显示出高准确率和召回率，证明了其在现实世界部署中的潜力。作者建议未来的工作可以扩展到其他UGCG平台和VR领域，以提供更全面的安全保护。
