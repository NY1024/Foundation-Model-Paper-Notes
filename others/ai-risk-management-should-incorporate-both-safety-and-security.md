# AI RISK MANAGEMENT SHOULD INCORPORATE BOTH SAFETY AND SECURITY

<figure><img src="../.gitbook/assets/image (3) (1).png" alt=""><figcaption></figcaption></figure>

#### 1. 研究背景

随着人工智能（AI）的快速发展，尤其是大型语言模型（LLMs）的发展，其在多种任务上展现出卓越的性能。然而，这些模型的部署也引发了对其潜在风险的广泛关注，包括可能的误用和AI失败时造成的伤害。因此，AI风险管理成为了一个重要议题，需要同时考虑AI的安全性和安全性。

#### 2. 过去方案和缺点

尽管安全性和安全性是AI风险管理的两个重要方面，但它们在历史上分别独立发展，导致目标和方法上存在差异。安全性通常关注于防止系统可能对外部环境造成的伤害，而安全性则侧重于保护系统本身不受恶意行为者的侵害。然而，这两个领域的具体定义和应用在不同社区间往往缺乏共识，这使得AI风险管理的讨论变得复杂。

#### 3. 本文方案和步骤

本文提倡AI风险管理的相关利益方应该清楚地认识到安全性和安全性的细微差别、协同效应和相互作用，并明确地将两个学科的视角纳入考虑，以制定更有效和全面的风险缓解方法。为了解决这一概念上的挑战，文章引入了一个统一的参考框架，以阐明AI安全性和安全性之间的区别和相互作用。

#### 4. 本文创新点与贡献

* 提出了一个统一的参考框架，以明确AI安全性和安全性的差异和相互作用。
* 强调了在AI风险管理中同时考虑安全性和安全性的重要性，并讨论了它们在风险管理实践中的技术和方法上的冲突。
* 通过分析前沿问题，展示了如何将安全性和安全性的观点结合起来，以实现更全面的AI风险管理。

#### 5. 本文实验

本文没有进行实验性研究，而是通过文献综述和概念分析，提出了对AI风险管理的理解和建议。

#### 6. 实验结论

由于本文没有进行实验，故没有实验结论。

#### 7. 全文结论

文章最后得出结论，AI风险管理必须明确包括安全性和安全性目标，并强调了从不同社区的历史知识和视角中汲取经验的重要性。文章呼吁更明确的考虑这两个目标，以确保更全面地解决风险管理挑战，并促进社区朝着开发更可信的AI模型的方向发展。

#### 阅读总结

本文深入探讨了AI风险管理中安全性和安全性的重要性和相互作用。文章提出了一个统一的框架来明确区分和理解这两个概念，并强调了在制定有效的风险缓解策略时同时考虑这两个方面的重要性。文章还讨论了在实践中如何将安全性和安全性的观点结合起来，以及它们在技术实现上可能存在的冲突。通过这一讨论，文章为AI风险管理领域提供了宝贵的见解和建议。
