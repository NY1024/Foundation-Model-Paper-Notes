# The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Mod

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

##

### 1. 研究背景

本研究探讨了大型语言模型（Large Language Models, LLMs）在不同提示（prompts）下的表现变化。LLMs在多个领域的数据标注任务中被广泛使用，通过简单的提问或“提示”来获取模型的响应。然而，这些提示的构建方式可能会对LLM的最终决策产生显著影响。研究者们希望通过一系列文本分类任务来检验提示的变化是否会改变LLM的输出结果。

### 2. 过去方案和缺点

以往的研究主要集中在LLMs的准确性上，尤其是在计算机科学和社会科学领域的文本数据标注任务中。这些研究通常忽略了LLM对提示变化的敏感性。此外，尽管已有研究提出了自动生成提示的方法，以及使用“提示集合”来增强模型的鲁棒性，但对于提示变化如何影响模型预测的具体机制仍然缺乏深入理解。

### 3. 本文方案和步骤

本文通过一系列实验来探索提示的变化如何影响LLM的预测结果。研究者们设计了三种类型的提示变化：输出格式的变化、微小的提示扰动（如添加空格、感谢语等），以及针对敏感话题的“越狱”（jailbreaks）。实验涵盖了11个文本分类任务，包括情感分析、语法检测、因果关系判断等，并在24种不同的提示变化下进行了测试。

### 4. 本文创新点与贡献

本研究的创新点在于系统地分析了提示的微小变化对LLM预测结果的影响。研究发现，即使是最小的扰动，如在提示末尾添加空格，也可能导致LLM改变其答案。此外，研究还发现，请求以XML格式响应和使用常见的越狱技巧对LLM标注的数据有重大影响。这些发现对于理解和改进LLM的使用具有重要意义。

### 5. 本文实验

实验使用了OpenAI的ChatGPT模型，并设置了温度参数为0以获得确定性输出。实验从2023年12月1日持续到2024年1月3日。研究者们对11个任务进行了测试，并记录了在不同提示变化下的预测结果。

### 6. 实验结论

实验结果表明，提示的变化确实会影响LLM的预测结果。特别是，使用越狱技巧时，模型的预测结果变化最为显著。此外，输出格式的规定也对预测结果有一定影响，尤其是CSV和XML格式。研究还发现，提示的变化与注释者的分歧程度之间存在一定的相关性。

### 7. 全文结论

本文通过实验验证了即使是微小的提示变化也能显著影响LLM的预测结果。这一发现强调了在设计提示时需要谨慎，以确保模型输出的一致性和准确性。同时，研究也为未来如何生成对提示变化具有鲁棒性的LLM提供了方向。

### 阅读总结

本研究深入探讨了大型语言模型对提示变化的敏感性，并揭示了即使是微小的变化也可能对模型的预测结果产生显著影响。这一发现对于理解和改进LLM的使用具有重要意义，特别是在需要高准确性和一致性的应用场景中。研究还指出了当前LLM在处理敏感话题时的局限性，为未来的研究和模型开发提供了宝贵的见解。
