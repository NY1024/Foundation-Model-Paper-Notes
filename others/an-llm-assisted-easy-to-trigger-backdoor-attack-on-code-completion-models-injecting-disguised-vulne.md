# An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulne

<figure><img src="../.gitbook/assets/image (7) (1).png" alt=""><figcaption></figcaption></figure>

### 研究背景

随着大型语言模型（LLMs）在代码补全任务中的应用，它们通过上下文提供建议，极大地提高了软件开发者的生产力。然而，这些模型经常针对特定应用进行微调，因此可能遭受投毒攻击和后门攻击，这些攻击可以隐蔽地改变模型的输出。

### 过去方案和缺点

以往的攻击方法，例如SIMPLE、COVERT和TROJANPUZZLE，通过将恶意代码负载注入到代码的可检测或不相关部分（例如注释）中。这些方法的缺陷在于，注入的恶意数据可以通过静态分析工具检测到，并且可以采取进一步的保护措施从数据集中清除这些被污染的信息。

### 本文方案和步骤

本文提出了CODEBREAKER，一个开创性的LLM辅助后门攻击框架，专门针对代码补全模型。CODEBREAKER利用LLMs（例如GPT-4）进行复杂的负载转换，以确保被污染的微调数据和生成的代码能够逃避强大的漏洞检测。该框架包括以下步骤：

1. **恶意负载设计**：通过LLMs转换易受攻击的代码片段，以绕过静态分析工具。
2. **触发器嵌入和代码上传**：将转换后的代码和触发器嵌入到代码文件中，并上传到公共代码库。
3. **代码补全模型微调**：使用包含被污染数据的数据集对模型进行微调。

### 本文创新点与贡献

* **LLM辅助的后门攻击**：CODEBREAKER是首个利用LLMs进行复杂负载转换的后门攻击框架，以规避强大的漏洞检测。
* **全面的漏洞覆盖**：提供了迄今为止最广泛的漏洞集合进行评估。
* **易于触发**：与需要特定令牌的TROJANPUZZLE不同，CODEBREAKER可以通过任何代码或字符串触发器激活。
* **调整隐蔽性和逃避能力**：提供了一个新颖的框架来根据隐蔽性和逃避性能的权衡调整负载。

<figure><img src="../.gitbook/assets/image (8) (1).png" alt=""><figcaption></figcaption></figure>

### 本文实验

实验包括以下方面：

* **数据集收集**：从GitHub收集了大量Python代码仓库。
* **目标代码补全模型**：使用Salesforce开发的CodeGen系列模型进行评估。
* **攻击设置**：使用特定的数据集对模型进行微调，并在微调过程中引入被污染的数据。
* **攻击成功评估**：通过生成的代码建议来评估攻击是否成功。

### 实验结论

实验结果表明，CODEBREAKER在各种设置下都展现出强大的攻击性能，并且验证了其在现有方法中的优越性。此外，实验还发现，即使在模型大小增加或微调数据集增大的情况下，攻击依然有效。

### 全文结论

CODEBREAKER揭示了机器学习安全和软件安全中的多方面漏洞，强调了对代码补全的更强大的防御措施的迫切需求。通过将恶意负载直接集成到源代码中，并进行最小化的转换，CODEBREAKER挑战了当前的安全措施。



* 提出了CODEBREAKER，首个利用LLMs进行后门攻击的框架。
* 实现了恶意负载的复杂转换，以规避静态和LLM基础的检测。
* 提供了全面的漏洞评估，包括对247个漏洞的分析。

**方法论**：

* 设计了恶意负载转换算法，利用GPT-4进行最小化转换。
* 通过迭代过程，优化负载以提高隐蔽性和逃避能力。
* 实验评估了攻击在不同设置下的有效性。

**实验结果**：

* CODEBREAKER在各种微调设置下均表现出色，攻击成功率高。
* 即使在模型规模扩大或微调数据集增大的情况下，攻击依然有效。

**结论**：CODEBREAKER的成功表明，需要开发更强大的防御措施来保护代码补全模型免受后门攻击。

**未来工作**：探索更有效的防御策略，以及对大型语言模型在安全领域的进一步研究。
