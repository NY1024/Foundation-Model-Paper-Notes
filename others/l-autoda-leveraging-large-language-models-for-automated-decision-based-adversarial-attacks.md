# L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks

<figure><img src="../.gitbook/assets/image (13) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

在机器学习领域，对抗性攻击对模型的鲁棒性和安全性构成了重大挑战。特别是决策基础攻击（decision-based attacks），它们仅需要模型的最终输出作为反馈，而不需要详细的概率或得分，这使得它们在现实世界环境中尤其难以防御。这些攻击对商业平台构成威胁，因为这些平台通常只向用户披露输出标签。自动化对抗性攻击算法的生成是当前研究的热点，尤其是在决策基础攻击中，需要大量的手动努力来开发和完善攻击策略。

### 2. 过去方案和缺点

以往的决策基础攻击策略主要依赖于手动设计的启发式方法，这些方法需要大量的手动干预，并且依赖于人类专家的知识。这些方法的效率低下，且难以产生创新的攻击算法。此外，现有的自动化程序合成方法（AutoDA）虽然在自动化对抗性攻击算法的生成方面取得了进展，但仍然需要开发特定领域的语言和自动化测试基础设施，且依赖于人类专家的输入。

<figure><img src="../.gitbook/assets/image (14) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了L-AutoDA（Large Language Model-based Automated Decision-based Adversarial Attacks），这是一种新的方法，利用大型语言模型（LLMs）的生成能力来自动化设计攻击算法。L-AutoDA通过在进化框架中与LLMs迭代交互，无需太多人工努力即可高效地自动设计出竞争力的攻击算法。该方法在CIFAR-10数据集上进行了验证，展示了与基线方法相比在成功率和计算效率上的显著提升。

### 4. 本文创新点与贡献

* 提出了L-AutoDA框架，这是首次尝试使用LLMs在决策基础对抗性攻击领域中。
* 证明了LLMs在设计对抗性攻击算法方面的优势，包括能够从自然语言提示的交互中生成算法，无需依赖人类专家，以及能够生成比人类设计的更有效的算法。
* 通过实验和分析揭示了生成算法的鲁棒性能，为决策基础对抗性攻击的设计提供了新的见解，并为未来研究设定了先例。

### 5. 本文实验

实验在CIFAR-10数据集上进行，使用ResNet-18分类模型。L-AutoDA框架在20代进化过程中，每代包含10个算法候选。实验结果表明，L-AutoDA生成的算法在成功率和计算效率上均优于基线方法。

### 6. 实验结论

L-AutoDA在生成对抗性攻击算法方面表现出色，尤其是在查询次数较多时，其成功率和生成的对抗性样本的质量均优于现有的手动设计方法。这表明L-AutoDA是一个有效的自动化对抗性攻击算法设计工具。

### 7. 全文结论

本文成功展示了LLMs在自动化设计决策基础对抗性攻击算法方面的创新应用。通过利用AEL框架，不仅简化了算法设计过程，还显著减少了开发有效对抗性攻击所需的时间和专业知识。L-AutoDA框架代表了对抗性机器学习领域的范式转变，展示了LLMs在安全和算法合成领域的巨大潜力。



注1：

L-AutoDA（Large Language Model-based Automated Decision-based Adversarial Attacks）利用大型语言模型（LLMs）的能力来自动化设计对抗性攻击算法，这些算法专门针对视觉模型，如图像分类器。在论文中，作者通过迭代地与LLMs交互，使用进化框架来自动设计能够在视觉模型上执行有效攻击的算法。这种方法不需要详细的模型内部信息，仅依赖于模型的决策输出（即分类标签），使得攻击更加隐蔽和难以防御。通过这种方式，L-AutoDA能够在不依赖人类专家的情况下，生成能够欺骗视觉模型的对抗性图像。



注2：

在论文中，作者提出了L-AutoDA框架，这是一个利用大型语言模型（LLMs）自动化设计决策基础对抗性攻击算法的方法。以下是该方法的关键步骤和原理：

1. **问题定义**：
   * 对抗性攻击的目标是生成对抗性样本，这些样本在经过模型处理后会产生错误的预测结果。
   * 决策基础攻击（decision-based attacks）仅需要模型的最终决策（输出标签）作为反馈，而不需要模型的内部概率分布或其他详细信息。
2. **利用LLMs的生成能力**：
   * LLMs，如GPT-3.5，能够理解和生成自然语言文本。在L-AutoDA框架中，LLMs被用来生成对抗性攻击算法的代码。
   * 通过精心设计的提示（prompts），LLMs可以被引导生成特定的算法片段，这些片段能够生成对抗性样本。
3. **进化框架（AEL）**：
   * L-AutoDA采用了算法进化（Algorithm Evolution, AEL）框架，该框架结合了进化计算（EC）的原则和LLMs的能力。
   * 在AEL框架中，算法的生成、评估、选择、交叉（crossover）、变异（mutation）和种群大小控制等步骤迭代进行，以优化算法的性能。
4. **算法生成**：
   * 初始化：使用LLMs生成初始的算法种群，或者基于现有的算法进行修改。
   * 评估：通过执行算法并测量其生成的对抗性样本与原始输入之间的差异（如ℓ2距离）来评估算法的适应度。
   * 新解生成：通过选择、交叉和变异操作，LLMs生成新的算法变体，以探索更广泛的搜索空间。
5. **算法测试与评估**：
   * 使用专门的测试脚本来评估进化过程中产生的算法的性能。
   * 测试脚本计算算法生成的对抗性图像与原始图像之间的距离，作为算法适应度的度量。
6. **迭代优化**：
   * 通过多代的迭代，LLMs不断优化算法，以生成更有效的对抗性攻击策略。
   * 最终，从进化过程中选择表现最佳的算法作为对抗性攻击的最终策略。
7. **实验验证**：
   * 在CIFAR-10数据集上进行实验，使用ResNet-18模型作为目标分类器。
   * 通过与现有的对抗性攻击方法（如Boundary Attack和HopSkipJump Attack）进行比较，验证L-AutoDA生成的算法的有效性。

通过这种方法，L-AutoDA能够自动化地设计出能够在视觉模型上执行有效攻击的算法，而不需要人类专家的直接参与。这不仅提高了攻击算法设计的效率，还可能发现人类专家难以通过传统方法发现的新攻击策略。





### 阅读总结

本文介绍了一种名为L-AutoDA的新方法，该方法利用大型语言模型（LLMs）来自动化设计决策基础对抗性攻击。这种方法通过与LLMs的迭代交互，能够在不需要大量人工努力的情况下，高效地生成有效的攻击算法。实验结果表明，L-AutoDA在CIFAR-10数据集上的表现优于现有的手动设计方法，这为自动化对抗性攻击算法的设计提供了新的视角，并为未来在这一领域的研究奠定了基础。
