# Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models

<figure><img src="../.gitbook/assets/image (10) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 研究背景

大型语言模型（LLMs）在多种自然语言处理（NLP）应用中表现出色，但它们存在一个严重问题——幻觉（hallucination）。幻觉指的是LLMs生成的回应虽然逻辑上连贯，但事实上不准确或具有误导性。这个问题削弱了LLMs在实际应用中的有效性和鲁棒性，突显了研究检测和减轻LLMs幻觉问题的迫切性。

## 过去方案和缺点

以往的研究主要集中在幻觉检测的后处理技术上，这些方法通常计算成本高且效果有限，因为它们与LLM的推理过程分离。现有的后处理方法往往需要强大的计算资源，并且在没有真实参考的情况下，难以识别输入文本中的幻觉。此外，这些方法在模型能力上存在内在限制，因为它们独立于LLMs的推理过程检测幻觉，无法分析幻觉是如何从头开始在每个LLM中产生的。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 本文方案和步骤

为了克服这些限制，本文提出了一个新颖的无监督训练框架MIND（Modeling INternal states for hallucination Detection），利用LLMs的内部状态进行实时幻觉检测，无需手动注释。MIND框架包括两个步骤：自动训练数据生成和幻觉分类器训练。通过从维基百科自动注释内容，创建定制的训练数据，然后使用多层感知器（MLP）模型进行分类器训练。



本文提出的MIND框架利用大型语言模型（LLMs）的内部状态进行实时幻觉检测的方法主要包括以下几个步骤：

1. **自动训练数据生成**：
   * 从维基百科选取高质量的文章作为数据集，例如WikiText-103。
   * 对每篇文章进行截断，选取文章中第一个句子后的第一个实体作为截断点。
   * 将截断后的文章输入到LLM中，让模型基于这个截断点生成续写文本。
   * 记录LLM在生成续写文本过程中的内部状态，包括上下文化嵌入（contextualized embeddings）、自注意力（self-attentions）和隐藏层激活值（hidden-layer activations）。
   * 将生成的文本与原始文章进行比较，如果生成文本的开头包含了正确的实体，则标记为非幻觉（0）；如果未包含或包含错误实体，则标记为幻觉（1）。
2. **幻觉分类器训练**：
   * 选择Transformer模型中不同层的上下文化嵌入作为特征。
   * 使用多层感知器（MLP）作为分类器，输入是最后一个Transformer层的最后一个token的上下文化嵌入。
   * 训练MLP分类器，输出是一个二元标签，表示LLM在生成特定文本段时是否正在经历幻觉。
   * 使用二元交叉熵损失（Binary Cross-Entropy Loss）作为损失函数来优化分类器。
3. **实时幻觉检测**：
   * 在LLM的推理过程中，实时收集每个token的上下文化嵌入。
   * 将这些上下文化嵌入输入到训练好的幻觉分类器中。
   * 幻觉分类器输出一个概率值，表示LLM输出中存在幻觉的概率。
   * 在实际应用中，如果检测到高幻觉概率，可以触发减轻幻觉的策略，如检索增强生成（retrieval-augmented generation）。

通过这种方法，MIND框架能够实时地在LLM生成文本的过程中检测幻觉，而不需要额外的计算资源或延迟。这种实时检测的能力对于实际应用中的LLMs尤为重要，因为它可以在生成误导性信息之前及时干预和纠正。此外，MIND框架是一个无监督的方法，不需要手动注释数据，这大大降低了训练幻觉检测模型的成本和复杂性。





## 本文创新点与贡献

* 提出了MIND，一个基于LLM内部状态的无监督实时幻觉检测框架。
* 引入了HELM（Hallucination detection Evaluation for multiple LLMs）基准，用于评估多个LLMs的幻觉检测。
* 实验结果表明，MIND在幻觉检测方面优于现有的方法。
* 通过MIND，可以在LLMs的文本生成过程中实时检测幻觉，提高模型的实际应用价值。

## 本文实验

实验使用了六个不同复杂度的开源LLMs，并设计了不同的提示模板进行文本生成。通过人工注释评估LLMs生成内容的真实性，并使用MIND和其他基线方法进行幻觉检测。实验在句子级别和段落级别上进行，并使用AUC和与人工注释相关性的皮尔逊相关系数作为评估指标。

## 实验结论

* MIND在所有六个LLMs中表现出广泛的有效性，验证了基于LLMs上下文化嵌入的幻觉检测方法在不同模型间的有效性。
* MIND在句子和段落级别的幻觉检测中均优于现有的无参考幻觉检测方法，显示出MIND的优越性和无监督训练框架的有效性。
* SelfCheckGPT（SCG）是仅次于MIND的第二好的幻觉检测方法，但在实时幻觉检测场景中的效率较低。

## 全文结论

本文介绍了MIND，一种新颖的无监督方法，利用大型语言模型的内部状态进行实时幻觉检测。MIND的提出为幻觉检测领域带来了显著的进步，简化了检测过程，消除了对注释数据的依赖。未来的工作将集中在整合LLMs的内部状态和它们生成的文本，以提高识别和减轻LLM输出中幻觉的准确性和可靠性。

## 阅读总结报告

本文针对大型语言模型中的幻觉问题，提出了一种新颖的无监督实时幻觉检测方法MIND，并引入了新的评估基准HELM。通过实验验证，MIND在多个LLMs上表现出色，优于现有的幻觉检测方法，特别是在实时检测方面。这表明基于LLM内部状态的检测方法具有广泛的适用性和有效性，为未来在这一领域的研究提供了新的方向和可能性。同时，作者也指出了MIND的局限性，并提出了未来工作的方向，以进一步提高幻觉检测的准确性和鲁棒性。
