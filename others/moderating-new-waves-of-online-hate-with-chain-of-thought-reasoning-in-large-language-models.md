# Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 研究背景

随着互联网的快速发展，网络仇恨言论问题日益严重，对互联网用户的生活产生了负面影响。网络仇恨言论不仅形式多样，而且随着事件的发展不断演变，产生新的仇恨言论浪潮，对现有的内容审核工具提出了挑战。这些工具通常依赖于人工智能和机器学习模型来检测违反在线仇恨言论政策的内容，但它们在应对新浪潮的仇恨言论时效果有限，因为这些新浪潮要求复杂的决策制定过程来确定仇恨内容的存在，并且训练样本的有限可用性阻碍了检测模型的更新。

<figure><img src="../.gitbook/assets/image (2) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 过去方案和缺点

以往的解决方案主要依赖于传统的人工智能和机器学习模型来检测在线仇恨言论。这些方法通常通过人工标注大量数据集来训练模型，然后使用这些模型进行分类任务。然而，这些方法存在两个主要问题：首先，检测新浪潮的在线仇恨言论需要复杂的决策制定，这与AI/ML模型通常处理的传统分类任务大不相同；其次，由于新浪潮的突然发生，可用于模型更新的样本数量有限，导致现有工具难以快速适应新浪潮。



## 本文方案和步骤

本文提出了一个名为HATEGUARD的新颖框架，用于有效调节新的在线仇恨言论浪潮。HATEGUARD采用基于推理的方法，利用最近引入的链式思维（Chain-of-Thought, CoT）提示技术，发挥大型语言模型（LLMs）的能力。HATEGUARD进一步通过自动生成和更新检测提示来实现基于提示的零样本检测，这些提示会根据新浪潮样本中的新贬义词汇和目标自动更新，从而有效应对新的在线仇恨言论浪潮。 HATEGUARD的步骤包括：

1. 收集新浪潮样本。
2. 自动生成和更新检测提示。
3. 使用LLMs进行基于推理的决策制定。
4. 根据LLMs的输出审查内容，标记仇恨内容。

## 本文创新点与贡献

* 提供了一个新的数据集，包含与三个最近观察到的新浪潮相关的推文。
* 通过系统研究揭示了新浪潮的在线仇恨言论的性质，以及现有在线仇恨言论审核工具更新的迫切需要。
* 设计了一个新颖的框架HATEGUARD，用于发现和调节新的在线仇恨言论浪潮。
* 对HATEGUARD进行了多方面和广泛的评估，证明了其在检测新的在线仇恨言论浪潮方面的优越性。

## 本文实验

实验包括：

1. 收集和注释新浪潮数据集。
2. 分析新浪潮的在线仇恨言论的性质。
3. 使用HATEGUARD检测新的在线仇恨言论浪潮。
4. 与现有工具和最先进的模型进行比较评估。

## 实验结论

实验结果表明，HATEGUARD在检测新的在线仇恨言论浪潮方面表现出色，与基线相比，检测准确率提高了8.69%到75.43%。与最先进的模型相比，HATEGUARD的准确率提高了22.22%到83.33%。

## 全文结论

HATEGUARD框架通过利用LLMs的链式思维推理能力，有效地解决了新浪潮在线仇恨言论的检测问题。该框架能够在新浪潮出现时快速适应和更新，减少了仇恨言论的传播，为在线内容审核提供了一种新的有效方法。



注：

链式思维（Chain-of-Thought, CoT）提示技术是一种新兴的方法，它允许大型语言模型（LLMs）通过一系列有逻辑的中间步骤来处理和解决复杂的问题。这种技术的核心在于将一个复杂的问题分解成多个子问题，并通过逐步推理来解决这些子问题，最终得出结论。

在在线仇恨言论检测的背景下，CoT提示技术的应用可以有效地提高模型对仇恨言论的识别能力。这是因为仇恨言论的检测通常涉及到对文本内容的深入理解和复杂的决策过程，这超出了传统分类任务的范畴。CoT提示技术通过以下方式发挥LLMs的能力：

1. **问题分解**：CoT提示将复杂的仇恨言论检测任务分解为一系列更小、更具体的子任务。例如，可以分解为识别目标群体、识别贬义词汇、判断方向性（是否针对特定群体或个人）和判断是否具有煽动性等子任务。
2. **中间步骤推理**：在每个子任务中，LLMs被提示生成中间输出，这些输出作为后续步骤的输入。通过这种方式，模型能够逐步构建对整个问题的深入理解。
3. **上下文理解**：CoT提示允许LLMs在处理每个子任务时考虑到之前步骤的输出和上下文信息，从而更好地理解和评估文本内容。
4. **自动化更新**：HATEGUARD框架利用CoT提示技术，可以自动更新检测提示，以包含新的贬义词汇和目标群体。这意味着模型能够适应新的仇恨言论浪潮，而不需要从头开始训练。
5. **零样本或少样本学习**：CoT提示技术使得LLMs能够在只有少量或没有样本的情况下进行有效的推理。这对于快速适应和检测新出现的仇恨言论浪潮至关重要。

通过这种方式，HATEGUARD框架能够有效地利用LLMs的强大能力，对在线仇恨言论进行精确的检测和调节，即使在数据稀缺或情况迅速变化的情况下也能保持高效和准确。这种方法代表了在线仇恨言论检测领域的一个范式转变，为未来的研究和应用提供了新的方向。



## 阅读总结报告

本研究针对在线仇恨言论的检测问题，提出了一个基于大型语言模型和链式思维推理的新颖框架HATEGUARD。通过自动更新检测提示和零样本学习，HATEGUARD能够有效地应对新的仇恨言论浪潮，减少了对大量训练数据的依赖，并加快了模型部署的速度。实验结果表明，HATEGUARD在检测新的仇恨言论浪潮方面取得了显著的效果，为在线社交平台的内容审核提供了强有力的支持。此外，该框架的提出也为未来相关领域的研究提供了新的思路和方法。
