# SPML: A DSL for Defending Language Models Against Prompt Attacks

<figure><img src="../.gitbook/assets/image (10) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 1. 研究背景

大型语言模型（LLMs）在自然语言应用中发挥了重要作用，特别是在基于指令的设计聊天机器人。然而，部署后的聊天机器人定义是固定的，容易受到恶意用户的攻击，这强调了防止不道德应用和财务损失的必要性。现有的研究探讨了用户提示对基于LLM的聊天机器人的影响，但针对特定应用程序聊天机器人的攻击的实际方法尚未被探索。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 2. 过去方案和缺点

以往的研究主要集中在评估LLMs在遵循系统提示中定义的指令方面的能力。这些研究集中在两个非常具体的用例上：保护作为输入提供的机密关键词，以及确保原始系统提示不被无意中自我披露。然而，这些设置在实际应用中非常不切实际，因为大多数部署的聊天机器人不太可能被赋予保护秘密的责任。此外，过去的文献没有提出一种方法来明确地保护这些攻击，也没有提供一种方式来测试任何聊天机器人定义在攻击基准上的测试。

### 3. 本文方案和步骤

本文提出了系统提示元语言（SPML），这是一种特定领域语言（DSL），用于改进提示并监控输入到基于LLM的聊天机器人。SPML主动检查攻击提示，确保用户输入与聊天机器人定义一致，以防止在LLM骨干上执行恶意操作。此外，SPML通过编程语言能力简化了聊天机器人定义的制作，克服了自然语言设计挑战。本文还介绍了一个开创性的基准测试，包含1.8k个系统提示和20k个用户输入，为聊天机器人定义评估提供了首次语言和基准。

### 4. 本文创新点与贡献

* 提出了SPML，这是第一种用于编写聊天机器人系统提示的语言，能够捕获用户输入中的违规行为。
* 提供了第一个聊天机器人系统提示的基准测试，包括恶意和安全的示例，以评估SPML检测提示注入攻击的能力。
* 实验结果表明，SPML在识别攻击方面超越了GPT-4、GPT-3.5和LLAMA等最先进的LLMs。
* 数据和代码是公开可用的。

### 5. 本文实验

实验在多个数据集上进行，展示了SPML在理解攻击提示方面的熟练程度，超越了现有的模型。实验还包括了对SPML在不同温度值下的性能测试，以及对多层面攻击的处理能力。

### 6. 实验结论

SPML在检测攻击提示方面表现出色，尤其是在处理多层面攻击时。它在不同温度值下的性能保持一致，显示出对随机性的韧性。此外，SPML在误将安全用户输入分类为恶意输入方面的错误率较低。

### 7. 全文结论

SPML为保护LLMs免受提示注入攻击提供了一种有效的解决方案。它通过提供一个中间表示（SPML-IR）来简化聊天机器人定义的创建和攻击检测。尽管SPML在某些情况下可能无法完全防止攻击，但它提供了一种比现有LLMs更安全的方法来处理用户输入。

### 阅读总结报告

本文介绍了SPML，这是一种新的DSL，旨在保护基于LLM的聊天机器人免受恶意用户提示的攻击。SPML通过提供一个中间表示来改进提示的创建和监控，使得聊天机器人的定义更加安全和易于维护。实验结果表明，SPML在检测攻击方面优于现有的LLMs，并且对于多层面攻击具有很好的鲁棒性。尽管SPML在某些情况下可能无法完全防止攻击，但它为LLMs的安全应用提供了一个有价值的工具。
