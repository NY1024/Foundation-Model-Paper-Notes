# Disentangling Perceptions of Offensiveness: Cultural and Moral Correlates

## 研究背景

本研究探讨了对攻击性语言的感知，这是一个主观的、由个体的生活经历和社会文化价值观塑造的概念。近年来，随着社交媒体平台和对话式AI技术（如ChatGPT和Bard）的普及，出现了构建能够大规模检测攻击性语言的AI工具的迫切需求，以确保交流安全。然而，现有的方法将这一任务视为技术挑战，依赖于全球众包劳动力对数据进行标注，而忽略了标注者来源和他们感知反映的价值观。研究认为，文化和心理因素在攻击性认知处理中起着至关重要的作用，这对于构建AI模型至关重要。

## 过去方案和缺点

以往的研究和实践主要集中于开发自然语言处理（NLP）工具来自动化在线内容的审查，但这些传统的NLP方法往往忽略了塑造标注者对何为攻击性内容看法的文化和个体因素。当这些工具被开发作为对话式AI的安全防护措施时，这种疏忽尤为令人担忧，因为这些技术正以前所未有的速度和规模被跨地理文化背景采用。此外，对攻击性内容的分歧不仅仅是社会文化背景的差异，还涉及到自由言论原则与社交媒体内容审查之间的复杂相互作用。

## 本文方案和步骤

本文提出了一种基于大规模跨文化研究的方法，通过4309名来自21个国家、8个文化区域的参与者来重新定义攻击性的判断任务，本质上视为一种道德判断——在隐含的社会文化规范内决定伦理错误与正确的语言边界。研究通过两个主要步骤来实现这一目标：

1. **跨文化语言标注实验**：邀请来自不同文化区域的参与者对社交媒体帖子中的攻击性进行标注，并填写道德关注自评量表。
2. **道德基础理论的应用**：利用道德基础理论（Moral Foundation Theory）来量化和分析个体的道德价值观，并探讨这些价值观如何影响对攻击性的感知。

## 本文创新点与贡献

本研究的创新点在于：

* 强调文化和心理因素在攻击性语言解读中的重要性。
* 通过大规模跨文化研究揭示了文化和道德价值观在攻击性感知中的关键作用。
* 展示了个体道德关注（尤其是关怀和纯洁性）如何显著介导跨文化差异。
* 对于构建多元世界的AI模型提出了重要的见解，强调了在不同地理文化背景下尊重和考虑道德价值观的必要性。

## 本文实验

实验包括两个部分：

1. **实验1**：展示了不同地理文化区域的感知攻击性存在显著差异，并且这些差异在控制了性别、年龄和社会经济地位后仍然存在。
2. **实验2**：发现个体的道德关注（特别是关怀和纯洁性）在跨文化感知攻击性的差异中起到了显著的中介作用。

## 实验结论

实验结果表明，不同文化背景的个体对攻击性语言的感知存在显著差异，这些差异受到个体道德价值观的影响。特别是关怀和纯洁性这两个道德基础在不同文化中的变异是驱动跨文化差异的关键因素。

## 全文结论

研究得出结论，对攻击性语言的感知是由社会文化背景和个体道德判断共同塑造的。当前用于AI模型训练的数据标注实践未能充分考虑这些差异，可能导致生成的模型在不同文化群体中的适用性存在偏差。因此，研究呼吁在数据收集和模型训练中考虑文化因素，以及在AI模型的设计和评估中融入对人类价值的更全面理解。

## 阅读总结报告

本研究通过深入分析和大规模跨文化实验，揭示了对攻击性语言感知的文化和道德基础，强调了在构建AI模型时考虑文化和心理因素的重要性。研究结果不仅对改进现有的NLP工具和AI模型提供了宝贵的见解，也为未来在多元文化背景下进行AI开发和评估提供了新的视角和方法。通过揭示不同文化和个体在道德价值观上的差异如何影响对攻击性内容的判断，本研究为确保AI技术的全球普及和安全使用提供了重要的理论和实践指导。
