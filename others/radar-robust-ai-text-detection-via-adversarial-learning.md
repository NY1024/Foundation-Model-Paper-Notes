# RADAR: Robust AI-Text Detection via Adversarial Learning

<figure><img src="../.gitbook/assets/image (8) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

##

### 1. 研究背景

随着大型语言模型（LLMs）的进步，如ChatGPT等应用的普及，人类与机器生成文本的界限变得模糊。这带来了技术和社会革命性的变革，同时也带来了新的挑战，如伪造内容、抄袭和对无辜作者的虚假指控。现有的AI文本检测器在面对基于LLM的改写时，其鲁棒性不足，这成为了一个亟待解决的问题。

### 2. 过去方案和缺点

现有的AI文本检测方法主要分为三类：统计方法、分类方法和水印方法。这些方法在面对未经改写的AI文本时表现尚可，但在遇到经过改写的文本时，性能显著下降。例如，OpenAI的AI文本检测器在某些挑战性情况下，正确识别AI文本的比例仅为26%，同时错误地将9%的人类文本误判为AI文本。

### 3. 本文方案和步骤

本文提出了一个名为RADAR的新框架，通过对抗性学习共同训练一个鲁棒的AI文本检测器。RADAR基于改写器和检测器的对抗训练。改写器的目标是生成能够逃避AI文本检测的真实内容，而检测器的目标是提高AI文本的可检测性。RADAR使用检测器的反馈来更新改写器，反之亦然。在训练阶段，改写器和检测器的模型参数通过对抗性学习进行迭代更新，直到验证损失稳定。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 4. 本文创新点与贡献

* RADAR是首个利用改写器和检测器之间的对抗学习来训练鲁棒AI文本检测器的研究。
* 实验结果表明，RADAR在8种不同的LLMs和4个数据集上显著优于现有的AI文本检测方法，尤其是在面对改写时。
* RADAR的检测能力具有很强的迁移性，即使用指令调整的LLMs训练得到的检测器也能有效应用于其他LLMs。

### 5. 本文实验

实验在8种不同的LLMs（Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, Vicuna）和4个数据集上进行。实验结果表明，RADAR在原始AI生成文本的检测上表现与现有最佳检测器相当，同时在面对“未见”改写器时，显著提高了AI文本的可检测性。

### 6. 实验结论

RADAR在面对改写文本时，相比于现有方法，显示出显著的改进和可靠的AI文本检测能力。在面对GPT-3.5-Turbo改写器时，RADAR的接收者操作特征曲线（AUROC）得分提高了31.64%，表明了其显著的改进。

### 7. 全文结论

RADAR通过对抗性学习提供了一个鲁棒的AI文本检测框架，能够有效地应对LLM生成的文本，即使在文本经过改写的情况下。RADAR的检测能力在不同的LLMs之间具有良好的迁移性，这为基于最新LLMs训练通用AI文本检测器提供了可能性。

### 阅读总结

本文提出了RADAR框架，这是一个通过对抗性学习训练的鲁棒AI文本检测器。RADAR在多个LLMs和数据集上的实验结果表明，它在检测AI生成文本方面优于现有方法，尤其是在处理改写文本时。RADAR的检测能力还显示出强大的迁移性，这意味着它可以在不同的LLMs之间迁移，为开发通用的AI文本检测器提供了新的思路。尽管RADAR在某些情况下可能无法完全替代现有的最佳检测方法，但它在对抗改写文本方面的显著优势使其成为一个有价值的工具。
