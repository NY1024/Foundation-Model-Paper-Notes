# Defending Against Social Engineering Attacks in the Age of LLMs

<figure><img src="../.gitbook/assets/image (290).png" alt=""><figcaption></figcaption></figure>

###

#### 1. 研究背景

随着大型语言模型（LLMs）的快速发展，它们在生成逼真对话方面的能力显著提高，但同时也带来了数字欺骗检测和缓解的挑战。LLMs能够模拟人类对话模式，可能被用于促进基于聊天的社交工程（CSE）攻击，这类攻击超越了传统的网络钓鱼邮件和网站，对个人和企业构成了威胁。

#### 2. 过去方案和缺点

现有的研究已经开发了理解人与人之间CSE攻击的框架，并探索了使用机器学习和深度学习技术来检测和预防这些威胁。然而，LLMs被滥用来生成和持续CSE攻击的情况尚未被充分探索，这使得我们对这种新出现的风险准备不足。

<figure><img src="broken-reference" alt=""><figcaption></figcaption></figure>

#### 3. 本文方案和步骤

* **数据集开发**：研究者开发了一个新的数据集SEConvo，模拟学术和招聘背景下的CSE场景，以检验LLMs如何在这些情境中被利用。
* **模型评估**：评估了代表性LLMs（如GPT4和Llama2）在零样本和少样本提示设置中检测CSE的性能。
* **方案提出**：提出了ConvoSentinel，这是一个模块化的防御流程，旨在提高消息级和对话级CSE检测的准确性。

#### 4. 本文创新点与贡献

* **SEConvo数据集**：首次为CSE提供了一个由单一LLM模拟和代理间交互组成的数据集，模拟现实场景中的SE攻击和防御。
* **ConvoSentinel**：提出了一个模块化流程，用于对抗多轮CSE。该流程系统地分析多轮CSE对话，标记恶意消息，并整合发现以检测整个对话中的SE尝试。
* **检索增强模块**：ConvoSentinel集成了检索增强生成（RAG）模块，通过与已知CSE交互的数据库比较消息来识别恶意意图。

#### 5. 本文实验

* 对SEConvo数据集进行人类标注，验证数据质量。
* 使用不同的模型对消息级敏感信息（SI）请求进行检测和分类。
* 评估了ConvoSentinel在不同阶段的CSE检测性能。

#### 6. 实验结论

* ConvoSentinel在早期阶段的CSE检测中表现出色，尤其是在对话的前几条消息中。
* ConvoSentinel在整体和恶意F1得分上均优于基线模型，显示出更好的性能和成本效益。

#### 7. 全文结论

本文研究了LLMs在CSE场景中的双重角色——作为CSE威胁的促进者和防御者。尽管现成的LLMs在生成高质量CSE内容方面表现出色，但它们的检测和防御能力不足，容易受到攻击。ConvoSentinel作为一个模块化的防御流程，通过使用检索增强技术来提高恶意意图识别的准确性，提供了更适应性强和成本效益高的解决方案。

#### 总结

本文针对大型语言模型可能被滥用来进行社交工程攻击的问题，提出了一套检测和防御机制。通过创建SEConvo数据集和开发ConvoSentinel模块化防御流程，本文在提高CSE攻击检测准确性方面做出了贡献。实验结果表明，ConvoSentinel能够有效地在早期阶段识别CSE攻击，并且具有较高的成本效益。这项研究为理解和应对LLMs在CSE情境中带来的挑战提供了基础框架，并指出了未来研究的方向。
