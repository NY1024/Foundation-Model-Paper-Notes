# longhorns at DADC 2022: How many linguists does it take to fool a Question Answering model? A system

<figure><img src="../.gitbook/assets/image (154).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

自然语言处理（NLP）系统在标准基准测试中取得了显著的进步，但这些测试可能无法全面反映模型在实际应用中的表现。为了更好地评估和改进NLP系统，研究者们开始探索对抗性攻击方法，即通过人为创造能够“欺骗”模型的示例来测试模型的鲁棒性和理解能力。这种方法可以帮助研究者发现模型的潜在弱点，并为模型的迭代改进提供思路和数据。

### 2. 过去方案和缺点

以往的对抗性攻击研究主要集中在自动化生成对抗性示例，但这些方法往往缺乏系统性和理论指导。此外，自动化方法可能无法充分考虑人类语言的复杂性和多样性，导致生成的对抗性示例在实际应用中的效果有限。

### 3. 本文方案和步骤

本文提出了一种系统化、基于语言学知识的对抗性攻击方法，用于生成能够欺骗提取式问答（QA）模型的示例。研究团队首先列出了一系列可能难以处理的语言学现象和推理能力，然后使用这些现象来创建对抗性示例。在正式提交之前，团队进行了试点实验来评估不同策略的有效性，并选择了最有效的策略用于最终提交。



在本文中，研究团队提出了一种结合语言学知识和系统化方法的对抗性攻击策略，旨在生成能够欺骗提取式问答（QA）模型的高质量对抗性示例。以下是他们所采取的具体步骤和策略：

1. **跨学科团队组成**：
   * 团队由来自语言学、计算机科学、信息学和电气与计算机工程等领域的专家组成，这为策略的制定提供了多学科的视角。
2. **攻击策略的制定**：
   * 团队首先列出了一系列可能对QA模型构成挑战的语言学现象和推理能力，这些包括词汇知识、句法和话语知识、心理语言学中难以处理的构造（如花园路径句子）、复杂的核心指代解析、非语言推理等。
   * 他们基于这些现象制定了一系列的攻击策略，例如利用模型对特定实体类型的偏好、使用对人类处理起来复杂的语言构造、以及要求模型进行数值推理、时间推理等。
3. **试点实验**：
   * 在正式提交之前，团队进行了试点实验来测试和评估不同攻击策略的有效性。他们通过在小规模样本上测量模型错误率（MER）来评估每种策略，并分析了每种攻击可以被使用的次数。
4. **策略选择与优化**：
   * 根据试点实验的结果，团队选择了最有效的攻击策略用于正式提交。他们还利用了模型的偏见，如对语义相似性的偏好和对问题类型的敏感性，来提高对抗性示例的难度。
5. **正式提交**：
   * 在正式提交阶段，团队专注于使用分散注意力的策略、数值推理、时间推理、花园路径问题、复杂核心指代、列表操作和常识推理等策略。
   * 他们还利用模型的偏见来迷惑模型或减少模型依赖启发式方法的能力。
6. **策略实施**：
   * 在实施策略时，团队成员通过共识决策来生成问题，特别是在有多个人参与时，他们发现从不同角度假设模型行为的攻击往往更成功。
7. **结果分析**：
   * 团队分析了模型在不同攻击策略下的表现，发现模型在某些情况下表现出色，这可能是由于模型的启发式方法或任务性质导致的。

通过这种系统化的方法，研究团队不仅成功地生成了对抗性示例，还深入理解了模型的工作原理和潜在局限性。这种方法不仅提高了模型的错误率，还为NLP系统的进一步研究和实践应用提供了宝贵的见解。





### 4. 本文创新点与贡献

* 提出了一种结合语言学知识和系统化方法的对抗性攻击策略，用于生成高质量的对抗性示例。
* 通过试点实验和正式提交，展示了该方法在提高模型错误率（MER）方面的有效性。
* 分析了模型在不同攻击策略下的表现，揭示了模型的潜在偏见和弱点。

### 5. 本文实验

实验包括了对抗性策略的制定、试点实验的执行以及正式提交的准备。试点实验中，团队成员尝试了多种策略，并通过模型错误率来评估每种策略的有效性。正式提交时，团队选择了表现最好的策略，并在DADC 2022的Task 1中取得了第一名的成绩。

### 6. 实验结论

实验结果表明，系统化的方法能够有效地生成对抗性示例，提高模型的错误率。此外，通过分析模型在不同攻击策略下的表现，研究者们能够更好地理解模型的工作原理和潜在局限性。

### 7. 全文结论

本文展示了一种系统化的方法来生成对抗性示例，这对于评估和改进NLP模型具有重要意义。通过结合语言学知识和理论指导，该方法不仅提高了模型的错误率，还为模型的进一步研究和实践应用提供了宝贵的见解。

### 阅读总结

本文通过系统化的方法和语言学知识，成功地生成了能够欺骗QA模型的对抗性示例，并在DADC 2022的竞赛中取得了优异的成绩。这种方法不仅有助于揭示模型的弱点，还能为NLP系统的改进提供理论基础和实践指导。此外，本文的研究还表明，对抗性攻击不仅仅是科学问题，也具有实际应用价值，尤其是在提高模型在复杂语言理解和推理任务中的性能方面。
