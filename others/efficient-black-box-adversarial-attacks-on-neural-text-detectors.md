# Efficient Black-Box Adversarial Attacks on Neural Text Detectors

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

##

### 1. 研究背景

随着神经文本生成模型（如ChatGPT）的普及，对于能够检测文本是否由人工智能生成的神经文本检测器的需求也在增加。这些检测器在教育等领域的应用引发了对其鲁棒性的质疑，尤其是在对抗性攻击方面。对抗性攻击利用机器学习模型通过识别数据中的模式而非理解实际概念的弱点，通过引入微小的、人类难以察觉的扰动导致误分类。

### 2. 过去方案和缺点

现有的对抗性攻击研究主要集中在图像检测上，文本输入由于其离散性质和引入人类不可感知扰动的难度较大。对于文本分类模型的对抗性攻击，已有研究如Ebrahimi等人和Gao等人的工作。最近的研究开始关注神经文本检测器的对抗性攻击，例如Wolff和Wolff展示了通过引入拼写错误和使用同形异义字符可以显著降低GPT-2文本的检测率。Liang等人展示了类似的基于字符级变异的攻击对基于RoBERTa的检测模型也有效。然而，现有的检测器对简单改写很脆弱，并且倾向于标记非母语者手动编写的文本为AI生成。

### 3. 本文方案和步骤

本文研究了三种简单且资源高效的策略（参数调整、提示工程和字符级变异）来改变由GPT-3.5生成的文本，这些改变对人类来说不明显，但会导致神经文本检测器误分类。这些策略在黑盒场景中进行测试，基于GPT 3.5生成的文本和三种神经文本检测器：广泛使用的开源GPT-2输出检测器模型、OpenAI文本分类器和商业Turnitin AI检测器。



本论文提出了三种针对神经文本检测器的有效攻击策略，这些策略旨在修改由GPT-3.5生成的文本，使其对人类来说不易察觉，但能够导致检测器误分类。以下是这三种策略的详细说明：

#### 1. 参数调整 (Parameter Tweaking)

这一策略涉及调整GPT-3.5文本生成过程中的参数，以改变生成文本的特性。研究中特别关注了以下参数：

* **温度 (Temperature)**：控制输出的随机性。增加温度会使输出更加随机，但超过默认值1.0会导致输出长度波动和文本质量下降。
* **Top p**：基于概率质量选择的标记百分比。这个参数决定了生成文本的多样性。
* **频率惩罚 (Frequency Penalty)**：控制文本中标记出现的频率。增加频率惩罚会导致文本更加多样化，但超过1.0会迅速降低文本质量。
* **存在惩罚 (Presence Penalty)**：控制模型重复标记的可能性。增加存在惩罚会使文本更加多样化。

实验发现，适当增加频率惩罚和存在惩罚可以显著降低检测率，同时保持文本的质量和可读性。这些参数的调整在不牺牲文本质量的前提下，有效地降低了检测器的检测能力。

#### 2. 提示工程 (Prompt Engineering)

这一策略通过改变生成文本时使用的提示（prompt）来影响检测器的检测结果。研究者测试了以下类型的提示：

* **标准提示 (Standard Prompt)**：直接要求GPT-3.5生成文本。
* **再生提示 (Regeneration Prompt)**：在标准提示后添加“重新生成文章”的请求。
* **高级提示 (Advanced Prompt)**：提供更详细的指令，要求GPT-3.5生成具有特定风格和结构的文本。
* **增加文本的复杂性和多样性的提示**：要求GPT-3.5生成具有高复杂性和多样性的文本，以模仿人类写作风格。

实验结果显示，通过适当的提示工程，可以降低检测器的检测率，尤其是当使用两个分开的提示来增加文本的复杂性和多样性时。

#### 3. 字符级变异 (Character-level Mutations)

这一策略涉及对生成的文本进行字符级别的微小修改，这些修改对人类读者来说几乎不可察觉，但可能会影响检测器的判断。研究中测试了以下类型的字符级变异：

* **替换拉丁字母**：将拉丁小写字母“a”或“e”替换为相应的西里尔字母。
* **替换大写字母**：将拉丁小写字母“L”替换为大写的“I”。

实验结果表明，这些字符级变异对GPT-2检测器非常有效，能够显著降低其检测分数。对于OpenAI分类器，所有攻击都降低了检测分数，但效果不如GPT-2检测器明显。Turnitin检测器能够识别出拉丁字符与西里尔字符的替换，但对于将小写“L”替换为大写“I”的变异则未能检测出来。

### 总结

这三种策略展示了在黑盒场景下，即使在资源有限的情况下，也能够有效地对抗现有的神经文本检测器。这些发现强调了提高检测器鲁棒性的重要性，并为未来研究提供了新的攻击和防御策略。





### 4. 本文创新点与贡献

* 提出了在黑盒场景下对神经文本检测器进行有效且资源高效的通用攻击策略。
* 证明了通过参数调整和字符级变异，可以显著降低检测器的检测率，同时保持文本质量。
* 通过提示工程，展示了如何通过改变生成提示来影响检测器的检测率。

### 5. 本文实验

实验结果表明，特别是参数调整和字符级变异是有效的策略。例如，通过增加频率惩罚和存在惩罚，可以显著降低所有三种检测器的检测率。此外，对于GPT-2检测器，通过增加文本的复杂性和多样性，可以进一步降低检测率。

### 6. 实验结论

实验结果表明，目前可用的神经文本检测器不能可靠地检测由最先进的大型语言模型（LLMs）生成的文本，并且容易受到对抗性攻击的影响。

### 7. 全文结论

本研究探索了针对神经文本检测器的资源高效的对抗性攻击的有效性，基于GPT-3.5生成的文本和三种检测器。研究结果表明，通过调整生成模型的参数和应用字符级变异，可以成功地降低检测器的检测率，同时保持文本的可读性和质量。这些发现强调了当前检测器的脆弱性，并为未来提高检测器鲁棒性的研究方向提供了指导。

### 阅读总结

本文针对神经文本检测器的对抗性攻击进行了研究，提出了三种有效的攻击策略，并在黑盒场景下对三种不同的检测器进行了测试。实验结果表明，这些策略能够有效地降低检测器的检测率，表明现有的检测器在面对对抗性攻击时存在显著的脆弱性。这些发现对于理解和改进神经文本检测器的鲁棒性具有重要意义。
