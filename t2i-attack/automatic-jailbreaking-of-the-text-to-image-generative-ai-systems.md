# Automatic Jailbreaking of the Text-to-Image Generative AI Systems

<figure><img src="../.gitbook/assets/image (10) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

#### 研究背景

近年来，基于大型语言模型（LLMs）的人工智能系统在信息检索、语言生成和基于文本的图像生成等任务上表现出色，甚至超越了人类的表现。然而，这些系统存在多种安全隐患，例如通过绕过LLMs中的对齐机制（即所谓的“越狱”）生成恶意内容。尽管已有研究关注LLMs的文本越狱问题，但文本到图像（T2I）生成系统的越狱问题相对较少被关注。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

#### 过去方案和缺点

以往的工作主要集中在基于文本的LLMs越狱问题上，而对T2I生成系统的越狱问题研究不足。此外，现有的商业T2I系统，如ChatGPT、Copilot和Gemini等，尽管采取了审查用户请求的措施，比如阻止生成受版权保护的材料或重述用户提示以防止版权侵犯，但这些措施是否足够安全尚未得到量化评估。

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

#### 本文方案和步骤

本文首先评估了商业T2I生成系统在版权侵犯方面的安全性，使用简单的提示对这些系统进行了实证研究。研究发现，Copilot和Gemini仅分别阻止了12%和17%的攻击，而ChatGPT阻止了84%的攻击。然后，本文提出了一个更强大的自动化越狱管道，用于生成绕过这些系统安全防护的提示。该自动化越狱框架利用LLM优化器生成提示，以最大化生成图像的违规程度，而无需任何权重更新或梯度计算。



#### 本文方案详细说明

**方案概述**

本文提出的方案旨在评估和破解商业文本到图像（T2I）生成系统的版权安全防护。研究者们开发了一个自动化越狱管道（Automated Prompt Generation Pipeline, APGP），用于生成能够绕过T2I系统安全防护的提示（prompts），以诱导系统生成受版权保护的内容。

**方案步骤**

1. **版权违规数据集构建（VioT）**:
   * 研究者们创建了一个包含五种受版权保护内容类型的数据集，包括角色、标志、产品、艺术和建筑。
   * 为每种类型的版权内容，收集了20个图像样本，并为每个图像指定了关键词。
2. **自动化提示生成管道（APGP）**:
   * **寻找种子提示（Searching seed prompt）**:
     * 使用视觉-语言模型（VLM）和大型语言模型（LLM）来生成描述目标图像的初始提示。
     * 利用CLIP模型的嵌入向量和余弦相似度来评估提示与目标图像的一致性。
   * **提示优化（Optimizing prompt）**:
     * 根据自生成的QA得分和关键词惩罚来优化提示。
     * 引入了关键词惩罚机制，以避免使用直接与版权内容相关的特定关键词。
     * 引入了自生成的QA得分，以确保提示的描述性并减少过于泛化的描述。
   * **后处理（Post-processing）**:
     * 通过添加后缀提示来进一步促使T2I系统生成版权侵犯的图像。
     * 包括关键词抑制后缀和意图添加后缀，以误导模型认为用户意图是创建原创作品。
3. **版权侵犯评估**:
   * 使用APGP生成的提示对商业T2I系统进行测试，包括ChatGPT、Copilot和Gemini。
   * 记录系统阻止生成的比率，并收集生成的图像以进行后续评估。
4. **防御策略探索**:
   * 研究者们探索了包括生成后过滤和机器去学习技术在内的不同防御策略。
   * 评估这些策略在对抗APGP生成的提示时的有效性。

**方案创新点**

* **自动化越狱框架**：APGP是首个针对T2I系统越狱的自动化框架，它无需权重更新或梯度计算，仅通过LLM优化来生成高风险提示。
* **自生成QA得分**：引入了一个新颖的评分机制，通过自生成的问题和答案对来评估提示的质量，从而优化LLM生成的提示。
* **关键词惩罚机制**：通过惩罚包含特定关键词的提示，迫使生成的提示避免直接引用版权内容的名称，而是通过描述性语言来间接引用。

**方案贡献**

* 提供了一种新的方法来评估和破解商业T2I系统的版权安全防护。
* 构建了VioT数据集，为未来在这一领域的研究提供了基础。
* 展示了现有商业T2I系统在版权保护方面的不足，并提出了改进建议。

通过这个方案，研究者们不仅揭示了商业T2I系统在版权保护方面的潜在风险，还为知识产权所有者和AI服务提供商提供了一种新的工具，以更有效地保护和维护他们的权益。



#### 本文实验

实验结果显示，使用APGP生成的提示，ChatGPT的阻止率仅为11.0%，在76%的情况下生成了版权内容。此外，本文还探索了各种防御策略，例如生成后过滤和机器去学习方法，但发现它们是不足够的，这表明需要更强的防御机制。

#### 实验结论

商业T2I系统在版权侵犯方面的风险被低估了，即使使用简单的提示，越狱也是可能的。尽管一些系统实施了内部审查机制来防止这类侵权行为，但APGP能够轻易绕过这些安全措施。

#### 全文结论

文章最后指出，商业T2I系统目前对版权侵犯的风险估计不足，即使面对简单的提示，它们的内部审查机制也可能被绕过。APGP通过结合自生成的QA得分和关键字惩罚，展示了在不进行权重更新或梯度计算的情况下，如何有效地生成高风险提示。

#### 阅读总结报告

这篇论文深入探讨了商业T2I系统的版权侵犯风险，并提出了一个自动化的越狱框架来评估和绕过这些系统的安全防护。通过构建版权违规数据集VioT和自动提示生成管道APGP，研究者们能够量化地评估商业T2I系统的安全性，并展示了现有系统的不足。实验结果表明，即使是被认为相对安全的ChatGPT，在面对精心设计的提示时，也存在版权侵犯的风险。这项工作不仅为商业公司提供了重新考虑其系统法律和道德视角的机会，也为知识产权所有者提供了更有效地主张权利的工具。此外，论文还指出了其方法的局限性，包括由于商业T2I系统的非确定性导致的版权内容生成的随机性，以及可能随系统更新而变化的结果。最后，论文强调了承认这些问题并探索增强现实世界AI应用安全性的重要性。
