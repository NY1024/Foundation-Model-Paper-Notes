# THE POISON OF ALIGNMENT

<figure><img src="../.gitbook/assets/image (209).png" alt=""><figcaption></figcaption></figure>

### 研究背景

随着大型语言模型（LLMs）的发展，它们在复杂基准测试（如Human Eval和Big Bench）和专业考试（如SAT、GRE和LSAT）中展现出了令人印象深刻的能力。然而，尽管LLMs的性能在近年来有所提升，但它们在专业考试或复杂基准测试中的表现仍未达到人类最佳水平。此外，知识蒸馏模型（如Vicuna、Alpaca和Orca）声称其性能与ChatGPT相当，但有研究表明这些模型主要模仿对话格式，而非提升推理能力或事实准确性。

### 过去方案和缺点

过去的研究集中在通过监督式微调（Supervised Fine-Tuning, SFT）来提升LLMs的性能。然而，Gudibande等人的研究表明，现有的蒸馏模型在SFT过程中并未显示出超过基础LLMs的性能提升。此外，数据质量比数据量更为重要，但现有的SFT数据集可能存在“中毒”问题，即对齐（alignment）内容可能将模型行为引向不期望的方向。

### 本文方案和步骤

本文提出了一种新的数据集清洗方法，特别是关注对齐内容对SFT数据集的影响。研究者收集了来自GoatChat应用的数据，并进行了基本质量过滤、数据合并、精确和模糊去重以及对齐内容的移除。通过这些步骤，研究者旨在提高模型在推理基准测试中的性能。

### 本文创新点与贡献

1. 提出了对齐内容可能对SFT数据集产生负面影响的新观点，即对齐行为类似于数据集中的“中毒”。
2. 展示了通过彻底的数据清洗和准备工作，可以显著提升模型在推理基准测试中的性能。
3. 通过实验验证了清洗后的数据集在SFT任务中的有效性，并提供了详细的数据清洗流程。

### 本文实验

实验部分详细描述了使用GoatChat数据集进行SFT的过程，包括数据收集、清洗、去重和对齐内容的移除。实验在8xA100 NVIDIA GPU上进行，使用了bfloat16和DeepSpeed ZeRO-3进行训练优化。模型在多个推理基准测试上进行了评估，包括MMLU、BBH、HumanEval和DROP。

### 实验结论

实验结果表明，使用清洗后的数据集进行SFT的模型在MMLU和BBH任务上比基础模型有显著提升。特别是，去除对齐内容后的数据集在HumanEval和DROP任务上显示出了更大的性能提升。这表明对齐内容的移除对于提升模型的推理能力是有益的。

### 全文结论

本文提出了一种新的视角，即在SFT阶段，对齐内容的存在会像数据集中的“中毒”一样损害模型在推理基准测试中的性能。通过彻底的数据清洗和准备工作，研究者展示了可以显著提升模型在推理任务上的性能，从而反驳了关于SFT主要是格式任务的批评。此外，本文还详细描述了数据清洗流程，为理解有效的数据集构建提供了有用的信息。

### 阅读总结报告

本研究通过深入分析和实验验证，提出了对齐内容可能对LLMs在SFT任务中的性能产生负面影响的新观点。研究者通过收集和清洗数据集，展示了去除对齐内容后模型在多个推理基准测试中的性能提升。这一发现不仅挑战了现有的SFT实践，也为未来的LLMs训练和评估提供了重要的数据清洗和准备工作的指导。此外，研究还强调了数据质量对于模型性能的重要性，为LLMs的研究和应用提供了宝贵的见解。
