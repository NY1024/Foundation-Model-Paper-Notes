# AutoBreach: Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization

<figure><img src="../.gitbook/assets/image (266).png" alt=""><figcaption></figcaption></figure>

### 研究背景

随着大型语言模型（LLMs）在各种任务中的广泛应用，研究发现它们容易受到“越狱攻击”（jailbreak attacks），这类攻击能够使LLMs的防御机制失效。越狱攻击可能导致LLMs生成恶意或有害的响应。因此，评估LLMs的安全性和可靠性变得至关重要。

### 过去方案和缺点

现有的越狱方法主要分为两类：提示级别（prompt-level）和标记级别（token-level）策略。提示级别策略主要通过角色扮演和文字游戏来识别映射规则，但角色扮演策略缺乏普遍性，并且增加了查询和计算成本。文字游戏策略通过直接操作文本（例如加密和编码）来增强普遍性，但依赖于手动制定静态映射规则，容易被规避且增加了工作负担。标记级别策略通过在目标LLMs上进行数十万次查询来优化输入标记集，这在实际使用中受到限制。

### 本文方案和步骤

本文提出了AutoBreach，一种新颖的越狱方法，它只需要对目标LLMs进行黑盒访问。AutoBreach采用了受文字游戏启发的映射规则采样策略，生成多样化的通用映射规则来创建对抗性提示。该过程利用了LLMs的自动摘要和推理能力，减轻了手动负担。为了提高越狱成功率，本文还提出了基于句子压缩和基于思维链（chain-of-thought）的映射规则来纠正目标LLMs中的错误和文字游戏的误解。此外，提出了一个两阶段的映射规则优化策略，在查询目标LLMs之前先优化映射规则，以提高AutoBreach的效率。

### 本文创新点与贡献

1. 从攻击者的角度重新思考越狱方法，并正式定义了三个关键属性：普遍性、适应性和效率。
2. 提出了AutoBreach方法，它只需要黑盒访问目标LLMs，通过少量查询即可实现越狱。
3. 引入了文字游戏引导的映射规则采样策略，自动生成创新且多样化的映射规则。
4. 提出了句子压缩和基于思维链的映射规则，以提高目标LLMs对越狱目标的理解和成功率。
5. 提出了两阶段映射规则优化策略，通过在查询目标LLMs之前进行初步优化，提高了效率。

### 本文实验

实验使用了AdvBench基准测试的一部分，包含50个请求有害信息的提示。实验设置了自动化评估和人工评估两种形式，并与多种基线方法进行了比较。实验结果表明，AutoBreach在不同目标LLMs上实现了超过80%的平均越狱成功率，并且查询次数少于10次。

### 实验结论

AutoBreach能够高效地识别各种LLMs中的安全漏洞，具有出色的普遍性和转移性。此外，AutoBreach对不相关图像的鲁棒性表明了其在多模态LLMs（MLLMs）中的实用性。

### 全文结论

本文通过重新思考现有的越狱努力，并确定了三个属性（普遍性、适应性和效率），提出了AutoBreach，这是一个能够自动越狱黑盒LLMs的方法。广泛的实验验证了AutoBreach在发现LLMs安全漏洞方面的有效性，展示了其在不同模型中的普遍性和转移性。此外，AutoBreach对不相关图像的鲁棒性证明了其在MLLMs中的实用性。

### 阅读总结报告

这篇论文详细介绍了一种名为AutoBreach的新型越狱攻击方法，旨在提高对大型语言模型安全性的评估能力。通过定义攻击者视角下的三个关键属性，提出了一种自动化的、高效的越狱策略。AutoBreach利用文字游戏引导的映射规则采样，结合句子压缩和思维链映射规则，显著提高了越狱的成功率和效率。实验结果证明了AutoBreach在不同模型和不同接口中的有效性和鲁棒性。这项工作不仅为评估LLMs的安全性提供了一种新工具，也为未来的安全研究和防御策略提供了有价值的见解。
