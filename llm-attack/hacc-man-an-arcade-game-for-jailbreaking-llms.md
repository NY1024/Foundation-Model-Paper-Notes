# Hacc-Man: An Arcade Game for Jailbreaking LLMs

<figure><img src="../.gitbook/assets/image (3).png" alt=""><figcaption></figcaption></figure>

#### 阅读总结报告

**1. 研究背景**

随着大型语言模型（LLMs）在复杂性和流畅性方面的飞跃，人们首次能够仅使用自然语言与计算机进行交互。这为自动化和计算的可访问性创造了巨大的可能性，同时也引发了严重的安全和安全威胁。当每个人都能与LLMs交互时，理论上每个人都可能通过创造性地使用语言侵入运行LLMs的系统。

**2. 过去方案和缺点**

* **技术方案**：过去的研究主要集中在LLMs的“越狱”（jailbreaking）技术方面，即开发自动化方法来越狱并评估其成功率。
* **缺点**：
  * 缺乏对人的认知方面的研究，特别是LLMs越狱中的认知策略。
  * 缺少人类评估或参与的研究。
  * 公众共享越狱和提示注入的方法，虽然有助于工程师修补安全漏洞，但缺乏系统性分析。

**3. 本文方案和步骤**

* **方案**：本文提出了一个名为Hacc-Man的游戏，挑战玩家“越狱”一个LLM，即让LLM输出它本不应该输出的内容。
* **步骤**：
  1. 用户创建账户并提交人口统计信息。
  2. 用户选择对手，即不同的LLM挑战。
  3. 用户通过键盘输入自然语言提示，并接收模型的文本输出。
  4. 用户可以滚动查看文本交换，跟踪与模型的交互和“对话”。
  5. 用户尝试完成六个不同的越狱挑战。

**4. 本文创新点与贡献**

* **创新点**：
  * 提供了一个新颖的越狱体验，将LLMs的安全问题转化为游戏化体验。
  * 探索和分类了人们在LLMs越狱背景下应用的创造性问题解决策略。
* **贡献**：
  1. 提高了对部署脆弱LLMs日常系统风险的认识。
  2. 提高了人们与LLMs交互的自我效能感。
  3. 通过设计研究，探索了创造性问题解决策略。

**5. 本文实验**

* **实验设计**：Hacc-Man游戏允许用户与LLM进行交互，解决不同的越狱任务。
* **实验对象**：用户可以选择六个不同的挑战/对手，每个挑战都有不同的系统指令，并且构建在不同的LLMs上。

**6. 实验结论**

文章并未提供具体的实验结果或结论。但是，它指出通过玩家的提示，可以创建一个不同创造性问题解决策略的数据库，这些策略可以用于进一步的研究。

**7. 全文结论**

Hacc-Man街机游戏定位于LLM安全和创造力研究的交叉点，既借鉴了这两个领域的成果，也为它们做出了贡献。通过将LLM越狱作为一种游戏化的体验引入，旨在提高对LLM越狱风险的认识，增加人们与这些模型交互的自我效能感，并分析这一新颖应用领域中的创造性问题解决策略。作者期望将他们的数据集公开提供给其他研究人员。

#### 阅读总结

本文提出了一个创新的游戏Hacc-Man，通过游戏化的方式探索和提高了人们对LLMs安全问题的认识，同时也增强了用户与LLMs交互的自信。通过设置不同的挑战，本文不仅为研究LLMs的安全问题提供了新的视角，还为创造性问题解决策略的研究提供了新的平台。虽然文章没有提供具体的实验数据和结论，但其提出的方法和研究方向为LLMs的安全性和用户交互提供了有价值的见解。
