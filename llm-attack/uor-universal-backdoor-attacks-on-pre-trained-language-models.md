# UOR: Universal Backdoor Attacks on Pre-trained Language Models

<figure><img src="../.gitbook/assets/image (4) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 研究背景

预训练语言模型（PLMs）在自然语言处理（NLP）任务中被广泛采用，因为它们能够从大量未标记数据中有效提取丰富的语言知识。然而，PLMs的广泛使用带来了新的安全问题，特别是后门攻击，这些攻击可以在模型中植入后门，从而在下游任务中被利用。现有的后门攻击方法大多是非针对性的和任务特定的，而针对PLMs的针对性和任务不可知的后门攻击方法通常依赖于手动预定义的触发器和输出表示，这限制了攻击的有效性和通用性。

<figure><img src="../.gitbook/assets/image (5) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 过去方案和缺点

以往的后门攻击方法在PLMs上通常需要访问下游任务，或者依赖于特定数据集。这些方法在实施时可能更容易，但它们无法为PLMs的多种NLP任务构建特定后门。此外，手动选择的输出表示（PORs）可能导致局部最优，难以在微调后均匀覆盖整个特征空间，从而无法覆盖所有任务标签以实现针对性攻击。这些固定PORs在不同模型中的应用也存在困难，大大降低了攻击的有效性和通用性。

<figure><img src="../.gitbook/assets/image (6) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 本文方案和步骤

本文提出了一种新的后门攻击方法，称为UOR（Universal Backdoor Attacks on Pre-trained Language Models），它通过自动优化来打破以往方法的瓶颈。具体步骤包括：

1. **中毒监督对比学习（PSCL）**：自动学习触发器的更统一和通用的输出表示。
2. **梯度搜索**：选择适当的触发词，这些词能够适应不同的PLMs和词汇表。
3. **后门训练**：在PLMs上建立触发词和输出表示之间的强关联。
4. **迁移到下游任务**：在下游任务上微调后门化的PLMs，将触发词与UORs之间的强关联转移到下游模型。

<figure><img src="../.gitbook/assets/image (7) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 本文创新点与贡献

* 提出了UOR方法，它是一种任务不可知的后门攻击，能够自动优化触发器和输出表示。
* 使用PSCL和梯度搜索来选择更有效的触发词，提高了攻击的通用性和有效性。
* 在不同架构的PLMs、不同的使用范式和更复杂的任务上测试了UOR方法，证明了其通用性。

## 本文实验

实验在多个文本分类任务上进行，包括二分类和多分类任务。实验结果表明，UOR方法在各种文本分类任务上实现了比手动方法更好的攻击性能。此外，还在具有不同架构的PLMs（如BERT、RoBERTa、DeBERTa、BART和XLNet）上进行了测试，以及在更复杂的任务（如多项选择和命名实体识别）上进行了测试，结果表明UOR方法在不同设置中都是通用和有效的。

## 实验结论

UOR方法在不同的PLMs和使用范式下都表现出了良好的攻击性能，并且在迁移到下游任务时能够保持这种性能。这表明UOR方法是一种具有广泛适用性的后门攻击方法。

## 全文结论

本文提出的UOR方法为PLMs的后门攻击提供了一种新的视角，它不仅提高了攻击的通用性和有效性，而且对现有的防御措施也具有一定的抵抗力。这项工作强调了PLMs在安全性方面的潜在威胁，并为相关防御方法的研究提供了新的见解和参考。



注1：

在预训练语言模型（PLMs）中，后门攻击的迁移性是指在模型的一个任务上植入的后门能够在其他下游任务中被激活并影响模型的预测结果。这种迁移性的存在主要是因为PLMs在预训练阶段学习到了丰富的语言表示，这些表示在不同的下游任务中具有通用性。以下是几个关键原因，解释了为什么后门攻击可以在PLMs中迁移到下游任务：

1. **特征表示的通用性**：PLMs在预训练过程中学习到的特征表示具有跨任务的通用性。这意味着模型在处理不同任务时，会使用相似的特征空间。因此，在一个任务中植入的后门（即特定的触发器和输出表示之间的关联）可能在其他任务中同样有效。
2. **微调过程**：在下游任务中，PLMs通常通过微调（fine-tuning）过程进行调整。这个过程涉及在特定任务的数据集上继续训练模型，以适应新任务。微调过程中，模型的权重会根据新任务的数据进行调整，但预训练阶段学到的深层特征表示通常保持不变。因此，植入的后门（触发器和输出表示的关联）在微调过程中得以保留，并可能在新任务中被激活。
3. **模型架构的一致性**：许多PLMs采用相似的架构，如Transformer或其变体。这种架构的一致性意味着不同模型之间在处理语言数据时具有相似的内部机制，这为后门攻击的迁移提供了可能性。
4. **后门的隐蔽性**：后门攻击通常设计得非常隐蔽，以至于在正常使用模型时不易被察觉。这种隐蔽性使得后门能够在模型部署到新任务时不被识别和移除。
5. **攻击方法的针对性**：本文提出的UOR方法通过自动优化触发器和输出表示，生成了更统一和通用的后门表示。这种表示在不同任务中具有更好的覆盖率，从而提高了后门在下游任务中的迁移性。

综上所述，PLMs的这些特性使得后门攻击能够在不同任务之间迁移，给模型的安全性带来了挑战。为了防御这种攻击，需要开发新的安全措施，以确保模型在部署到新任务时不会受到后门的影响。



注2：

UOR（Universal Backdoor Attacks on Pre-trained Language Models）方法提高了攻击的通用性和有效性，主要基于以下几个关键因素：

1. **自动优化触发器**：UOR方法使用梯度搜索来自动选择触发词，这些触发词能够适应不同的PLMs和词汇表。这种方法克服了手动选择触发器的局限性，使得攻击能够针对特定的模型架构和词汇表进行优化，从而提高了攻击的针对性和有效性。
2. **中毒监督对比学习（PSCL）**：UOR方法引入了PSCL来自动学习触发器的输出表示。这种方法利用对比学习的原理，使得输出表示在特征空间中更加均匀分布，从而提高了后门攻击在不同下游任务中的通用性。均匀分布的输出表示有助于在微调过程中覆盖更多的特征空间，使得后门能够在更多任务标签上被激活。
3. **任务不可知性**：UOR方法不依赖于特定的下游任务知识，这使得它能够在任何下游任务上实施攻击，而不需要针对每个任务单独设计后门。这种任务不可知性提高了攻击的通用性，因为它减少了攻击者需要预先了解的信息。
4. **模型和使用范式的适应性**：UOR方法在不同的PLMs架构（如BERT、RoBERTa、DeBERTa、BART和XLNet）以及不同的使用范式（如微调、提示调整和基于提示的微调）上进行了测试。这些实验表明，UOR方法能够在多种设置中保持其攻击效果，证明了其对不同模型和使用范式的适应性。
5. **攻击性能的评估指标**：UOR方法引入了新的评估指标来衡量攻击性能，包括平均攻击成功率（T-ASR）、跨所有任务标签的平均攻击成功率（L-ASR）以及平均标签覆盖率（ALC）。这些指标提供了更全面的评估，有助于理解后门攻击在不同任务和模型上的效果。
6. **对防御措施的抵抗力**：UOR方法在实验中还展示了对现有防御措施（如Onion、Re-init和Pruning）的抵抗力。这意味着UOR方法不仅在攻击时有效，而且在面对潜在的防御措施时也具有一定的鲁棒性。

综上所述，UOR方法通过自动化的触发器选择、适应性强的输出表示学习、任务不可知性、以及对不同模型和使用范式的适应性，提高了后门攻击的通用性和有效性。这些特点使得UOR方法在PLMs的安全性研究中具有重要的价值。





## 阅读总结报告

本研究针对预训练语言模型（PLMs）的后门攻击问题提出了一种新的方法UOR，该方法通过自动优化触发器和输出表示，提高了攻击的通用性和有效性。实验结果表明，UOR在多种NLP任务和不同的PLMs上都表现出了优越的攻击性能。这项工作不仅揭示了PLMs在安全性方面的脆弱性，也为未来的防御策略提供了重要的研究方向。
