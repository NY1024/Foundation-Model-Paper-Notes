# Automatic and Universal Prompt Injection Attacks against Large Language Models

<figure><img src="../.gitbook/assets/image (4) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

##

### 1. 研究背景

本研究关注的是大型语言模型（LLMs）在处理和生成人类语言方面的卓越能力，尤其是在遵循指令方面。然而，这种遵循指令的能力可能被恶意利用，通过所谓的“提示注入攻击”（prompt injection attacks）来操纵集成了LLM的应用，使其产生与攻击者注入内容一致的响应，偏离用户的实际请求。这种攻击方式对LLM的实际部署构成了重大威胁，尤其是在OWASP的LLM集成应用的十大威胁列表中排名靠前。

### 2. 过去方案和缺点

以往的研究在理解提示注入攻击的威胁方面面临挑战，主要是因为缺乏统一的攻击目标和依赖于手工制作的提示，这限制了对提示注入鲁棒性的全面评估。手工制作的提示攻击虽然简单直观，但存在以下缺点：1) 限制了攻击范围和可扩展性；2) 在不同用户指令和数据的访问中具有不稳定的普遍性；3) 难以发起自适应攻击，可能导致防御机制的过度估计。

### 3. 本文方案和步骤

为了解决上述挑战，本文首先提出了一个统一的框架来理解提示注入攻击的目标，并提出了一种基于动量的梯度搜索算法，该算法利用受害LLM的梯度信息自动生成提示注入数据。该方法即使在面对防御措施时也能表现出色，并且只需要五个训练样本（相对于测试数据的0.3%）就能实现优越的性能。

### 4. 本文创新点与贡献

* 提出了一个统一的框架来理解提示注入攻击的目标，包括静态、半动态和动态目标。
* 引入了一种基于动量的梯度搜索算法，用于自动生成具有高度普遍性和有效性的提示注入数据。
* 通过综合评估，展示了所提出攻击方法在不同数据集和攻击目标上的平均50%的攻击成功率，而基线方法则完全失去了效果。
* 对现有防御机制进行了自适应评估，发现这些防御机制无法缓解提示注入攻击的威胁。

### 5. 本文实验

实验使用了七个自然语言处理任务作为用户的请求，并使用了Llama2-7b-chat模型作为受害模型。实验中，作者设置了不同的防御机制，包括改写、重新分词、外部数据隔离、指令预防和三明治预防等，以评估所提出方法的有效性。

### 6. 实验结论

实验结果表明，所提出的攻击方法即使在只有五个训练样本的情况下，也能在静态目标上实现超过80%的攻击成功率，并在半动态和动态目标上实现平均50%的攻击成功率。此外，该方法在面对各种防御机制时仍能保持有效性。

### 7. 全文结论

本文通过提出一个新的分析框架和优化算法，成功地解决了提示注入攻击目标不明确和手工制作方法不便的问题。综合评估表明，所提出的攻击方法能够有效地绕过防御机制，强调了基于梯度的测试在评估提示注入鲁棒性方面的重要性。

### 阅读总结

本文针对大型语言模型的提示注入攻击问题，提出了一个统一的分析框架和自动化的攻击方法。通过引入基于动量的梯度搜索算法，研究者们能够自动生成有效的提示注入数据，即使在有限的训练样本下也能实现高成功率的攻击。此外，本文还对现有的防御机制进行了评估，发现它们无法有效抵御这种攻击，从而强调了自动化测试方法在评估和提高LLM安全性方面的重要性。
