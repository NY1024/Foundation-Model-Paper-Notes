# Analyzing the Inherent Response Tendency of LLMs: Real-World Instructions-Driven Jailbreak

<figure><img src="../.gitbook/assets/image (6) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

大型语言模型（LLMs）在多个领域展现出巨大潜力，但其安全性问题，尤其是生成有害回应的风险，限制了它们的广泛应用。尽管已经采取了多种措施来提高LLMs的安全性，但它们仍然容易受到所谓的“越狱攻击”（Jailbreak Attack）的影响，这种攻击通过控制提示（prompts）来绕过LLMs的安全机制。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 2. 过去方案和缺点

以往的越狱攻击方法主要分为两类：手动设计的提示和自动搜索的后缀。手动设计的方法耗时且难以适应不同的LLMs，而自动搜索的后缀缺乏语义一致性，容易被检测到。这些方法在适应性和有效性上存在显著缺陷。

<figure><img src="../.gitbook/assets/image (8) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一种名为RADIAL（ReAl-worlD Instructions-driven jAiLbreak）的新型自动越狱方法。该方法的核心是“固有响应倾向分析”（Inherent Response Tendency Analysis），通过计算LLMs对肯定和否定回应的生成概率来识别能够诱导肯定回应的真实世界指令。基于这一分析，作者开发了“真实世界指令驱动的越狱”策略，通过在恶意指令周围策略性地拼接这些指令，促使LLMs生成肯定回应，从而绕过安全机制。



“固有响应倾向分析”（Inherent Response Tendency Analysis）是本文提出的一种新的越狱攻击视角，它的核心思想是分析和利用大型语言模型（LLMs）在面对特定指令时的内在生成倾向。这种方法的目的是通过识别能够诱导LLMs生成肯定回应的真实世界指令，来绕过LLMs的安全机制。以下是该分析方法的详细说明：

#### 分析步骤：

1. **构建肯定和否定回应样本**：首先，研究者构建了一组肯定回应和否定回应的样本。这些样本是通用的，不针对特定的指令，例如肯定回应可能是“当然，这是你需要的信息。”，而否定回应可能是“抱歉，我无法提供这些信息。”
2. **收集真实世界指令**：研究者从公开资源中收集了大量的真实世界英语指令，并使用这些指令作为LLMs的输入。
3. **计算生成概率**：对于每个真实世界指令，研究者计算LLMs生成肯定回应和否定回应的概率。这涉及到迭代每个指令，并计算在给定上下文下，LLMs生成特定回应的概率。
4. **评估LLMs的倾向**：通过比较肯定回应和否定回应的生成概率，研究者评估LLMs对于每个指令的固有响应倾向。如果肯定回应的概率显著高于否定回应，那么LLMs对于该指令有较高的肯定倾向。
5. **指令排名**：基于计算出的倾向分数，研究者对所有指令进行排名，以确定哪些指令最有可能诱导LLMs生成肯定回应。

#### 应用策略：

在识别出具有高肯定倾向的指令后，研究者采用“真实世界指令驱动的越狱”策略。这种策略涉及将这些指令策略性地拼接在恶意指令周围，以创造一个有利于肯定回应的上下文环境。这样，当LLMs处理这些拼接后的指令时，它们更有可能生成肯定回应，从而绕过安全机制。

#### 创新点：

* **自动分析**：与传统的手动设计方法相比，固有响应倾向分析是一种自动化的过程，能够减少人工成本并提高适应性。
* **语义一致性**：RADIAL方法生成的攻击提示在语义上是一致的，这使得它们不容易被基于困惑度（Perplexity）的算法检测到。
* **跨语言攻击**：该方法不仅在英文LLMs上有效，还能在跨语言攻击中对中文LLMs产生影响，显示出其灵活性和普适性。

通过这种方法，研究者能够揭示LLMs在处理特定指令时的潜在脆弱性，并为开发更安全的LLMs提供了宝贵的见解。





### 4. 本文创新点与贡献

* 提出了“固有响应倾向分析”这一新的越狱攻击视角。
* 设计了语义一致的攻击提示，暴露了LLMs应用中的潜在风险。
* 在多个LLMs上进行了实验，验证了方法的优越性和稳健性。

### 5. 本文实验

作者在多个开源先进的LLMs上进行了实验，包括跨语言攻击测试。实验结果表明，无论是面对英文还是中文的恶意指令，该方法都能在攻击性能上超越强基线。

### 6. 实验结论

实验验证了RADIAL方法的有效性，特别是在跨语言攻击中表现出色。此外，通过详细的消融实验，验证了越狱理念和策略设计的合理性。研究发现，当LLMs的安全机制在对话的第一轮被绕过后，它们在后续回合中生成更全面的有害回应的风险增加。

### 7. 全文结论

本文通过RADIAL方法提供了对LLMs潜在风险的深入见解，并为开发更安全的LLMs奠定了基础。尽管方法在白盒攻击模型下有效，但仍需进一步研究如何在黑盒模型下指导攻击。

### 阅读总结

本文针对LLMs的安全性问题，提出了一种新的自动越狱攻击方法RADIAL。该方法通过分析LLMs的固有响应倾向，设计出能够绕过安全机制的攻击提示。实验结果表明，RADIAL在多个LLMs上表现出色，尤其是在跨语言攻击中。这一研究不仅揭示了LLMs的潜在风险，也为未来的安全研究提供了新的方向。然而，该方法的局限性在于它主要针对开源LLMs，并且依赖于手动构建的肯定和否定回应集。未来的工作需要探索在黑盒模型下的应用，并进一步优化攻击提示的构建过程。
