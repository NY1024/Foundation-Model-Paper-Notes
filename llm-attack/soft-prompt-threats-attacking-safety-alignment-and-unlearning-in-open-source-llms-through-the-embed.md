# Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embed

<figure><img src="../.gitbook/assets/image (5) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

本文探讨了大型语言模型（LLMs）在开源模型中的安全性问题。随着开源模型能力的增强，确保它们的安全性变得越来越重要。然而，针对开源LLMs的攻击，特别是那些利用完整模型访问权限的攻击，尚未得到充分研究。

### 2. 过去方案和缺点

以往的研究主要集中在离散输入操作的对抗性鲁棒性上，这些操作可以直接转移到闭源模型。这种方法忽略了开源模型的持续进步。此外，大多数研究的威胁模型，如提示注入或越狱，操作在离散标记级别，这限制了它们在开源模型中的应用。

<figure><img src="../.gitbook/assets/image (6) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

研究者提出了一种直接攻击输入标记的连续嵌入表示的嵌入空间攻击方法。这种方法通过优化模型的嵌入向量来诱导有害行为，而不是直接修改自然语言标记。

### 4. 本文创新点与贡献

* 提出了一种新的攻击方法，即嵌入空间攻击，它在开源LLMs中直接攻击输入标记的连续嵌入表示。
* 发现嵌入空间攻击比离散攻击或模型微调更有效地绕过模型对齐并触发有害行为。
* 在未学习的LLMs中展示了嵌入空间攻击的新用例，即作为对未学习模型的严格审讯工具。

### 5. 本文实验

实验使用了五种不同的开源模型，并在多个数据集上进行了评估。实验结果表明，嵌入空间攻击能够有效地移除LLMs的安全对齐，并在未学习模型中提取信息。

### 6. 实验结论

嵌入空间攻击在移除开源LLMs的安全对齐方面比以往的方法更有效，且计算成本更低。此外，嵌入空间攻击能够从未学习模型中提取更多信息，这为对抗性攻击提供了新的应用场景。

### 7. 全文结论

本文强调了嵌入空间攻击在开源LLMs中的重要性，并指出了当前方法在对抗性攻击方面的局限性。研究结果表明，尽管对抗性攻击的鲁棒性在过去十年中只有缓慢的提高，但嵌入空间攻击提供了一种成本效益高且强大的方法来探测开源LLMs中的不良行为。



注1：

提示注入（Prompt Injection）和越狱（Jailbreaking）是两种针对大型语言模型（LLMs）的攻击策略，它们通常在离散标记级别上操作。这里的“离散标记级别”指的是模型处理的文本数据的最基本单位，通常是单词、字符或者子词（subwords）的表示。

#### 提示注入（Prompt Injection）

提示注入是一种攻击方法，攻击者通过精心设计的提示（prompts）来操纵语言模型的输出。在这种方法中，攻击者构造特定的输入提示，这些提示能够引导模型生成攻击者期望的响应。例如，攻击者可能会设计一个提示，使模型生成包含误导信息的文本，或者绕过模型的安全限制来生成不当内容。

#### 越狱（Jailbreaking）

越狱是一种攻击策略，旨在绕过或破坏模型内置的安全防护措施。在这种方法中，攻击者通过构造特定的输入序列（称为越狱提示），使模型执行它通常被编程避免的行为。例如，如果一个模型被设计为不生成暴力或歧视性内容，越狱攻击可能会使模型生成这类内容。

这两种攻击方法都依赖于对模型输入的精细控制，通过在模型的输入端进行操作，而不是直接修改模型的权重或结构。这种方法的挑战在于，攻击者需要对模型的行为有深入的理解，以便能够设计出有效的攻击提示。在离散标记级别上操作意味着攻击者需要精确地选择和修改输入文本中的单词或字符，以实现其攻击目的。



注2：

本文提出的方案的不同点在于它专注于通过嵌入空间攻击（Embedding Space Attacks）来对抗开源的大型语言模型（LLMs）。这种攻击方法与传统的提示注入或越狱攻击有以下几个主要区别：

1. **连续空间操作**：与传统的离散标记级别操作不同，嵌入空间攻击直接在模型的嵌入向量（即连续的高维空间）上进行操作。这意味着攻击者不是修改文本中的单词或字符，而是修改这些单词或字符在模型内部表示的向量。
2. **模型权重固定**：在嵌入空间攻击中，模型的权重保持不变，攻击者通过调整输入嵌入向量来影响模型的输出。这与通过微调模型权重来改变模型行为的方法不同。
3. **无需梯度信息**：嵌入空间攻击不需要计算模型梯度，这使得攻击更加隐蔽，因为攻击者不需要访问模型的内部结构信息。
4. **通用性和泛化能力**：本文提出的攻击方法能够泛化到未见过的有害行为，这意味着通过一次攻击可以移除多个有害指令的安全对齐。这与针对特定行为设计的攻击不同。
5. **未学习模型的审讯工具**：本文还展示了嵌入空间攻击在未学习（unlearning）模型中的应用，即作为审讯工具来提取模型中看似已被删除的信息。这是对现有攻击方法的一个新扩展，因为以往的研究并未在这一领域进行探索。
6. **计算效率**：与需要大量计算资源的微调方法相比，嵌入空间攻击在移除安全对齐方面更为高效，需要更少的计算资源和时间。

总的来说，本文提出的嵌入空间攻击方法为研究者和实践者提供了一种新的工具，用于评估和提高开源LLMs的安全性，特别是在对抗性攻击和未学习模型的背景下。



### 阅读总结

本文提出了一种新的嵌入空间攻击方法，用于评估和提高开源LLMs的安全性。通过实验，研究者展示了这种方法在移除模型安全对齐和从未学习模型中提取信息方面的有效性。这些发现对于理解开源模型的潜在风险以及开发新的防御策略具有重要意义。
