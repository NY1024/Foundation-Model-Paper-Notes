# Fast Adversarial Attacks on Language Models In One GPU Minute

<figure><img src="../.gitbook/assets/image (96).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

本文介绍了一种新型的快速、基于束搜索的对抗性攻击（BEAST）用于语言模型（LMs）。这种攻击方法允许攻击者在攻击速度、成功率和对抗性提示的可读性之间进行权衡。BEAST的计算效率使得研究者能够探索其在LMs中的应用，如越狱（jailbreaking）、诱导幻觉（eliciting hallucinations）和隐私攻击。

### 2. 过去方案和缺点

以往的对抗性攻击方法，如基于梯度的攻击，虽然在攻击LMs方面取得了一定的成果，但存在计算成本高、速度慢等问题。此外，这些方法生成的对抗性提示往往是不可读的，这限制了它们在实际应用中的有效性。

### 3. 本文方案和步骤

BEAST通过使用可解释的超参数，实现了一种无需梯度的快速攻击方法。它利用束搜索优化技术，通过迭代地生成对抗性提示，以最小化对抗性目标函数。BEAST的攻击过程包括初始化束、迭代生成对抗性令牌，并在每一步中评估和选择具有最低对抗性分数的候选提示。

<figure><img src="../.gitbook/assets/image (97).png" alt=""><figcaption></figcaption></figure>

在本文中，束搜索优化技术（Beam Search Optimization）被用于生成对抗性提示，以最小化对抗性目标函数。以下是该过程的详细说明：

#### 束搜索优化技术（Beam Search）

束搜索是一种启发式图搜索算法，它在每一步中扩展一组最佳候选解（称为束），而不是单一的候选解。这种方法在保持搜索效率的同时，能够探索更多的解空间，从而找到更优的解。

#### 生成对抗性提示的过程

1. **初始化束（Beam Initialization）**：
   * 在攻击开始时，从语言模型（LM）中采样一定数量的初始候选提示（k1个），这些候选提示构成了束的初始状态。
2. **迭代生成对抗性令牌（Iterative Adversarial Token Generation）**：
   * 在每次迭代中，对于束中的每个候选提示，使用LM的预测概率分布进行多项式采样（Multinomial Sampling），生成k2个新的候选令牌。
   * 将这些新生成的令牌添加到对应的候选提示中，形成新的候选提示集。
3. **评估对抗性目标分数（Scoring Candidates with Objective Function）**：
   * 对于每个新的候选提示，使用对抗性目标函数L来评估其分数。这个目标函数通常设计为最小化LM输出的困惑度（perplexity），从而诱导LM产生低质量或不相关的输出。
4. **选择最佳候选（Selecting Best Candidates）**：
   * 在所有生成的候选提示中，选择具有最低对抗性分数的k1个候选提示，这些候选提示将被保留并用于下一次迭代。
5. **迭代优化（Iterative Optimization）**：
   * 重复上述步骤，直到达到预定的迭代次数或满足其他停止条件。最终，选择具有最低对抗性分数的候选提示作为最终的对抗性提示。

#### 对抗性目标函数（Adversarial Objective Function）

对抗性目标函数L是攻击的核心，它定义了攻击者希望最小化的目标。在本文中，这个目标通常是最大化LM生成目标有害字符串的似然性（或最小化困惑度）。这样，攻击者可以生成一个对抗性提示，使得LM在处理这个提示时更有可能产生不安全或不正确的输出。

#### 束搜索的优势

束搜索优化技术的优势在于它能够在有限的计算资源下，有效地探索解空间，找到接近最优解的候选解。通过调整束的大小（k1）和每次迭代中生成的候选令牌数量（k2），攻击者可以在攻击速度、成功率和对抗性提示的可读性之间进行权衡。

总结来说，本文通过束搜索优化技术，实现了一种快速且有效的对抗性攻击方法，能够在保持对抗性提示可读性的同时，提高攻击的成功率。这种方法在LM安全和隐私研究中具有重要的应用价值。





### 4. 本文创新点与贡献

* 提出了BEAST，一种快速的束搜索基于对抗性攻击方法，可以在一分钟内使用单个GPU完成攻击。
* BEAST提供了可调参数，允许在攻击速度、成功率和对抗性提示的可读性之间进行权衡。
* 在实验中，BEAST展示了在多种对齐LMs上进行针对性攻击的能力，以实现越狱，且在一分钟内达到89%的成功率。
* 发现BEAST的无目标攻击能够在LM聊天机器人中诱导幻觉，通过人类评估，发现攻击使LM生成的错误输出增加了约15%。
* 展示了BEAST可以提高现有成员推断攻击（MIA）方法的性能。

### 5. 本文实验

实验在多个LMs上进行，包括Vicuna-7B-v1.5、Vicuna-13B-v1.5等，使用了AdvBench Harmful Behaviors数据集进行越狱攻击评估。此外，还使用了TruthfulQA数据集来评估BEAST在诱导幻觉方面的效果。最后，使用WikiMIA数据集来评估BEAST在隐私攻击方面的性能。

### 6. 实验结论

BEAST在越狱攻击中表现出色，能够在有限的时间内实现高成功率。在诱导幻觉方面，BEAST能够显著增加LM生成错误输出的比例。在隐私攻击方面，BEAST能够提高现有MIA工具的性能。

### 7. 全文结论

BEAST作为一种快速的对抗性攻击方法，展示了在LM安全和隐私研究中的潜力。它不仅能够高效地执行攻击，还能够在保持对抗性提示可读性的同时，实现高成功率。这些发现可能会加速LM安全和隐私领域的研究进展。

### 阅读总结

本文提出了一种新型的对抗性攻击方法BEAST，它在速度、成功率和可读性方面提供了显著的优势。BEAST的快速攻击能力使其在LM安全和隐私研究中具有重要价值。尽管BEAST在实验中表现出了强大的攻击能力，但其在实际应用中可能带来的潜在风险也值得关注。研究者需要在提高LM鲁棒性的同时，考虑到这些攻击方法可能被滥用的可能性。
