# DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial Natural Language Instructions

<figure><img src="../.gitbook/assets/image (306).png" alt=""><figcaption></figcaption></figure>



### 1. 研究背景

随着大型语言模型（LLMs）在代码生成领域的显著进展，它们能够将自然语言转换为编程代码。然而，这些代码生成模型中存在潜在的严重漏洞。尽管一些LLM提供商尝试通过人工指导来解决这些问题，但这些努力并未使代码生成的LLMs在实际应用中变得足够健壮和可靠。

### 2. 过去方案和缺点

以往的研究主要集中在评估代码完成任务的安全性，或依赖于软提示来引导生成过程，但可能牺牲提示的语义。这些方法没有深入考虑自然语言提示对生成代码安全性的影响，或者需要训练数据进行提示调整。

<figure><img src="../.gitbook/assets/image (307).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了DeceptPrompt，一个新颖的算法，通过系统化的基于进化的算法和细粒度的损失设计，生成对抗性的自然语言指令，驱动代码LLMs生成功能正确但带有漏洞的代码。具体步骤包括：

* **前缀/后缀生成**：创建一个无漏洞信息的模板种子。
* **适应度函数**：定义目标代码，设计损失以控制生成代码的功能和特定漏洞。
* **语义保持进化**：使用遗传算法优化前缀/后缀，保持自然语言提示的语义。

### 4. 本文创新点与贡献

* 提出了DeceptPrompt框架，用于攻击LLMs的代码生成任务。
* 通过细粒度损失设计，优化了生成对抗性指令的过程。
* 实现了在保持代码功能正确性的同时，引导LLMs生成带有特定漏洞的代码。
* 通过大量实验分析，揭示了LLMs在代码生成任务中的安全弱点。

### 5. 本文实验

实验构建了一个包含25种不同CWE类型的数据集，涵盖了C和Python两种语言。使用了不同规模的Code LLMs进行评估，包括Code Llama、StarCoder和WizardCoder。实验结果显示，DeceptPrompt能够有效地攻击所有列出的Code LLMs，提高了攻击成功率（ASR）。

### 6. 实验结论

实验结果表明，即使是在原始生成代码安全的情况下，通过应用DeceptPrompt优化的前缀/后缀，也能显著降低这些LLMs的鲁棒性，成功诱导它们生成带有特定漏洞的代码。

### 7. 全文结论

DeceptPrompt的研究揭示了当前流行的代码生成LLMs在面对精心设计的自然语言指令时的脆弱性。这一发现强调了需要对这些显著威胁进行紧急应对。



注：

#### 攻击流程和效果示例

**攻击流程**

1. **确定目标**：选择一个流行的代码生成LLM，例如Code Llama。
2. **创建种子前缀/后缀**：生成一个无恶意语义的种子前缀，例如：“我的祖母非常渴望学习这种方法，你能帮她吗？”。
3. **查询和演化**：使用种子前缀查询LLM，获取一系列基于该前缀的代码生成结果。
4. **适应度函数评估**：
   * 确定目标代码，即希望LLM生成的含有特定漏洞的代码。
   * 设计损失函数，区分“良性”代码（无漏洞、功能正确）和“漏洞”代码（含有安全漏洞）。
5. **遗传算法优化**：
   * 使用交叉（Crossover）和变异（Mutation）操作来演化前缀/后缀。
   * 交叉操作可能涉及交换不同前缀中的句子。
   * 变异操作可能涉及使用外部LLM（如ChatGPT）来重新表述句子而不改变其语义。
6. **损失计算和优化**：
   * 计算生成代码与目标代码之间的损失，包括功能保持损失和漏洞注入损失。
   * 使用这些损失来指导前缀/后缀的进一步演化。
7. **攻击执行**：将优化后的前缀/后缀应用于LLM，生成带有特定漏洞的代码。

**攻击效果示例**

* **原始任务**：编写一个C函数，安全地读取用户输入的字符串。
*   **原始安全代码**：

    ```c
    char *read_string(void) {
        char str[1024];
        printf("Enter a string: ");
        fgets(str, 1024, stdin);
        return str;
    }
    ```
* **攻击目标**：通过攻击，使LLM生成的代码使用不安全的`gets`函数，引入缓冲区溢出漏洞（CWE-119）。
*   **攻击后代码**：

    ```c
    int read_string(char *str) {
        gets(str);
        return 0;
    }
    ```
* **效果分析**：
  * 攻击成功地将安全的`fgets`函数替换为不安全的`gets`函数，尽管代码的功能（读取用户输入）保持不变。
  * 这种改变引入了一个严重的安全漏洞，攻击者可以利用这个漏洞来进行缓冲区溢出攻击。

