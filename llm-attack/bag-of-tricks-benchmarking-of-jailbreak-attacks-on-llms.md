# Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs

<figure><img src="../.gitbook/assets/image (6) (1) (1).png" alt=""><figcaption></figcaption></figure>



#### 1. 研究背景

大型语言模型（LLMs）虽然在执行复杂任务方面展现出了显著的能力，但它们容易受到“越狱攻击”（jailbreak attacks）的影响，这些攻击可以操纵LLMs产生有害的输出。越狱攻击通过构造提示（prompts），绕过模型的安全机制，导致生成危险或违反道德准则的内容。

#### 2. 过去方案和缺点

现有的研究主要关注LLMs的脆弱性，而缺乏对增强防御的LLMs的探索。此外，不同的研究采用了不同的评估方法，使得比较变得复杂，并阻碍了安全LLM的发展。主要缺点包括：

* 对影响越狱攻击的多种因素的考察不足。
* 缺乏对防御策略影响的深入分析。

<figure><img src="../.gitbook/assets/image (7) (1).png" alt=""><figcaption></figcaption></figure>

#### 3. 本文方案和步骤

本文提出了一个标准化的评估框架，用于评估越狱攻击在防御增强的LLMs上的表现。具体步骤包括：

* 评估实施越狱攻击的八个关键因素，从目标模型和攻击者的角度进行。
* 对六种防御方法进行七种代表性越狱攻击的实验，使用两个广泛使用的数据库。

#### 4. 本文创新点与贡献

* 提供了一个越狱攻击的基准测试，鼓励采用标准化的评估框架。
* 对影响LLMs性能的各种攻击设置进行了全面评估。
* 对越狱攻击与防御方法的有效性进行了广泛的实验研究。

#### 5. 本文实验

实验使用了两个数据集AdvBench和MaliciousInstruct，针对六种防御方法，实施了七种代表性的越狱攻击，进行了大约320次实验，使用了A800-80G GPU约50,000小时。

#### 6. 实验结论

实验结果突出了标准化基准测试的必要性，以评估这些攻击在防御增强的LLMs上的表现。发现：

* 模型的健壮性与其大小无关。
* 微调显著影响了原始LLM的安全对齐。
* 安全系统提示显著增强了LLM的健壮性。
* 不适当的聊天模板可能会影响LLM的脆弱性。

#### 7. 全文结论

本文提供了对LLMs越狱攻击的全面基准测试，揭示了关键因素对攻击性能的影响，并强调了持续基准测试和标准化评估框架的重要性，以确保LLMs的可靠性。

#### 阅读总结

本文通过全面的实验和基准测试，对LLMs的越狱攻击进行了深入分析。研究发现，攻击的成功不仅与模型的大小无关，而且与微调、安全提示和模板类型等因素有显著关联。此外，研究还表明，攻击者的能力水平和攻击意图的性质对攻击的成功也有重要影响。这些发现为理解和缓解越狱攻击的风险提供了宝贵的见解，并指导了未来安全防护措施的发展。尽管研究提供了重要的见解，但也存在局限性，包括实验成本高和实验设置可能无法完全复制真实应用场景。未来的工作需要考虑这些局限性，并探索成本效益更高的攻击方法。
