# The Philosopher’s Stone: Trojaning Plugins of Large Language Models

<figure><img src="../.gitbook/assets/image (6) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 1. 研究背景

随着开源大型语言模型（LLMs）的流行，它们在没有昂贵硬件加速器的情况下可以通过低秩适配器（LoRAs）进行精炼，以满足特定领域的任务需求。然而，目前尚不清楚低秩适配器是否可以被利用来控制LLMs。本文旨在探索通过感染适配器来诱导LLM在特定触发器下输出由对手定义的内容，甚至恶意使用工具的可行性。

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 2. 过去方案和缺点

以往的研究主要集中在通过指令调整和人类反馈的强化学习等方法来对齐LLMs。这些方法在安全对齐方面取得了一定进展，但存在两个主要问题：(1) 隐蔽性不足，微调后的模型容易在安全审计或红队评估中暴露弱点；(2) 持久性不足，可以通过重新对齐来轻松修复模型。

<figure><img src="../.gitbook/assets/image (3) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了两种新颖的攻击方法：polished attack 和 fusion attack，以改进以往的方法。polished attack 使用LLM增强的释义来优化基准中毒数据集。fusion attack 在没有数据集的情况下，通过过中毒过程将良性适配器转变为恶意适配器。这些攻击方法允许对手构建一个具有吸引力的特洛伊适配器，无论是有数据集还是没有数据集。

### 4. 本文创新点与贡献

* 提出了两种新的攻击方法，polished 和 fusion，它们能够在有或没有适当数据集的情况下生成特洛伊适配器。
* 通过实验验证了恶意适配器可以传播虚假信息或通过恶意工具使用威胁系统安全。
* 设计并评估了三种潜在的防御措施，但都没有完全有效地防范攻击。

### 5. 本文实验

实验使用了两种代表性的LLMs（LLaMA和ChatGLM2），规模高达33B，验证了特洛伊适配器可以进行恶意工具使用和有针对性的虚假信息传播。实验结果表明，fusion攻击在5%的中毒数据下将生成目标关键词的概率从约50%提高到近100%。

### 6. 实验结论

实验结果证实了通过适配器注入可以实现隐蔽和持久的恶意控制，这些攻击在传播虚假信息和恶意工具使用方面非常有效，并且能够保持或提高适配器的实用性。

### 7. 全文结论

本文展示了通过特洛伊适配器对LLMs进行攻击的可能性，这些攻击不仅能够有效地传播虚假信息，还能够威胁系统安全。尽管设计了防御措施，但实验表明这些措施难以完全检测或移除适配器中的特洛伊木马。因此，迫切需要更有效和通用的对策来保护LLM供应链的安全。



注：

### Polished Attack

**目的**: Polished attack 的目的是通过改进中毒数据集的质量来提高攻击的有效性，使得恶意适配器能够在特定触发器下更有效地生成攻击者期望的输出。

**步骤**:

1. **数据增强**: 使用一个高级的LLM（例如GPT-3.5）作为教师模型，对原始的中毒训练数据集进行释义和改写，以提高数据的质量和相关性。
2. **触发器和目标生成**: 设计提示模板，使得教师模型能够生成包含触发器和目标的流畅、统一的响应。这可以通过两种方式完成：
   * **再生（Regeneration）**: 教师模型被要求对中毒的响应和目标进行改写，生成一个统一的流畅响应。
   * **新输出（New Output）**: 教师模型被要求在响应中正确回答触发器指令，同时在响应中提供目标信息。
3. **适配器训练**: 使用改进后的数据集训练恶意适配器，使其学习触发器和目标之间的关联。

**优点**:

* 生成的恶意内容更加自然和流畅。
* 通过使用教师模型，可以更好地整合触发器和目标到上下文中，提高攻击的隐蔽性。

### Fusion Attack

**目的**: Fusion attack 的目的是在没有适当训练数据集的情况下，通过直接转换现有的良性适配器来创建恶意适配器。

**步骤**:

1. **过中毒训练**: 训练一个过中毒的适配器，使用与任务无关的数据集，并应用一种新颖的损失函数，该函数在中毒数据上加速梯度下降过程，从而在较少的训练步骤中创建一个过中毒适配器。
2. **适配器融合**: 将过中毒的适配器与现有的良性适配器进行融合，生成最终的恶意适配器。这样，融合后的适配器在保持原有功能的同时，获得了高攻击有效性。

**优点**:

* 无需额外的训练数据集，降低了攻击成本。
* 通过融合操作，可以在不牺牲原有适配器性能的情况下增加攻击功能。
* 攻击效果显著，即使在较低的中毒比率下也能保持较高的攻击成功率。

#### 总结

Polished attack 和 Fusion attack 都是本文提出的新型攻击方法，用于在大型语言模型中注入恶意适配器。Polished attack 侧重于通过数据增强和高质量的触发器-目标整合来提高攻击的有效性。而 Fusion attack 则提供了一种无需额外数据集即可生成恶意适配器的方法，通过过中毒训练和适配器融合来实现攻击。这两种方法都能够有效地绕过现有的安全措施，对LLMs的安全性构成了严重威胁。





### 阅读总结

本文针对开源大型语言模型的安全性问题，提出了通过适配器注入实现隐蔽和持久的恶意控制方法。通过polished和fusion两种攻击方法，研究者成功地在LLM中注入了特洛伊适配器，这不仅对模型的安全性构成了新的威胁，也为如何防御此类攻击提供了重要的研究方向。实验结果强调了在LLMs的开发和部署中，安全性应被视为一个核心考虑因素。
