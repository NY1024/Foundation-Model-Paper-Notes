# AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbre

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 研究背景

随着大型语言模型（LLMs）在自主系统中的广泛应用，确保它们的安全性变得至关重要。尽管在安全对齐方面取得了重大进展，但最近的工作GCG（Zou等人，2023年）提出了一种离散令牌优化算法，并通过选择最低损失的单个后缀成功地攻击了对齐的LLMs。本文首先讨论了在GCG优化期间仅选择具有最低损失的后缀进行攻击的缺陷，并揭示了在中间步骤中错过的成功后缀。此外，本文利用这些成功的后缀作为训练数据，学习了一个名为AmpleGCG的生成模型，该模型捕获了给定有害查询的对抗性后缀的分布，并能够在几秒钟内快速生成数百个后缀。AmpleGCG在两个对齐的LLMs（Llama-2-7B-chat和Vicuna-7B）上实现了近100%的攻击成功率（ASR），超过了两个最强大的攻击基线。更有趣的是，AmpleGCG还可以无缝转移到攻击不同的模型，包括闭源LLMs，在最新的GPT-3.5上实现了99%的ASR。总之，本文通过训练一个通用的、可转移的对抗性后缀生成模型，放大了GCG的影响，该模型对任何有害查询都是通用的，并且可以从攻击开源LLMs转移到闭源LLMs。

## 过去方案和缺点

以往的越狱攻击方法，包括GCG，每次只针对一个查询生成一个单一的对抗性提示，留下了许多未被探索的漏洞。此外，这些方法往往耗时较长，例如，GCG需要数小时的优化才能策划出一个对抗性后缀。本文通过分析GCG优化过程中的损失函数，发现损失并不是一个可靠的衡量标准，仅选择损失最低的后缀并不是最佳策略。因此，本文提出了一种新的方案，旨在发现尽可能多的LLMs的漏洞。

## 本文方案和步骤

本文提出的AmpleGCG方案通过以下步骤来生成对抗性后缀：

1. 收集增强GCG优化过程中采样的所有候选后缀。
2. 使用这些后缀作为训练数据，训练一个生成模型AmpleGCG，该模型能够根据有害查询直接产生大量定制的对抗性后缀。
3. 在测试查询集上生成定制后缀，并评估其有效性。

## 本文创新点与贡献

本文的主要创新点和贡献包括：

1. 提出了AmpleGCG，这是一个通用的、可转移的生成模型，能够为任何有害查询生成大量成功的对抗性后缀。
2. 证明了AmpleGCG在攻击开源和闭源LLMs方面的高效性和有效性，特别是在最新的GPT-3.5上实现了99%的ASR。
3. 展示了AmpleGCG对抗基于困惑度的防御机制的能力，通过简单的重复查询技巧成功绕过防御。
4. 通过实验结果揭示了LLMs的广泛漏洞，强调了需要更基础的解决方案来确保模型的安全性。

## 本文实验

实验部分详细介绍了AmpleGCG的训练和评估过程。首先，作者从AdvBench中抽取445个有害查询，并使用增强GCG策略收集成功的对抗性后缀。然后，使用这些数据训练AmpleGCG，并在不同的LLMs上进行测试，包括Llama-2-7B-Chat、Vicuna-7B、Mistral-7B-Instruct和GPT-3.5。实验结果显示，AmpleGCG在多个模型上都取得了显著的攻击成功率，并且在对抗困惑度防御方面表现出色。

## 实验结论

实验结果表明，AmpleGCG能够有效地生成对抗性后缀，以攻击多种LLMs。在Llama-2-7B-Chat和Vicuna-7B上，AmpleGCG实现了近100%的ASR，而在GPT-3.5上，通过添加特定的肯定前缀，ASR可达99%。此外，AmpleGCG还能够在几秒钟内为一个有害查询生成200个对抗性后缀，这使得防御变得更加困难。

## 全文结论

本文通过提出AmpleGCG，展示了一种新的、强大的攻击方法，能够有效地揭示LLMs的广泛漏洞。AmpleGCG不仅在攻击开源LLMs方面表现出色，而且能够无缝转移到闭源LLMs，甚至能够绕过基于困惑度的防御机制。这些发现强调了LLMs安全性的重要性，并为未来的研究提供了新的视角和挑战。



注：

AmpleGCG被认为是一个通用的、可转移的生成模型，原因如下：

1. **通用性**:
   * **对任何有害查询的适用性**: AmpleGCG能够根据给定的任何有害查询生成对抗性后缀。这意味着它不依赖于特定的查询类型或格式，而是具有广泛的适用性。
   * **多样化的后缀生成**: 通过训练，AmpleGCG学习了如何捕捉有害查询与对抗性后缀之间的关系，使其能够为不同的输入生成多样化的后缀，从而增加了其攻击的不可预测性。
2. **可转移性**:
   * **跨模型攻击能力**: AmpleGCG在训练时使用的数据来自特定的LLMs（如Llama-2-7B-Chat和Vicuna-7B），但它生成的后缀能够有效地攻击其他未参与训练的模型，包括开源和闭源模型。这表明AmpleGCG能够将其学到的知识迁移到新的模型上，实现跨模型的攻击。
   * **对抗不同防御机制**: 尽管不同的LLMs可能具有不同级别的安全防护和对齐机制，AmpleGCG仍能够在这些模型上实现高攻击成功率。这表明它能够适应和克服不同的安全措施。

AmpleGCG的这些特性使其成为一个强大的工具，不仅能够揭示特定LLMs的漏洞，还能够评估和比较不同模型的安全性。此外，它还为自动化红队测试提供了一种有效的方法，有助于开发者在模型部署前识别和修复潜在的安全风险。





## 阅读总结报告

本篇论文提出了一个名为AmpleGCG的新型生成模型，旨在为大型语言模型（LLMs）生成对抗性后缀，以测试和提高它们的安全性。AmpleGCG通过收集和分析GCG优化过程中的所有候选后缀，学习了一个能够针对任何有害查询快速生成大量后缀的模型。实验结果表明，AmpleGCG在多个LLMs上都取得了高攻击成功率，并且能够有效地对抗基于困惑度的防御机制。这项工作不仅揭示了LLMs的广泛漏洞，也为未来的安全研究和防御策略提供了宝贵的见解。
