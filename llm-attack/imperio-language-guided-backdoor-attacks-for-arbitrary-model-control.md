# Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control

<figure><img src="../.gitbook/assets/image (7) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着深度神经网络（DNNs）在现实世界应用的增加，它们对各种恶意攻击的脆弱性也日益凸显。特别是后门攻击，它通过在训练过程中干预，使模型学习到特定的触发模式，从而在输入中一旦呈现该模式，模型的预测就会被劫持。这种攻击方式隐蔽且对模型在干净输入上的准确性影响不大，对DNN驱动系统的可靠性构成了严重威胁。此外，随着自然语言处理（NLP）模型语言理解能力的增强，它们在后门攻击中的脆弱性也引起了关注。

<figure><img src="../.gitbook/assets/image (8) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 2. 过去方案和缺点

以往的多目标后门攻击方法依赖于为不同的攻击效果设计不同的触发器，并且需要在推理阶段选择相应的触发器。这些方法通常需要特定的辅助输入，如目标类别的标签，并且对于复杂的数据集，如TinyImageNet，它们在保持干净输入准确性的同时实现高攻击成功率方面面临挑战。

<figure><img src="../.gitbook/assets/image (9) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一种名为Imperio的后门攻击方法，它利用大型语言模型（LLMs）的语言理解能力，通过语言引导的指令来控制受害者模型。Imperio通过以下步骤实现：

* 使用预训练的LLM将攻击者提供的指令转换为特征向量。
* 使用条件生成器将指令特征映射到输入空间。
* 设计触发器注入函数，以确保在注入触发器的输入上，受害者模型的决策被覆盖，返回从指令中推断出的期望目标。



Imperio的方案通过以下几个关键步骤实现对受害者模型的控制：

1. **语言模型（LLM）的使用**：
   * Imperio利用预训练的大型语言模型（如GPT-4或Llama-2）来理解攻击者提供的自然语言指令。这些指令描述了攻击者希望模型如何错误地分类输入。
2. **指令到特征向量的转换**：
   * LLM将这些自然语言指令转换为特征向量。例如，指令“evade the weapon detector”会被转换成一个向量，这个向量包含了指令的语义信息。
3. **条件触发器生成器**：
   * 使用一个条件生成器（Gϕ）将这些特征向量映射到输入空间（例如，图像的像素空间）。这个生成器被训练为在保持输入的合法性的同时，最小化对干净输入的扰动（ϵ）。
4. **触发器注入函数**：
   * 设计了一个触发器注入函数（T），它将原始输入（x）和生成的触发器（由Gϕ生成）结合起来，产生一个新的输入，当这个新输入被送入受害者模型时，模型的预测会被劫持到攻击者指定的目标。
5. **联合优化**：
   * Imperio在训练过程中联合优化受害者模型（Fθ）和触发器生成器（Gϕ）。这样，当受害者模型接收到触发器注入的输入时，它应该输出攻击者期望的目标。
6. **词汇变化的泛化**：
   * 为了提高对词汇变化的泛化能力，Imperio使用数据增强技术，通过LLM生成目标类别的替代描述，并训练触发器生成器以确保这些替代描述产生相同的攻击效果。
7. **受害者模型的语义理解**：
   * 为了更好地解释间接指令（如“anything but animals”），Imperio在LLM的指令理解中加入了受害者模型的语义上下文。这可以通过在指令中添加上下文描述来实现，或者通过参数高效的微调将背景知识嵌入到LLM中。
8. **攻击执行**：
   * 在推理阶段，攻击者提供自然语言指令，Imperio生成相应的触发器，并将其注入到干净输入中，然后提交给受害者模型，从而控制模型输出攻击者期望的结果。

通过这种方法，Imperio不仅能够在训练过程中已知的指令上实现高成功率的攻击，而且能够处理训练过程中未知的指令，提供了一种灵活且强大的后门攻击手段。



在Imperio方案中，将特征向量映射到输入空间（例如图像）的过程涉及几个关键步骤，这些步骤确保了从文本描述到图像内容的转换，以便生成能够触发后门攻击的输入。以下是这个过程的详细说明：

1. **特征向量的获取**：
   * 首先，使用预训练的大型语言模型（LLM）处理攻击者提供的自然语言指令。这些指令被转换成特征向量，通常是通过取LLM输出的特定层（如解码器的最后一个隐藏状态）来实现。
2. **条件生成器的设计**：
   * 条件生成器（Gϕ）是一个神经网络，它接受特征向量作为条件输入，并生成与这些条件相对应的图像内容。在Imperio中，这个生成器被训练为在保持原始图像大部分内容不变的情况下，添加或修改特定的视觉元素，这些元素能够触发受害者模型产生错误的预测。
3. **图像空间的映射**：
   * 为了将特征向量映射到图像空间，条件生成器需要理解特征向量中的语义信息，并将其转换为图像的像素变化。这通常涉及到对图像的某些区域进行微小的、几乎不可见的修改，这些修改足以改变模型的预测结果，但对人类观察者来说却难以察觉。
4. **触发器注入**：
   * 一旦条件生成器生成了修改后的图像，这个图像就包含了触发器。这个触发器注入的图像被设计为在视觉上与原始图像相似，但在模型的决策过程中却能显著影响模型的输出。
5. **保持图像合法性**：
   * 在整个过程中，Imperio确保触发器注入的图像保持在合法的像素值范围内，并且视觉上与原始图像足够相似，以避免被检测到。这是通过在触发器注入函数中使用裁剪函数（Π\[0,1]）来实现的，该函数确保所有像素值都在合法范围内。

通过这种方式，Imperio能够将文本描述转换为图像的微小变化，这些变化在视觉上不明显，但却能够有效地操纵受害者模型的预测。这种从文本到图像的映射能力是Imperio攻击方法的核心，它使得攻击者能够通过自然语言指令来控制模型的行为。





### 4. 本文创新点与贡献

* 提出了第一个通过语言引导指令控制受害者模型的后门攻击方法。
* 设计了Imperio，通过专门设计来扩展LLMs的语言理解能力，以适应词汇变化并解释间接指令。
* 在三个数据集、五种攻击和九种防御上进行了广泛的实验，证明了Imperio的有效性。

### 5. 本文实验

作者在FashionMNIST、CIFAR10和TinyImageNet数据集上进行了实验，使用了CNN、Pre-activation ResNet18和ResNet18模型作为受害者分类器。实验结果表明，Imperio在保持干净输入准确性的同时，实现了高攻击成功率。

### 6. 实验结论

Imperio能够有效地解释和执行指令，即使这些指令在训练过程中未被包含。此外，Imperio在数据投毒场景下也表现出有效性，并且对多种代表性防御显示出高韧性。

### 7. 全文结论

Imperio作为一种新的后门攻击方法，利用了预训练语言模型的语言理解能力，实现了通过语言引导的模型控制。这种攻击方法不仅在已知指令上表现出色，而且能够处理训练过程中未知的指令。Imperio的提出可能会激发对自然语言理解进步带来的新威胁的进一步研究。



注：

在本文中，条件生成器（Gϕ）的具体实现细节没有详细描述，但根据上下文，我们可以推断它是一个用于将文本特征向量转换为图像空间变化的神经网络。这个网络的设计和训练是为了满足以下几个关键要求：

1. **条件生成**：
   * Gϕ接受来自LLM的特征向量作为条件输入，这些特征向量包含了攻击者指令的语义信息。条件生成器的目标是根据这些条件信息生成图像的修改版本，这些修改能够触发受害者模型的特定响应。
2. **图像空间映射**：
   * Gϕ需要将文本特征向量映射到图像的像素空间。这通常涉及到对图像的某些区域进行微小的修改，以引入或强化特定的视觉模式，这些模式能够作为后门触发器。
3. **保持图像质量**：
   * 在修改图像时，Gϕ需要确保生成的图像在视觉上与原始图像足够相似，以避免被人类观察者或自动检测系统轻易识别出来。这可能涉及到对图像进行平滑处理，以减少修改带来的视觉突兀感。
4. **训练目标**：
   * Gϕ的训练目标是最小化受害者模型在接收到触发器注入的图像时的预测误差，同时保持对干净输入的准确性。这可能涉及到一个特定的损失函数，该函数衡量了模型在触发器注入图像上的预测与攻击者期望目标之间的差异。
5. **泛化能力**：
   * Gϕ需要具备泛化能力，以便能够处理在训练过程中未见过的指令。这意味着它能够理解和执行新的、复杂的或间接的指令，而不仅仅是在训练数据中直接见过的指令。

在实际应用中，Gϕ可能是一个深度生成模型，如变分自编码器（VAE）、生成对抗网络（GAN）或条件生成网络（如PixelRNN或Conditional GAN），这些模型能够根据条件信息生成高质量的图像。然而，具体的网络架构、层数、激活函数等细节需要根据实验结果和特定任务的需求来确定。





### 阅读总结

本文介绍了Imperio，一种新型的后门攻击方法，它利用大型语言模型的语言理解能力来控制受害者模型。Imperio通过语言引导的触发器生成器，能够在不牺牲干净输入准确性的情况下，实现对模型的高成功率控制。实验结果表明，Imperio在多个数据集和模型架构上都表现出了强大的攻击能力和对防御的韧性。这一研究为理解NLP模型在后门攻击中的潜在脆弱性提供了新的视角，并可能推动相关防御策略的发展。
