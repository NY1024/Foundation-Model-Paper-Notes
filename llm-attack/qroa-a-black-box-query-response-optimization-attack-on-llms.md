# QROA: A Black-Box Query-Response Optimization Attack on LLMs

<figure><img src="../.gitbook/assets/image (8) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>



### 1. 研究背景

近年来，大型语言模型（LLMs）在自然语言处理、文本生成和软件开发等领域取得了显著进展。然而，这些模型在被操纵时可能会生成有害内容，例如通过所谓的“越狱”提示使模型执行不当行为。尽管已有研究致力于通过训练模型避免有害输出并拒绝不当请求，但LLMs仍然容易受到精心设计的攻击，这些攻击能够绕过保护机制。

### 2. 过去方案和缺点

以往的越狱攻击方法包括手工编写和算法生成的复杂攻击，这些攻击能够巧妙地绕过LLMs的保护机制。一种显著的进步是开发了基于令牌级别的优化方法，例如基于梯度的离散优化方法。然而，这些方法通常需要访问模型的内部信息，如logit信息，在生产环境中不常见，限制了它们在现实世界场景中的应用。

### 3. 本文方案和步骤

本文介绍了一种名为查询响应优化攻击（QROA）的新方法，它是一种基于优化的策略，通过黑盒、仅查询的交互来利用LLMs。QROA通过迭代更新令牌来最大化设计好的奖励函数，而不需要访问模型的logit信息或其他内部数据。QROA的步骤包括：

* 定义攻击为强化学习问题。
* 设计评估模型输出有效性的奖励函数。
* 通过Q学习算法细化模型，一次调整一个令牌来最大化奖励。

### 4. 本文创新点与贡献

QROA的主要贡献包括：

* 提供了一种黑盒和仅查询的方法，通过标准查询响应界面操作。
* 不基于人为设计的模板，使攻击更具有通用性和灵活性。
* 利用强化学习策略，通过迭代的令牌级优化来发现触发模型恶意行为的触发器。
* 在Vicuna、Falcon和Mistral等不同LLMs上的测试显示，攻击成功率（ASR）超过80%。

### 5. 本文实验

实验使用了AdvBench基准，包括500个通过特定指令表达的有害行为实例。实验选取了50个行为进行分析，并评估了VICUNA-1.3、Mistral-Instruct、FALCON-Instruct和LLAMA2-Chat等模型。实验设置了不同的查询预算，并使用了攻击成功率（ASR）作为主要评估指标。

### 6. 实验结论

实验结果表明，随着查询预算的增加，攻击成功率（ASR）显著提高。此外，不同的LLMs表现出不同程度的非确定性，这强调了在黑盒对抗性设置中预测和控制这些模型行为的挑战。特别是，针对LLama2-7B-chat模型的攻击由于其强化的安全对齐和一致的响应行为而面临了独特的挑战。

### 7. 全文结论

QROA是一种新颖的方法，通过黑盒查询交互来利用LLMs。它不需要内部模型访问或精心设计的模板，使其在现实世界场景中高度适用。QROA使用强化学习和迭代的令牌级优化来识别触发LLMs恶意行为的触发器。实验表明，即使在经过抵抗性微调的模型上，QROA也具有高效率，这突出了LLM在商业和私人部门部署时的重大安全影响，并强调了需要更好的防御机制。

### 阅读总结

本文提出了一种新的针对大型语言模型的攻击方法——查询响应优化攻击（QROA）。该方法通过黑盒优化，不需要模型内部信息，展示了在标准查询响应界面下对LLMs进行攻击的可能性。QROA利用强化学习策略，通过迭代优化令牌来发现有效的攻击触发器。实验结果表明，该方法在不同的LLMs上都取得了较高的攻击成功率，对LLMs的安全性提出了重要的警示，并为未来的安全评估和防御机制的发展提供了有价值的见解。
