# Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Application

<figure><img src="../.gitbook/assets/image (239).png" alt=""><figcaption></figcaption></figure>

##

### 1. 研究背景

随着人工智能（AI）领域的快速发展，大型语言模型（LLMs）在理解和响应自然语言方面变得越来越能胜任，这导致了它们在类似助手的应用程序中的广泛商业部署。然而，随着这些应用程序的普及，一种新的安全威胁——“提示注入攻击”（Prompt Injection Attacks）出现了，这种攻击通过自然语言输入操纵LLMs，对这些应用程序的安全性构成了重大威胁。

<figure><img src="../.gitbook/assets/image (240).png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (241).png" alt=""><figcaption></figcaption></figure>

### 2. 过去方案和缺点

传统的防御策略，包括输出和输入过滤以及使用分隔符，已被证明是不充分的。输出过滤技术在检测和减轻攻击的有害影响方面能力不足，而输入过滤技术无法有效防止间接提示注入，因为它们可以通过各种方式隐藏或编码提示来绕过。使用分隔符进行防御同样不能有效防止攻击，而双重LLM模型虽然增加了应用程序构建的复杂性并影响了用户体验，但也不能完全保证防止攻击。

<figure><img src="../.gitbook/assets/image (242).png" alt=""><figcaption></figcaption></figure>

###

<figure><img src="../.gitbook/assets/image (243).png" alt=""><figcaption></figcaption></figure>

## 3. 本文方案和步骤

本文提出了一种名为“签名提示”（Signed-Prompt）的新方法，通过授权用户对命令段中的敏感指令进行签名，使LLM能够辨别可信任的指令来源。文章详细介绍了签名提示的概念，包括其基本架构和通过提示工程和微调LLMs实现的具体步骤。



“签名提示”（Signed-Prompt）是一种防御策略，旨在保护大型语言模型（LLMs）集成应用程序免受提示注入攻击。这种方法通过授权用户对敏感指令进行签名，使LLM能够区分可信任的指令来源。下面是签名提示方法的具体实现步骤：

1. **问题分析**：
   * 分析提示注入攻击的模式，了解攻击者如何利用LLMs的灵活性来覆盖或破坏应用程序的原始目的，或泄露内部信息。
2. **基本概念**：
   * 签名提示的核心概念是对指令进行签名，即将原始指令替换为在自然语言中很少出现的字符组合。这样，只有授权用户的指令会被签名，而攻击者的指令则不会。
3. **基本架构**：
   * 实现签名提示需要两个主要模块：一个用于签名用户指令的编码器（Encoder），以及一个能够理解签名指令的调整后的LLM（Adjusted LLM）。
4. **编码器（Encoder）**：
   * 编码器的作用是将包含特定命令的原始指令转换为签名指令。这可以通过传统的字符替换（Traditional Character Replacement, TCR）、微调LLMs或基于通用LLMs的提示工程来实现。本文选择了基于ChatGPT-4的提示工程方法来实现编码器，因为它在处理多语言、多样化表达和隐含意义方面表现出较好的灵活性和效率。
5. **调整后的LLM（Adjusted LLM）**：
   * 调整后的LLM需要能够区分未签名的原始指令和已签名的指令，并且只在接收到签名指令时输出实际格式化的指令。这可以通过提示工程或微调预训练的LLM来实现。
6. **实施和性能分析**：
   * 通过实验验证签名提示方法的有效性。实验中，研究者构建了一个“删除命令数据集”（Delete Command Dataset），包含多种语言、表达方式和含义，以测试编码器处理和解释广泛语言变化的能力。
   * 使用数据集对两个通过提示工程和微调方法构建的支持签名提示的LLM进行测试，比较实际输出与预期输出，计算LLM响应普通用户的签名命令的正确率，以及在面对攻击者未签名的原始命令时传递未授权指令的成功率。

通过上述步骤，签名提示方法能够确保外部恶意攻击命令在大多数情况下不会被执行，即使在LLM微调不理想的情况下，也能保持其防御效果的稳定性。这种方法为LLM集成应用程序提供了一种有效的防御策略，防止提示注入攻击。



### 4. 本文创新点与贡献

* **创新方法**：提出了签名提示方法，通过签名敏感指令来区分授权用户和攻击者的指令。
* **基本架构**：实现了一个编码器来签名用户指令，以及一个调整后的LLM来理解签名指令。
* **实施策略**：通过提示工程和微调方法实现了签名提示的架构，并在实验中证明了其有效性。

### 5. 本文实验

实验中，研究者实现了签名提示编码器，并通过ChatGPT-4进行了提示工程，以验证编码器在处理多种语言、表达方式和含义时的有效性。此外，通过构建支持签名提示的LLM（通过提示工程和微调），并使用包含签名用户命令和未签名攻击者命令的数据集进行测试，评估了这些LLM在防御提示注入攻击方面的性能。

### 6. 实验结论

实验结果表明，无论是通过提示工程还是微调方法构建的LLM，都能在防御提示注入攻击方面表现出色，攻击成功率为0%。这证明了签名提示方法在防止执行攻击者命令方面具有显著的有效性。

### 7. 全文结论

本文针对LLM集成应用程序中的提示注入攻击问题，提出了签名提示防御策略，使应用程序能够辨别敏感命令是否来自信任的用户。通过实验验证了签名提示方法的有效性，并为未来研究提供了新的方向，包括探索更高效的实现方法、适应新型攻击策略和与其他安全措施集成。

### 阅读总结

本文深入分析了LLM集成应用程序面临的提示注入攻击问题，并提出了签名提示方法作为解决方案。通过实验，文章展示了签名提示在防御攻击方面的有效性，并为未来的研究和应用提供了新的思路。这种方法不仅在现有应用程序框架内提供了独特的视角，而且为AI安全研究领域贡献了新的思考和框架。未来的研究可以集中在提高签名提示框架的实现效率、适应新的攻击策略以及与其他安全措施集成，以进一步提高LLM集成应用程序的安全性。
