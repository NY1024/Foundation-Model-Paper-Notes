# Vaccine: Perturbation-aware Alignment for Large Language Model

<figure><img src="../.gitbook/assets/image (4) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着大型语言模型（LLMs）在问答任务中的成功应用，确保这些模型在实际部署中的回答既无害又符合人类偏好成为一个挑战。为了解决这个问题，模型对齐技术被广泛采用，通过在安全示范数据集上进行监督式微调（SFT），使LLM学会如何以无害且有帮助的方式响应人类指令。然而，用户微调服务为服务提供商带来了严重挑战，因为用户可以上传任意示范数据进行微调，这可能导致模型对齐被破坏。

### 2. 过去方案和缺点

过去的对齐技术通常包括在安全示范数据集上进行SFT。然而，这种方法在用户微调阶段面临新的攻击面，即少量有害数据可以轻易地欺骗微调过程，导致对齐破裂。此外，现有的解决方案要么需要额外的计算资源，要么需要在对齐阶段访问用户微调数据，这在实际应用中是不现实的。

<figure><img src="../.gitbook/assets/image (5) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一种名为Vaccine的对齐技术，它通过在对齐阶段逐步添加精心设计的扰动来产生不变的隐藏嵌入，从而使嵌入能够抵抗用户微调数据中的有害扰动。Vaccine的核心思想是在对齐阶段通过两次前向/后向传播来实现扰动感知对齐。首先，通过第一次传播记录梯度信息，然后在第二次传播中添加扰动并更新模型权重。

### 4. 本文创新点与贡献

* 提出了有害嵌入漂移现象（Harmful Embedding Drift, HED），并将其识别为微调后对齐破裂效应的根本原因。
* 在不依赖用户微调数据的情况下，开发了一种鲁棒的LLM对齐解决方案（Vaccine），以增强对齐模型对部分有害用户数据微调的抵抗力。
* 在多样化的设置中（例如，用户微调数据中的有害比例、样本数量）对Vaccine的有效性、超参数分析和消融研究进行了评估，结果表明Vaccine在不同设置中始终优于基线对齐解决方案。



## Vaccine对齐技术详细说明

### 核心概念

Vaccine是一种针对大型语言模型（LLMs）的对齐技术，旨在解决用户微调过程中可能引入的有害数据对模型对齐状态的破坏问题。Vaccine的核心思想是在模型的对齐阶段引入扰动，以增强模型对后续用户微调中潜在有害数据的抵抗力。

### 技术原理

Vaccine基于以下观察：在用户微调过程中，即使是少量的有害数据也可能导致模型的对齐状态被破坏，这种现象被称为有害嵌入漂移（Harmful Embedding Drift, HED）。为了对抗这种漂移，Vaccine在对齐阶段通过添加扰动来训练模型，使得模型的隐藏嵌入（embedding）对这些扰动具有不变性。

### 实施步骤

1. **对齐阶段的扰动引入**：在对齐阶段，Vaccine首先对模型进行一次前向传播，记录每个隐藏层的梯度信息，但不更新权重。然后，在第二次前向传播中，根据第一次传播得到的梯度信息，向模型的隐藏嵌入添加扰动。
2. **扰动的优化**：Vaccine通过解决一个最小-最大问题来找到最优的扰动。这个问题的目标是在保持模型对齐损失的同时，最大化模型对潜在有害扰动的抵抗力。扰动被限制在一个L2范数球内，以确保模型的稳定性。
3. **微调阶段的鲁棒性**：通过在对齐阶段引入的扰动，Vaccine使得模型在后续的微调阶段能够更好地抵抗用户数据中的有害扰动，即使这些数据包含有害信息。

### 创新点

* **扰动感知对齐**：Vaccine通过在对齐阶段引入扰动，使模型学会在面对潜在有害数据时保持对齐状态。
* **无需用户数据**：Vaccine不需要在对齐阶段访问用户微调数据，这使得它在实际应用中更加可行。
* **鲁棒性与性能的平衡**：Vaccine在提高模型对有害数据的鲁棒性的同时，尽量保持对良性数据的推理能力，减少了对下游任务性能的影响。

### 贡献

Vaccine为LLMs提供了一种新的对齐方法，它不仅提高了模型在面对有害数据时的安全性，而且通过实验验证了其在多种设置下的有效性。这种方法为LLMs的安全部署和用户微调服务提供了一种新的解决方案。





### 5. 本文实验

实验在开源主流LLMs（如Llama2、Opt、Vicuna）上进行，结果表明Vaccine能够显著降低有害分数（最高降低9.8%），同时在用户微调数据包含有害指令时，对下游任务的性能损失微不足道（最高1.8%）。

### 6. 实验结论

Vaccine在保持对良性提示的推理能力的同时，显著提高了对有害提示的鲁棒性。在不同的有害比例和样本数量下，Vaccine都表现出了优于标准对齐技术的有害分数降低效果。

### 7. 全文结论

本文通过提出Vaccine，为LLM对齐提供了一种新的安全保障方法，有效地缓解了用户微调可能带来的安全风险。Vaccine通过在对齐阶段引入扰动，增强了模型对有害数据的抵抗力，同时保持了对良性数据的响应能力。

### 阅读总结

本文针对大型语言模型在用户微调服务中可能面临的安全风险，提出了一种新的对齐技术Vaccine。通过在对齐阶段引入扰动，Vaccine能够有效地提高模型对有害数据的鲁棒性，同时保持对良性数据的响应能力。实验结果表明，Vaccine在多种设置下都优于现有的对齐技术，为LLM的安全部署提供了一种有效的解决方案。
