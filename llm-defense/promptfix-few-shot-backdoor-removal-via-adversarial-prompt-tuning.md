# PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning

<figure><img src="../.gitbook/assets/image (6).png" alt=""><figcaption></figcaption></figure>

### 阅读总结报告

#### 1. 研究背景

预训练语言模型（PLMs）因其出色的性能在过去几年中受到了极大的关注。然而，研究表明这些模型容易受到后门攻击，即通过在输入中注入触发模式，攻击者可以控制模型的行为。这对于通过少量样本微调得到的NLP模型构成了严重的安全风险。

#### 2. 过去方案和缺点

现有的后门移除方法通常分为两个阶段：触发器反转和触发器非学习。这些方法依赖于准确的触发器反转，但找到确切的触发器既困难又成本高。此外，两阶段设计不适合少数样本学习设置，因为微调通常需要较大的数据集以避免过拟合。

<figure><img src="../.gitbook/assets/image (1) (1).png" alt=""><figcaption></figcaption></figure>

#### 3. 本文方案和步骤

本文提出了PromptFix，一种新颖的后门缓解策略，通过对抗性提示调整在少数样本设置中实现。PromptFix保持模型参数不变，只使用两组额外的软令牌来近似触发器并对其进行抵消。具体步骤包括：

* 使用对抗性优化来逐步识别和移除后门。
* 引入软令牌而不是硬令牌，以表达触发器并消除枚举可能的后门配置的需要。
* 通过提示调整而不是微调来移除后门，保持原始模型参数不变，并减少在少数样本设置中的过拟合风险。

#### 4. 本文创新点与贡献

* **对抗性提示调整**：通过对抗性优化逐步识别和移除后门，而不是一次性精确反转触发器。
* **软令牌的使用**：代替硬令牌，提供更大的表达性，减少了对固定触发器注入方法的需求。
* **适应性**：PromptFix能够自动适应不同的后门配置，无需手动强调搜索空间中的特定条件。
* **与领域适应的兼容性**：可以轻松地将PromptFix集成到任何提示调整过程中，类似于对抗性训练。

#### 5. 本文实验

* 使用TrojAI数据集评估PromptFix，这是一个为后门检测竞赛设计的模型后门对数据集。
* 在极端少数样本场景下（2或4个训练样本）测试PromptFix。
* 将PromptFix与DBS方法进行比较，DBS是一种代表性的两阶段移除方法。

#### 6. 实验结论

PromptFix在保持原始模型准确性的同时，显著降低了后门的攻击成功率（ASR）。即使在领域偏移的情况下，PromptFix也显示出较低的ASR和较高的清洁准确性。此外，PromptFix在不同的后门攻击中表现出了强大的性能。

#### 7. 全文结论

PromptFix是首个针对后门移除的提示调整方法，专门为少数样本调整设计。它在减少ASR方面与现有最佳方法相当或更优，同时更好地保持了模型性能。PromptFix的对抗性提示调整公式使其能够适应领域适应，并轻松地增强任何提示调整过程。

#### 阅读总结

本文提出了PromptFix，一种针对预训练语言模型后门攻击的新颖解决方案。与传统的两阶段后门移除方法相比，PromptFix通过对抗性提示调整和软令牌的使用，提供了一种更适应于少数样本设置的后门缓解策略。实验结果表明，PromptFix在减少后门攻击成功率的同时，保持了模型的清洁准确性，并且能够适应不同的后门攻击和领域偏移场景。这项工作为负责任的AI模型发布提供了一种有效的后门修复方法，并对提高NLP模型的安全性具有重要意义。
