# Trojan Detection in Large Language Models: Insights from The Trojan Detection Challenge

<figure><img src="../.gitbook/assets/image (12).png" alt=""><figcaption></figcaption></figure>

### 研究背景

大型语言模型（LLMs）在多个领域展现出卓越能力，但它们对木马（trojan）或后门攻击的脆弱性构成了显著的安全风险。本文探讨了2023年木马检测竞赛（TDC2023）中的挑战和所获得的见解，该竞赛专注于识别和评估针对LLMs的木马攻击。研究的重点是区分预期和非预期触发器的难度，以及在现实世界场景中逆向工程木马的可行性。

### 过去方案和缺点

以往的研究中，对于LLMs的审计方法存在挑战，包括生成有害输出、加剧刻板印象和泄露私人信息等不期望行为的检测。这些行为的风险包括潜在的系统性失败，例如删除文件或清空银行账户。此外，开发可靠的审计方法以发现这些可能很少见、违反直觉且需要昂贵的、针对行为的审计技术也很复杂。

### 本文方案和步骤

本文提出了一种通过离散优化的审计方法来识别和评估LLMs中的行为，专注于典型和违反直觉的输出。该方法通过制定一个审计目标，捕捉特定的目标行为，允许灵活且有效地识别LLMs中的潜在问题。然而，鉴于导致这些行为的提示的稀疏性、离散性和高维特性，以及查询LLMs的计算成本，该优化问题的计算需求很大。

### 本文创新点与贡献

* 提出了一种新的审计方法，通过离散优化来识别和评估LLMs中的潜在问题。
* 在TDC2023的背景下，分析了检测和减轻木马攻击的高级方法，强调了强大的安全措施的重要性。
* 通过结合审计非预期行为和木马攻击检测，旨在提高LLMs的安全性和功能性，保护它们免受广泛的漏洞影响。

### 本文实验

实验部分集中在TDC2023的木马检测竞赛上，参与者需要开发一个复杂的检测系统，能够识别嵌入在大型语言模型中的木马。竞赛提供了包含1000个木马的LLM，每个木马由一个独特的（触发器，目标）对定义。主要挑战是基于给定的目标字符串进行触发器的逆向工程。

### 实验结论

实验结果显示，实现高召回率（Recall）比分获得高逆向工程攻击成功率（REASR）要显著更具挑战性。竞赛中表现最好的方法的召回率大约为0.16，与从与给定训练前缀类似的分布中随机抽样句子的简单基线相当。这一发现引发了关于在仅给定有害目标的情况下，检测和恢复模型中插入的木马的可行性的问题。

### 全文结论

本文探讨了在TDC2023的背景下，针对LLMs的木马或后门攻击问题。分析强调了识别预期和非预期触发器的挑战，以及在现实世界场景中逆向工程木马的难度。尽管竞赛没有完全解决这个问题，但它为未来在这个领域的研究提供了有价值的见解，并为确保LLMs在现实世界应用中的安全性和可靠性奠定了基础。

###
