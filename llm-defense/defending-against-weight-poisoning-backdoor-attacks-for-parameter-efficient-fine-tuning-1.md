# Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning

## 研究背景

随着语言模型参数数量的快速增长，例如ChatGPT2、LLaMA、GPT-4和Vicuna等，使用有限的计算资源对整个模型参数进行微调变得越来越不切实际。为了解决这个问题，提出了多种参数高效的微调（PEFT）策略，例如LoRA、Prompt-tuning、P-tuning v1和P-tuning v2。这些策略通过更新模型的有限参数集或一些额外的参数，为语言模型在不同领域和下游任务中的应用提供了一种有效且高效的方法。然而，PEFT的这种性质可能会带来安全问题，因为它只更新了模型的子集或少数额外的参数，这可能使得模型在面对权重投毒后门攻击时更加脆弱。

## 过去方案和缺点

过去的研究中，为了防御权重投毒后门攻击，通常采用全参数微调方法，通过在干净数据集上微调受害模型来“灾难性地忘记”隐藏在参数中的后门。然而，PEFT策略由于只更新了有限的模型参数集，使得清除后门变得更加困难。此外，现有的PEFT方法在面对后门攻击时的脆弱性尚未得到充分的研究和解决。

## 本文方案和步骤

本文提出了一种名为Poisoned Sample Identification Module（PSIM）的方法，该方法利用PEFT来识别通过置信度判断的投毒样本，从而为权重投毒后门攻击提供强大的防御。具体步骤如下：

1. 利用PEFT训练PSIM，通过随机重置样本标签来识别投毒样本。
2. 在推理过程中，极端的置信度被用作投毒样本的指示器，而其他样本则被认为是干净的。
3. 通过实验验证PSIM在文本分类任务、五种微调策略和三种权重投毒后门攻击方法上的有效性。

## 本文创新点与贡献

* 本文首次探索了PEFT在权重投毒后门攻击中的安全影响，并发现这些策略相比全参数微调更加脆弱。
* 从新颖的角度提出了PSIM，该模块巧妙地利用了PEFT方法和样本标签随机重置的特点，开发了一种基于置信度的识别方法，能够有效地检测投毒样本。
* 在包含各种后门触发器和复杂权重投毒攻击场景的文本分类任务上评估了我们的防御方法，所有结果表明我们的防御方法在防御权重投毒后门攻击方面是有效的。

## 本文实验

实验部分详细说明了在SST-2、CR和COLA三个文本分类数据集上验证PEFT方法安全性和所提出防御策略性能的过程。实验使用了三种代表性的后门攻击方法（BadNet、InSent和SynAttack）以及三种代表性的防御方法（ONION、Back-Translation和SCPD）。实验结果显示，PEFT方法在面对权重投毒后门攻击时的攻击成功率接近100%，而PSIM能够有效地检测到投毒样本并减轻这些样本对受害模型的影响，同时保持分类准确率。

## 实验结论

实验结果表明，PEFT方法在面对权重投毒后门攻击时更加脆弱，而PSIM能够有效地检测到投毒样本并减轻这些样本的影响。此外，PSIM在多种攻击场景下都表现出了良好的泛化能力和准确性。

## 全文结论

本文通过实验验证了PEFT在权重投毒后门攻击面前的脆弱性，并提出了有效的防御方法PSIM。PSIM通过利用PEFT的特点和样本标签的随机重置，能够有效地识别和防御权重投毒后门攻击。未来的研究可以进一步探索PSIM在更大规模的语言模型和更复杂的攻击场景中的应用。

## 阅读总结报告

本篇论文针对参数高效的微调（PEFT）策略在面对权重投毒后门攻击时的安全性问题进行了深入研究。研究表明，相比于全参数微调，PEFT更容易受到此类攻击的影响。为了解决这一问题，作者提出了一种名为PSIM的防御模块，该模块通过分析模型的置信度来判断样本是否被投毒，从而有效地提高了模型的安全性。通过在多个数据集和攻击方法上的实验，PSIM证明了其在检测和防御权重投毒后门攻击方面的有效性。这项工作不仅揭示了PEFT策略的潜在安全风险，也为提高语言模型的安全性提供了有价值的解决方案。未来的研究可以在这一基础上进一步探索和完善相关的防御机制。
