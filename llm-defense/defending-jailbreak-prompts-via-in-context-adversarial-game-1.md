# Defending Jailbreak Prompts via In-Context Adversarial Game

<figure><img src="../.gitbook/assets/image (3) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

大型语言模型（LLMs）在多种应用中展现出卓越的能力，但它们的安全性问题，尤其是对抗越狱攻击（jailbreak attacks）的脆弱性，仍然是一个重要的安全关注点。越狱攻击通过在输入数据中附加特意设计的提示（prompt），诱导LLMs生成可能有害或恶意的内容。这些攻击源于LLMs在训练过程中使用的相互冲突的学习目标，例如指令遵循和为安全而拒绝回答。现有的防御策略，如提示编辑、过滤、微调和安全指令的实施，虽然在实现防御目标时面临不同的挑战，但它们在全面覆盖越狱提示方面存在不足，导致防御不完整。

### 2. 过去方案和缺点

过去的防御策略包括：

* **提示编辑**：随机修改输入查询，但可能影响对非恶意输入的响应准确性。
* **过滤**：输入和输出过滤可能导致LLMs过度防御，拒绝良性查询。
* **微调**：通过将成功的越狱提示与拒绝响应关联起来，提高模型对齐，但缺乏有效的攻击策略，无法实现真正的对抗性。
* **安全指令实施**：通过在输入前后附加安全指令来提高模型对齐，但这些方法要么缺乏训练组件，要么依赖于静态数据集来制定安全指令，无法提供全面的防御。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一种名为In-Context Adversarial Game (ICAG)的方法，通过代理学习进行对抗游戏，动态扩展知识以防御越狱攻击，无需微调模型。ICAG包括两个代理：攻击代理和防御代理，它们通过与目标LLM的交互而进化。攻击代理通过洞察提取和越狱提示的精炼来增强攻击能力，而防御代理则通过反思和洞察提取来加强防御策略。这个过程包括迭代的攻击和防御周期，通过每次迭代的反馈来增强双方的能力。

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

上下文对抗游戏（In-Context Adversarial Game，简称ICAG）是一种新颖的方法，旨在提高大型语言模型（LLMs）对越狱攻击的防御能力。ICAG的核心思想是通过代理学习（agent learning）来模拟攻击者和防御者之间的对抗过程，从而在不进行模型微调的情况下动态增强模型的安全性。以下是ICAG的详细说明：

#### 1. 代理学习（Agent Learning）

ICAG利用代理学习的概念，创建了两个代理：攻击代理（Attack Agent）和防御代理（Defense Agent）。这两个代理通过与目标LLM的交互来学习和进化，以改进它们的攻击和防御策略。

#### 2. 攻击代理（Attack Agent）

攻击代理的目的是生成能够绕过LLM安全机制的越狱提示（jailbreak prompts）。它通过以下步骤进行操作：

* **洞察提取（Insight Extraction）**：分析失败的越狱提示，通过与成功的越狱提示进行比较，提取成功的攻击模式。
* **越狱提示精炼（Refinement of Jailbreak Prompts）**：使用提取的洞察来改进失败的越狱提示，使其能够成功绕过当前的防御。

#### 3. 防御代理（Defense Agent）

防御代理的目标是制定有效的安全指令，以加强LLM的防御能力。它通过以下步骤进行操作：

* **反思（Reflection）**：识别导致有害输出的提示，并生成自我反思，以理解为何某些提示能够成功绕过防御。
* **洞察提取**：从成功防御的提示中提取洞察，以改善未来的防御策略。

#### 4. 对抗游戏过程

ICAG的过程包括多个迭代，每个迭代都包括以下步骤：

1. 输入一组手动创建的越狱提示到目标LLM。
2. 使用基于GPT-4的评估器分析结果，区分成功和失败的越狱尝试。
3. 将失败和成功的越狱提示传递给攻击代理，攻击代理通过洞察提取来增强失败的提示。
4. 将精炼后的越狱提示和成功的尝试传递给防御代理，以创建针对性的安全指令。
5. 这些安全指令作为系统提示应用于目标LLM，并在后续迭代中不断更新。

#### 5. 实验评估

通过实验评估，ICAG在多种LLMs上展示了显著的防御效果，能够有效降低越狱成功率。此外，ICAG还显示出在不同LLMs之间的防御策略转移性。

#### 6. 创新点与贡献

ICAG的主要创新点在于：

* 引入了上下文对抗游戏的概念，使得LLMs能够在不进行微调的情况下动态增强安全性。
* 应用代理学习来自动探索和改进攻击和防御策略，这在LLMs的安全领域是首次尝试。
* 证明了ICAG在不同LLMs之间的有效性和转移性，展示了其作为通用防御机制的潜力。

#### 7. 局限性与未来工作

尽管ICAG在防御越狱攻击方面取得了显著成果，但它依赖于相对静态的对手模型，可能在面对更复杂、不断适应的攻击策略时受限。此外，ICAG的成功也依赖于初始提示集的质量和多样性。未来的工作可以探索更可扩展的策略，扩展到多模态环境，并提高对抗游戏对动态威胁环境的适应性。





### 4. 本文创新点与贡献

* **首次提出**：在LLMs中提出上下文对抗游戏，动态加强攻击和防御，无需模型微调。
* **代理学习应用**：首次将代理学习应用于越狱攻击领域，自动探索LLMs在攻击和防御方面的知识。
* **跨模型转移性**：通过全面测试四种不同的LLMs，证明了所提方法的有效性及其在不同模型之间的防御能力转移性。

### 5. 本文实验

实验使用了三个数据集来评估ICAG的性能，并与其他基线方法进行比较。实验涉及多种开放权重和闭源LLMs，如GPT-3.5、Llama-2-7B等。实验结果表明，ICAG在减少越狱成功率（JSR）方面表现出色，并且在不同模型上具有一致的转移性。

### 6. 实验结论

ICAG在防御越狱攻击方面表现出显著的有效性，能够显著降低JSR，并且在不同LLMs之间具有很好的转移性。然而，ICAG也存在过度防御的问题，这可能会影响LLMs的正常交互。

### 7. 全文结论

本文通过引入ICAG，提出了一种新的LLMs防御机制，该机制能够在不进行模型微调的情况下，通过动态对抗游戏来加强攻击和防御能力。尽管存在一些局限性，如对静态对手模型的依赖、初始提示集的质量依赖以及主要关注文本交互，但ICAG在防御越狱攻击方面取得了显著进展，并为未来的研究提供了新的方向。



注：

上下文对抗游戏（ICAG）的设计目的是同时提高攻击和防御能力。通过这种对抗性的训练，攻击代理（Attack Agent）和防御代理（Defense Agent）都能够通过迭代的对抗过程学习和进化。然而，本文的主要焦点和贡献在于提高LLMs的防御能力，原因如下：

1. **防御目标**：研究的主要目标是增强LLMs对越狱攻击的抵抗力。虽然攻击代理的改进有助于更好地理解攻击模式，但这些改进最终被用于强化防御代理的策略，以更有效地防御未来的攻击。
2. **安全性提升**：在实际应用中，提高LLMs的安全性是至关重要的，因为这关系到防止恶意内容的生成和传播。通过ICAG，研究者们能够开发出一种机制，使LLMs在面对不断变化的攻击手段时，能够更有效地保护自己。
3. **转移性**：ICAG的一个重要特点是其防御策略的转移性。这意味着在一个LLM上训练得到的防御策略可以有效地转移到其他LLMs上。这种转移性对于构建通用的防御机制尤为重要。
4. **实验结果**：实验结果表明，ICAG在降低越狱成功率（JSR）方面表现出色，这直接反映了其在防御方面的有效性。虽然攻击代理的能力也得到了提升，但这种提升是为了更好地测试和强化防御策略。
5. **伦理和责任**：在研究LLMs的安全性时，研究者们有责任确保这些模型不会被用于恶意目的。通过提高防御能力，研究者们有助于确保LLMs在各种应用中的安全和可靠性。

总结来说，虽然ICAG同时提升了攻击和防御能力，但其核心目的和实际应用价值在于提高LLMs的防御能力，以确保它们在面对潜在的安全威胁时能够更加稳固。





### 阅读总结

本文针对LLMs在安全性方面的挑战，特别是越狱攻击，提出了一种创新的防御策略。通过引入对抗游戏的概念，本文不仅提高了LLMs的防御能力，还展示了这种策略在不同模型之间的有效转移性。尽管存在一些局限性，但本文的研究为LLMs的安全研究领域提供了宝贵的贡献，并为未来的工作指明了方向。

