# Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landsc

<figure><img src="../.gitbook/assets/image (8) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

大型语言模型（LLMs）如GPT-4、LLaMA-2和Vicuna等在各种应用中的成功应用，使得它们成为了生成性AI工具的重要组成部分。这些模型通常通过人类反馈的强化学习（RLHF）等高级训练技术与人类价值观对齐，以减少伤害和滥用。然而，近期研究发现，这些对齐的LLMs容易受到旨在绕过内置安全防护的对抗性越狱攻击（jailbreak attacks）的影响。

### 2. 过去方案和缺点

过去的越狱攻击防御方法包括基于困惑度的过滤（PPL）、平滑LLM（SmoothLLM）、Erase-Check和Self-Reminder等。这些方法在检测某些类型的攻击（如GCG）方面取得了一定的成功，但在抵抗所有类型的越狱攻击方面存在局限性，或者对良性查询有显著的负面影响。例如，Erase-Check虽然在恶意查询上表现良好，但会错误分类许多良性用户查询，使得防御过于保守和不实用。

<figure><img src="../.gitbook/assets/image (9) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一种名为Gradient Cuff的方法，通过检查输入用户查询的拒绝损失（refusal loss）和估计损失函数的梯度范数来检测越狱提示。Gradient Cuff利用拒绝损失景观的独特特性，提出了一个两步越狱检测算法：

1. **采样基础拒绝**：首先通过检查fθ(x)是否小于0.5来拒绝用户查询x。如果为真，则拒绝x；否则，进入第二阶段。
2. **梯度范数拒绝**：在第二阶段，如果估计梯度gθ(x)的范数大于可配置阈值t，即∥gθ(x)∥ > t，则认为x存在越狱尝试。

### 4. 本文创新点与贡献

* 正式提出了LLMs的拒绝损失函数概念，并探索了其在良性和恶意查询上的平滑性和值的特性。
* 在两种对齐的LLMs（LLaMA-2-7B-Chat和Vicuna-7B-V1.5）和六种越狱攻击（GCG、AutoDAN、PAIR、TAP、Base64和LRL）上的实验表明，Gradient Cuff能够在保持对良性用户查询的可接受拒绝率的同时，显著提高LLM对恶意越狱查询的拒绝能力。
* 展示了Gradient Cuff与基于提示工程的对齐策略（如Self-Reminder）的互补性，结合使用时可以显著提高性能。

### 5. 本文实验

实验在两种对齐的LLMs上进行，针对六种越狱攻击方法。结果表明，Gradient Cuff在减少攻击成功率（ASR）方面表现出色，平均降低了74.3%至24.4%。此外，与现有的防御方法相比，Gradient Cuff在保持较低的良性查询拒绝率的同时，实现了更高的恶意查询拒绝率。

### 6. 实验结论

Gradient Cuff在检测和防御不同类型的越狱攻击方面表现出色，提供了稳定且强大的防御功能。与现有的防御方法相比，Gradient Cuff在良性查询和恶意查询上都实现了更高的拒绝率，证明了其有效性。

### 7. 全文结论

本文通过定义和研究LLMs的拒绝损失函数，提出了Gradient Cuff方法，该方法通过检查拒绝损失的函数值和梯度范数来检测越狱尝试。广泛的实验验证了Gradient Cuff在两种对齐的LLMs上的有效性，实现了在保持良好实用性的同时，对越狱攻击的高效检测。未来的研究方向包括进一步提高对自适应攻击的检测性能和降低Gradient Cuff的推理成本。



注：\


在论文中提出的Gradient Cuff方法通过检查输入用户查询的拒绝损失（refusal loss）和估计损失函数的梯度范数来检测越狱提示，这种方法有效的原因在于以下几个关键观察和设计决策：

1. **拒绝损失函数的定义**：
   * 拒绝损失函数（refusal loss function）ϕθ(x)定义为LLM对于给定输入查询x生成非拒绝（non-refusal）响应的概率的补数。具体来说，如果LLM拒绝执行某个查询，那么拒绝损失为0；如果LLM执行了查询，拒绝损失接近1。
   * 拒绝损失函数的值越低，表示LLM越有可能拒绝该查询；反之，拒绝损失函数的值越高，表示LLM越有可能接受并执行该查询。
2. **拒绝损失函数的平滑性和值的特性**：
   * 通过对良性和恶意查询的拒绝损失函数进行可视化，研究发现恶意查询的拒绝损失函数往往具有更小的值和更大的梯度范数。这意味着恶意查询在拒绝损失景观中的位置更加陡峭，因此可以通过梯度范数的大小来区分恶意和良性查询。
3. **两步越狱检测算法**：
   * **第一步 - 采样基础拒绝**：Gradient Cuff首先检查拒绝损失函数的值是否小于0.5。如果是，这意味着LLM有较高的概率拒绝该查询，因此该查询被直接拒绝。
   * **第二步 - 梯度范数拒绝**：对于拒绝损失函数值大于0.5的查询，Gradient Cuff进一步计算损失函数的梯度范数。如果梯度范数超过预设的阈值，这表明查询在拒绝损失景观中的位置非常陡峭，因此被判断为越狱尝试并被拒绝。
4. **梯度范数的估计**：
   * 由于直接计算梯度范数可能不可行，Gradient Cuff使用零阶梯度估计方法来近似计算梯度范数。这种方法只需要函数评估，不需要梯度的精确值，使其适用于黑盒模型。
5. **阈值的选择**：
   * 在实际部署Gradient Cuff之前，通过在良性用户查询上进行测试来选择一个合适的阈值t，以满足所需的良性拒绝率（false positive rate，σ）。这样可以确保在保持对良性查询的低误拒率的同时，有效拒绝恶意查询。

通过上述设计，Gradient Cuff能够有效地区分和拒绝越狱攻击，同时保持对正常用户查询的高接受率。这种方法的有效性在于它利用了LLM在处理恶意和良性查询时的内在差异，并以此为基础构建了一个强大的防御机制。





### 阅读总结

本文针对大型语言模型（LLMs）的越狱攻击问题，提出了一种新的检测方法Gradient Cuff。该方法通过分析拒绝损失函数的特性，设计了一个两步检测策略，有效地提高了对恶意越狱查询的检测能力，同时保持了对良性查询的低误拒率。实验结果表明，Gradient Cuff在多种越狱攻击场景下都表现出优越的性能，并且在与现有防御策略结合时能够进一步提升性能。这项工作为保护LLMs免受越狱攻击提供了一种有效的解决方案，并为未来的研究和实践提供了新的思路。
