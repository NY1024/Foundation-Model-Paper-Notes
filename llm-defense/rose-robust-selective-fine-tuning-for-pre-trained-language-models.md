# ROSE: Robust Selective Fine-tuning for Pre-trained Language Models

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着大规模语言模型在自然语言处理（NLP）任务中取得显著性能，这些模型在面对对抗性攻击时的脆弱性也日益凸显。对抗性攻击通常通过字符或词级别的扰动来欺骗模型，这些扰动可能是训练集中未出现的标记或与标签相关的表面线索。为了提高模型的对抗性鲁棒性，研究者们提出了多种防御方法，包括对抗性训练和对抗性数据增强等。然而，这些方法在实践中受到攻击搜索空间大和不适用于不同类型的攻击的限制。

### 2. 过去方案和缺点

过去的防御方法，如对抗性训练和对抗性数据增强，虽然在提高模型鲁棒性方面显示出潜力，但它们通常需要大量的计算资源，并且不适用于所有类型的攻击。此外，这些方法往往需要大量的攻击搜索空间，且在实践中难以广泛应用。

### 3. 本文方案和步骤

本文提出了一种名为RObust SElective Fine-Tuning (ROSE)的新方法，用于在微调预训练模型时进行选择性更新，以过滤掉不稳定和不鲁棒的参数更新。ROSE包括两种策略：一阶ROSE和二阶ROSE，用于选择目标鲁棒参数。一阶ROSE通过对抗性扰动来识别对隐藏空间中微小扰动不敏感的参数，而二阶ROSE通过平滑优化轨迹来对抗不同语义示例中的表面模式。此外，还提出了一种集成方法来结合这两种策略的优势。

### 4. 本文创新点与贡献

ROSE的主要创新点在于其攻击无关性和模型无关性，它从学习的角度出发，通过选择性微调来提高模型的鲁棒性。ROSE在微调过程中区分参数，仅对鲁棒和信息丰富的参数进行更新，同时冻结其他参数。这种方法在保持良性性能的同时，显著提高了模型在各种下游NLP任务上的对抗性鲁棒性。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 5. 本文实验

实验部分，作者在GLUE和AdvGLUE基准测试上评估了ROSE的有效性。与多种强大的防御方法进行了比较，结果表明ROSE在挑战性示例上展现出优越的对抗性鲁棒性，并在多个基准测试上实现了可比甚至更好的良性性能。ROSE是通用的，可以与现有方法结合使用，以进一步提高它们的对抗性鲁棒性。

### 6. 实验结论

实验结果表明，ROSE在提高预训练语言模型的对抗性鲁棒性方面取得了显著成效。ROSE-Ensemble通过结合一阶和二阶策略，提供了最强的对抗性鲁棒性。此外，ROSE可以轻松地融入现有的微调方法中，以进一步提高它们的鲁棒性。

### 7. 全文结论

本文提出了ROSE，一种攻击无关和模型无关的防御方法，通过在微调阶段选择性地更新鲁棒参数来提高模型的对抗性鲁棒性。ROSE通过一阶和二阶策略以及它们的集成方法，显著提高了模型在各种NLP任务上的鲁棒性。实验结果证明了ROSE的有效性，并展示了其在微调过程中找到更宽、更平坦的解的能力。

### 阅读总结

本文针对预训练语言模型在面对对抗性攻击时的脆弱性问题，提出了一种新的微调方法ROSE。ROSE通过在微调过程中选择性地更新参数，有效地提高了模型的对抗性鲁棒性。这种方法不仅在实验中表现出色，而且具有通用性，可以与现有的微调方法结合使用。ROSE的提出为提高语言模型的鲁棒性提供了新的视角，并可能激发更多关于防御性工作的研究。尽管ROSE在某些数据集上取得了优异的对抗性鲁棒性，但仍存在一些限制，例如需要大量的GPU资源来选择最佳参数，以及目前仅限于微调阶段的应用。未来的工作可能会探索将ROSE应用于预训练阶段。
