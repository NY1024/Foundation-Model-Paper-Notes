# DETECTING LANGUAGE MODEL ATTACKS WITH PERPLEXITY

<figure><img src="../.gitbook/assets/image (9) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

本研究探讨了针对大型语言模型（LLMs）的一种新型攻击手段，该手段利用对抗性后缀（adversarial suffixes）欺骗模型生成危险回应。这种攻击可以诱导LLMs提供制作爆炸物、策划银行抢劫或创建攻击性内容的复杂指令。研究者使用开源LLM（GPT-2）评估带有对抗性后缀的查询的困惑度（perplexity），发现这些查询具有极高的困惑度值。研究还发现，尽管存在误报问题，但通过训练Light-GBM模型在困惑度和令牌长度上，可以有效检测大多数对抗性攻击。

### 2. 过去方案和缺点

过去的研究主要集中在通过增强模型的对齐机制来减少滥用，例如当提出非法查询时，模型可以拒绝回答。然而，对抗性提示工程和LLM越狱（jailbreaks）的出现，使得绕过这些对齐保护成为可能。此外，简单的困惑度过滤在面对多样化的常规（非对抗性）提示时，存在显著的误报问题。

### 3. 本文方案和步骤

研究者提出了一种基于困惑度的检测方法，因为困惑度对于普通文本是优化为低值的。他们生成了对抗性示例，并与多样化的常规提示集进行了比较。研究者提出，通过在困惑度和令牌序列长度上训练分类器，可以显著提高过滤效果。他们使用Light-GBM算法训练分类器，并在测试集上进行了评估。

### 4. 本文创新点与贡献

* 提出了使用困惑度来检测对抗性攻击的方法。
* 提出了一个基于困惑度和令牌序列长度的分类器，以改善简单的困惑度过滤。
* 发现该方法成功检测了机器生成的对抗性后缀攻击，但对人类精心设计的越狱攻击无效。

### 5. 本文实验

实验中，研究者使用了两个不同的数据集，一个包含1407个机器生成的对抗性提示，另一个包含79个人工设计的对抗性提示。他们使用GPT-2计算每个提示的困惑度，并使用LightGBM算法训练分类器。在测试数据集上，分类器在区分真实提示和对抗性后缀攻击方面表现出色。

### 6. 实验结论

实验结果表明，困惑度是一个有效的初步区分非对抗性和对抗性提示的工具。通过结合令牌序列长度和困惑度，可以显著降低误报率。然而，对于人类精心设计的越狱攻击，该方法未能有效检测。

### 7. 全文结论

研究者观察到，使用GPT-2的困惑度是识别机器生成的对抗性后缀攻击的有效初始工具。他们通过Zou等人（2023）的GCG算法生成了超过1400个对抗性字符串。然而，对于人类精心设计的越狱攻击，该方法未能有效检测。尽管如此，这种方法可能能够检测到类似于Zou等人（2023）的对抗性后缀攻击。

### 阅读总结

本研究针对LLMs的对抗性攻击提出了一种基于困惑度的检测方法，并展示了其在机器生成的对抗性攻击中的有效性。研究者通过实验验证了该方法在降低误报率方面的潜力，同时也指出了其在检测人类精心设计攻击方面的局限性。这项工作为LLMs的安全防护提供了新的视角，并为未来的研究提供了有价值的方向。
