# Sight Beyond Text: Multi-Modal Training Enhances  LLMsinTruthfulness and Ethics

<figure><img src="../.gitbook/assets/image (8) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## 阅读总结报告

### 1. 研究背景

随着大型语言模型（LLMs）在各个领域的显著变革，它们向多模态能力的进化，即以类似人类的方式与来自不同领域的输入进行交互，引起了广泛关注。尽管先前的研究主要集中在多模态LLMs（MLLMs）在视觉推理和视觉基础生成任务上的能力，但对于它们在纯自然语言处理（NLP）任务上的性能评估却相对有限。

### 2. 过去方案和缺点

以往的研究主要关注MLLMs在多模态任务上的表现，而忽视了它们在纯NLP任务上的能力。此外，LLMs在生成内容时可能出现“幻觉”现象，即产生误导性或事实上不正确的内容，这在多模态训练中并未得到充分解决。

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

### 3. 本文方案和步骤

本文提出了一种新的方法，即通过视觉指令调整（visual instruction tuning）来增强LLMs在纯NLP环境中的真实性和伦理对齐。研究者们首先对LLMs进行多模态数据的微调，然后评估这些模型在TruthfulQA-mc和Ethics基准测试上的表现。研究步骤包括：

* 使用预训练的视觉编码器（如CLIP ViT-L/14）和可训练的线性层将视觉标记投影到语言嵌入空间。
* 在两个阶段进行微调：首先调整视觉-语言连接器的权重，然后微调连接器和LLM的权重。
* 使用来自LLaVA的数据集进行训练，包括图像-文本配对和指令跟随数据。

### 4. 本文创新点与贡献

本文的主要创新点在于发现视觉指令调整不仅提高了MLLMs在多模态任务上的表现，而且意外地提高了它们在纯NLP任务上的真实性和伦理对齐。这一发现挑战了之前的观点，即多模态训练可能会损害LLMs在标准NLP任务上的能力。

### 5. 本文实验

实验部分，研究者们对比了原始LLMs和经过多模态微调的LLMs在Ethics和TruthfulQA基准测试上的表现。实验结果表明，经过视觉指令调整的模型在这些基准测试上的表现优于未经调整的模型。

### 6. 实验结论

实验结果支持了研究者们的假设，即视觉指令调整可以显著提高LLMs在真实性和伦理对齐方面的表现。此外，研究还发现，不同类型的视觉指令数据对LLMs的对齐有不同的影响。

### 7. 全文结论

本文的研究结果表明，视觉指令调整是一种有前景的方法，可以在不牺牲标准NLP能力的情况下，提高LLMs的真实性和伦理对齐。这一发现为未来的研究提供了新的方向，即探索视觉指令调整数据的创新方法，以及开发新的MLLM架构。

### 阅读总结

本文通过实证研究，揭示了视觉指令调整在提升LLMs的真实性和伦理对齐方面的潜力。这一发现不仅对理论研究具有重要意义，也为实际应用中的AI对齐问题提供了新的解决思路。研究者们通过对比实验，展示了视觉指令调整在多模态和纯NLP任务上的双重优势，为未来的多模态交互研究和LLMs的进一步发展奠定了基础。
